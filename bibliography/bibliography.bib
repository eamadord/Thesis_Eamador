

@techreport{Kitchenham07guidelinesfor,
    author = {Kitchenham, Barbara A. and Charters, S.},
    citeulike-article-id = {7874938},
    institution = {Keele University},
    keywords = {data\_mining, software\_engineering},
    number = {EBSE-2007-01},
    posted-at = {2010-09-22 11:06:22},
    priority = {2},
    title = {{Guidelines for performing Systematic Literature Reviews in Software Engineering}},
    type = {Technical Report},
    year = {2007}
}

@inproceedings{daniele_knowledge_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Knowledge {Enhanced} {Neural} {Networks}},
	isbn = {978-3-030-29908-8},
	doi = {10.1007/978-3-030-29908-8_43},
	abstract = {We propose Knowledge Enhanced Neural Networks (KENN), an architecture for injecting prior knowledge, codified by a set of logical clauses, into a neural network.In KENN clauses are directly incorporated in the structure of the neural network as a new layer that includes a set of additional learnable parameters, called clause weights. As a consequence, KENN can learn the level of satisfiability to impose in the final classification. When training data contradicts a constraint, KENN learns to ignore it, making the system robust to the presence of wrong knowledge. Moreover, the method returns learned clause weights, which gives us informations about the influence of each constraint in the final predictions, increasing the interpretability of the model. We evaluated KENN on two standard datasets for multi-label classification, showing that the injection of clauses automatically extracted from the training data sensibly improves the performances. Furthermore, we apply KENN to solve the problem of finding relationship between detected objects in images by adopting manually curated clauses. The evaluation shows that KENN outperforms the state of the art methods on this task.},
	language = {en},
	booktitle = {{PRICAI} 2019: {Trends} in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Daniele, Alessandro and Serafini, Luciano},
	editor = {Nayak, Abhaya C. and Sharma, Alok},
	year = {2019},
	keywords = {Fuzzy logic, Neural networks, Neural-symbolic integration, Visual Relationship Detection},
	pages = {542--554},
	file = {Springer Full Text PDF:/Users/eamador/Zotero/storage/KRNFFFFC/Daniele and Serafini - 2019 - Knowledge Enhanced Neural Networks.pdf:application/pdf},
}

@article{hatzilygeroudis_integrated_2010,
	title = {Integrated {Rule}-{Based} {Learning} and {Inference}},
	volume = {22},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2010.79},
	abstract = {Neurules are a kind of integrated rules integrating neurocomputing and production rules. Each neurule is represented as an adaline unit. Thus, the corresponding neurule base consists of a number of autonomous adaline units (neurules). In this paper, we present the construction process and the inference mechanism of neurules and explore their generalization capabilities. The construction process, which also implements corresponding learning algorithm, creates neurules from a given empirical data set. The inference mechanism of neurules is integrated in its nature; it combines neurocomputing with symbolic processes. It is also interactive, i.e., it interacts with the user asking him/her to provide values for some variables necessary to carry on inference. As shown via experiments, the neurules' integrated inference mechanism is more efficient than the inference mechanism used in connectionist expert systems. Furthermore, neurules generalize much better than their constituent neural component (adaline unit) and are comparable to the backpropagation neural net (BPNN).},
	number = {11},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Hatzilygeroudis, Ioannis and Prentzas, Jim},
	month = nov,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	keywords = {Artificial neural networks, Backpropagation, Hybrid intelligent systems, Inference algorithms, Inference mechanisms, integrated inference, Knowledge based systems, Multivalued logic, Neural networks, neurocomputing., Neurosymbolic integration, Problem-solving, Production, rule-based reasoning},
	pages = {1549--1562},
	file = {IEEE Xplore Abstract Record:/Users/eamador/Zotero/storage/EBJHMGK6/5467071.html:text/html},
}


 
@techreport{rdfstandard,
  added-at = {2009-02-20T10:16:50.000+0100},
  author = {Lassila, O. and Swick, R. R.},
  biburl = {https://www.bibsonomy.org/bibtex/22677b7b9a697a3005e906739f2882ae4/lysander07},
  description = {My Main bibliography file},
  institution = {World Wide Web Consortium},
  interhash = {0bde507d9f42a58c9e36f7fdfc65c7a0},
  intrahash = {2677b7b9a697a3005e906739f2882ae4},
  keywords = {RDF i2cs09 www03 wwwbook},
  timestamp = {2009-02-20T10:17:17.000+0100},
  title = {{Resource Description Framework (RDF) Model and Syntax Specification }},
  type = {{W3C Recommendation}},
  URL = {http://www.w3.org/TR/1999/REC-rdf-syntax-19990222/},
  year = 1999
}


@article{roychowdhury_regularizing_2021,
	title = {Regularizing deep networks with prior knowledge: {A} constraint-based approach},
	volume = {222},
	issn = {0950-7051},
	shorttitle = {Regularizing deep networks with prior knowledge},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705121002525},
	doi = {10.1016/j.knosys.2021.106989},
	abstract = {Deep Learning architectures can develop feature representations and classification models in an integrated way during training. This joint learning process requires large networks with many parameters, and it is successful when a large amount of training data is available. Instead of making the learner develop its entire understanding of the world from scratch from the input examples, the injection of prior knowledge into the learner seems to be a principled way to reduce the amount of require training data, as the learner does not need to induce the rules from the data. This paper presents a general framework to integrate arbitrary prior knowledge into learning. The domain knowledge is provided as a collection of first-order logic (FOL) clauses, where each task to be learned corresponds to a predicate in the knowledge base. The logic statements are translated into a set of differentiable constraints, which can be integrated into the learning process to distill the knowledge into the network, or used during inference to enforce the consistency of the predictions with the prior knowledge. The experimental results have been carried out on multiple image datasets and show that the integration of the prior knowledge boosts the accuracy of several state-of-the-art deep architectures on image classification tasks.},
	language = {en},
	urldate = {2022-02-10},
	journal = {Knowledge-Based Systems},
	author = {Roychowdhury, Soumali and Diligenti, Michelangelo and Gori, Marco},
	month = {jun},
	year = {2021},
	keywords = {Convolutional neural networks, Deep learning, First-order logic, Image classification, Learning from constraints, Neuro symbolic methods},
	pages = {106989},
	file = {Texto completo:/Users/eamador/Zotero/storage/AIL2WJ62/Roychowdhury et al. - 2021 - Regularizing deep networks with prior knowledge A.pdf:application/pdf;ScienceDirect Snapshot:/Users/eamador/Zotero/storage/BD9V7PNC/S0950705121002525.html:text/html},
}


@MISC{googlekg,
  title = {Introducing the Knowledge Graph: things, not strings},
  howpublished = {\url{https://googleblog.blogspot.com/2012/05/introducing-knowledge-graph-things-not.html}},
  note = {Accessed: 2018-12-18}
}

@ARTICLE{ahmedetal,
author={E. {Ahmed} and I. {Yaqoob} and A. {Gani} and M. {Imran} and M. {Guizani}},
journal={IEEE Wireless Communications},
title={Internet-of-things-based smart environments: state of the art, taxonomy, and open research challenges},
year={2016},
volume={23},
number={5},
pages={10-16},
keywords={actuators;Internet of Things;sensors;wireless LAN;Internet-of-Things-based smart environments;communication technologies;actuators;sensors;network connectivity;continuously connected physical world;IoT-based smart environments;communication enablers;network types;local area wireless standards;Internet of things;Wireless communication;Telecommunication services;Intelligent sensors;Actuators;Smart devices},
doi={10.1109/MWC.2016.7721736},
ISSN={1536-1284},
month={October},}

@article{owlstandard,
author = {Bechhofer, Sean and Harmelen, Frank and Hendler, James and Horrocks, Ian and Mcguinness, Deborah and F. Patel-Schneider, Peter and Stein, Lynn},
year = {2004},
month = {02},
pages = {},
title = {OWL Web Ontology Language Reference}
}

@article{webchild,
  title={WebChild 2.0: fine-grained commonsense knowledge distillation},
  author={Tandon, Niket and de Melo, Gerard and Weikum, Gerhard},
  journal={Proceedings of ACL 2017, System Demonstrations},
  pages={115--120},
  year={2017}
}

@book{wordnet,
  title={WordNet: An electronic lexical database},
  author={Miller, George},
  year={1998},
  publisher={MIT press}
}

@article{conceptnet,
 author = {Liu, H. and Singh, P.},
 title = {ConceptNet \&Mdash; A Practical Commonsense Reasoning Tool-Kit},
 journal = {BT Technology Journal},
 issue_date = {October 2004},
 volume = {22},
 number = {4},
 month = oct,
 year = {2004},
 issn = {1358-3948},
 pages = {211--226},
 numpages = {16},
 url = {http://dx.doi.org/10.1023/B:BTTJ.0000047600.45421.6d},
 doi = {10.1023/B:BTTJ.0000047600.45421.6d},
 acmid = {1031373},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
} 

@inproceedings{kursuncu_knowledge_2020,
	title = {Knowledge {Infused} {Learning} ({K}-{IL}): {Towards} {Deep} {Incorporation} of {Knowledge} in {Deep} {Learning}},
	shorttitle = {Knowledge {Infused} {Learning} ({K}-{IL})},
	booktitle = {Proceedings of the AAAI 2020 Spring Symposium on Combining Machine Learning and Knowledge Engineering in Practice },
	author = {Kursuncu, Ugur and Gaur, Manas and Sheth, Amit},
	month = {Spring},
	year = {2020},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}


@article{cyckb,
 author = {Lenat, Douglas B.},
 title = {CYC: A Large-scale Investment in Knowledge Infrastructure},
 journal = {Commun. ACM},
 issue_date = {Nov. 1995},
 volume = {38},
 number = {11},
 month = nov,
 year = {1995},
 issn = {0001-0782},
 pages = {33--38},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/219717.219745},
 doi = {10.1145/219717.219745},
 acmid = {219745},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{Ribeiro_Singh_Guestrin_2018, title={Anchors: High-Precision Model-Agnostic Explanations}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11491}, abstractNote={ &lt;p&gt; We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, &quot;sufficient&quot; conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos}, year={2018}, month={Apr.} }

@article{ribeiro_lime_2016,
  author    = {Marco T{\'{u}}lio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  journal   = {CoRR},
  volume    = {abs/1602.04938},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.04938},
  eprinttype = {arXiv},
  eprint    = {1602.04938},
  timestamp = {Mon, 13 Aug 2018 16:49:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RibeiroSG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{moralmachine,
author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-François and Rahwan, Iyad},
year = {2018},
month = {10},
pages = {59-64},
title = {The Moral Machine Experiment},
volume = {563},
journal = {Nature},
doi = {10.1038/s41586-018-0637-6}
}

@article{Tandonetal,
 author = {Tandon, Niket and Varde, Aparna S. and de Melo, Gerard},
 title = {Commonsense Knowledge in Machine Intelligence},
 journal = {SIGMOD Rec.},
 issue_date = {December 2017},
 volume = {46},
 number = {4},
 month = feb,
 year = {2018},
 issn = {0163-5808},
 pages = {49--52},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3186549.3186562},
 doi = {10.1145/3186549.3186562},
 acmid = {3186562},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{deMelo,
 author = {de Melo, Gerard},
 title = {Inducing Conceptual Embedding Spaces from Wikipedia},
 booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
 series = {WWW '17 Companion},
 year = {2017},
 isbn = {978-1-4503-4914-7},
 location = {Perth, Australia},
 pages = {43--50},
 numpages = {8},
 url = {https://doi.org/10.1145/3041021.3054144},
 doi = {10.1145/3041021.3054144},
 acmid = {3054144},
 publisher = {International World Wide Web Conferences Steering Committee},
 address = {Republic and Canton of Geneva, Switzerland},
 keywords = {conceptual knowledge, semantic representations, wikipedia},
} 

 


@inproceedings{PurietAl,
  author    = {Manish Puri and
               Aparna S. Varde and
               Boxiang Dong},
  title     = {Pragmatics and Semantics to Connect Specific Local Laws with Public
               Reactions},
  booktitle = {BigData},
  pages     = {5433--5435},
  publisher = {{IEEE}},
  year      = {2018}
}


@article{FERNANDEZ2011789,
title = "Usability evaluation methods for the web: A systematic mapping study",
journal = "Information and Software Technology",
volume = "53",
number = "8",
pages = "789 - 817",
year = "2011",
note = "Advances in functional size measurement and effort estimation - Extended best papers",
issn = "0950-5849",
doi = "https://doi.org/10.1016/j.infsof.2011.02.007",
url = "http://www.sciencedirect.com/science/article/pii/S0950584911000607",
author = "Adrian Fernandez and Emilio Insfran and Silvia Abrahão"
}

@MISC{km4city,
title = {Km4City Project},
howpublished={\url{http://www.disit.org/drupal/?q=node/5487}},
note = {Accessed: 2018-12-20}
}

@MISC{roompathy,
title = {Roompathy Project},
howpublished={\url{https://ami-2016.github.io/RPY/index.html}},
note = {Accessed: 2019-02-19}
}

@article{khan2003five,
  title={Five steps to conducting a systematic review},
  author={Khan, Khalid S and Kunz, Regina and Kleijnen, Jos and Antes, Gerd},
  journal={Journal of the royal society of medicine},
  volume={96},
  number={3},
  pages={118--121},
  year={2003},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{goodchild2007citizens,
  title={Citizens as sensors: the world of volunteered geography},
  author={Goodchild, Michael F},
  journal={GeoJournal},
  volume={69},
  number={4},
  pages={211--221},
  year={2007},
  publisher={Springer}
}

@book{Jackson:1998:IES:521024,
 author = {Jackson, Peter},
 title = {Introduction to Expert Systems},
 year = {1998},
 isbn = {0201876868},
 edition = {3rd},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
}

@book{mycin,
 author = {Buchanan, Bruce G. and Shortliffe, Edward H.},
 title = {Rule Based Expert Systems: The Mycin Experiments of the Stanford Heuristic Programming Project (The Addison-Wesley Series in Artificial Intelligence)},
 year = {1984},
 isbn = {0201101726},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
}

@MISC{replicate,
title = {REPLICATE Project},
howpublished={\url{https://replicate-project.eu/}},
note = {Accessed: 2018-12-30}
}

@article{3cixty,
title = "3cixty: Building comprehensive knowledge bases for city exploration",
journal = "Journal of Web Semantics",
volume = "46-47",
pages = "2 - 13",
year = "2017",
issn = "1570-8268",
doi = "https://doi.org/10.1016/j.websem.2017.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S1570826817300318",
author = "Raphaël Troncy and Giuseppe Rizzo and Anthony Jameson and Oscar Corcho and Julien Plu and Enrico Palumbo and Juan Carlos Ballesteros Hermida and Adrian Spirescu and Kai-Dominik Kuhn and Catalin Barbu and Matteo Rossi and Irene Celino and Rachit Agarwal and Christian Scanu and Massimo Valla and Timber Haaker",
keywords = "3cixty, Smart city, Parallel faceted browser interface, Exploratory search engine, Knowledge base, Instance matching"
}

@INPROCEEDINGS{persaudetal,
author={P. Persaud and A. S. Varde and S. Robila},
booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)},
title={Enhancing Autonomous Vehicles with Commonsense: Smart Mobility in Smart Cities},
year={2017},
volume={},
number={},
pages={1008-1012},
keywords={common-sense reasoning;intelligent robots;knowledge based systems;mobile robots;smart cities;autonomous vehicles;smart mobility;smart cities;law firm;robot lawyer;robot drivers;cognitive capacity;commonsense knowledge;CSK;WebChild repository;domain-specific knowledge bases;Autonomous vehicles;Smart cities;Cognition;Robot sensing systems;Automated driving;AI and law;Commonsense Knowledge;Domain KBs;Object detection;Smart mobility},
doi={10.1109/ICTAI.2017.00155},
ISSN={2375-0197},
month={11},}

@Article{KimandChang,
author="Kim, Joo-Chang
and Chung, Kyungyong",
title="Depression Index Service Using Knowledge Based Crowdsourcing in Smart Health",
journal="Wireless Personal Communications",
year="2017",
month="Mar",
day="01",
volume="93",
number="1",
pages="255--268",
issn="1572-834X",
doi="10.1007/s11277-016-3923-3",
url="https://doi.org/10.1007/s11277-016-3923-3"
}

@INPROCEEDINGS{Olzewskietal,
author={R. Olszewski and H. Trojanowska and A. Turek and B. Kietlinska},
booktitle={2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)},
title={Solving smart city revitalisation problems with geoparticipation process and fuzzy methods},
year={2017},
volume={},
number={},
pages={2497-2503},
keywords={data mining;fuzzy reasoning;public administration;smart cities;Polish local governments;geoparticipation process;smart city revitalisation problems;smart city creation;urban revitalization;fuzzy rules;FIS knowledge base;fuzzy inference system;spatial data mining;complicated revitalization processes;exceptionally simple method;Data mining;Spatial databases;Urban areas;Buildings;Investment;Planning;Rivers;spatial data mining;FIS;smart city;revitalisation;geoparticipation;citizens;urban planning},
doi={10.1109/FSKD.2017.8393168},
ISSN={},
month={July},}

@INPROCEEDINGS{xiaoboetal,
author={W. Xiaobo and J. Liu and C. Xu},
booktitle={2016 International Conference on Smart City and Systems Engineering (ICSCSE)},
title={Research on Ontology-Based Knowledge Base Construction of Bilingual Teaching Resources},
year={2016},
volume={},
number={},
pages={144-148},
keywords={computer aided instruction;knowledge acquisition;ontologies (artificial intelligence);open systems;teaching;ontology-based knowledge base construction;bilingual education;China;Xinjiang bilingual teaching resources database;subject knowledge;knowledge expression;knowledge acquisition;curriculum-oriented knowledge model;teaching resource management;interoperability;resource sharing;personalized services;Education;Ontologies;Knowledge acquisition;Knowledge based systems;Knowledge management;Libraries;Data mining;Billingual education;Teaching resources;Ontology;kuowledge base},
doi={10.1109/ICSCSE.2016.0048},
ISSN={},
month={11},}

@InProceedings{giannakopouliuetal,
author="Giannakopoulou, Kalliopi
and Kontogiannis, Spyros
and Papastavrou, Georgia
and Zaroliagis, Christos",
editor="Sellis, Timos
and Oikonomou, Konstantinos",
title="A Cloud-Based Time-Dependent Routing Service",
booktitle="Algorithmic Aspects of Cloud Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="41--64",
}

@InProceedings{orlowskietal,
author="Or{\l}owski, Cezary
and Zi{\'o}{\l}kowski, Artur
and Or{\l}owski, Aleksander
and Kap{\l}a{\'{n}}ski, Pawe{\l}
and Sitek, Tomasz
and Pokrzywnicki, Witold",
editor="Nguyen, Ngoc Thanh
and Kowalczyk, Ryszard
and Or{\l}owski, Cezary
and Zi{\'o}{\l}kowski, Artur",
title="High-Level Model for the Design of KPIs for Smart Cities Systems",
booktitle="Transactions on Computational Collective Intelligence XXV",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--14",
}

@InProceedings{olszewskiturek,
author="Olszewski, Robert
and Turek, Agnieszka",
editor="Tan, Ying
and Shi, Yuhui",
title="Application of the Spatial Data Mining Methodology and Gamification for the Optimisation of Solving the Transport Issues of the ``Varsovian Mordor''",
booktitle="Data Mining and Big Data",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="103--114",
}

@InProceedings{chungetal,
author="Chung, Tong Lee
and Xu, Bin
and Yao, Xuanyu
and Li, Qi
and Yuan, Bozhi",
editor="Supnithi, Thepchai
and Yamaguchi, Takahira
and Pan, Jeff Z.
and Wuwongse, Vilas
and Buranarach, Marut",
title="Ontology Based Suggestion Distribution System ",
booktitle="Semantic Technology",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="414--421",
}

 

@inproceedings{barnwaletal,
  author    = {Rajesh P. Barnwal and
               Nirnay Ghosh and
               Soumya K. Ghosh and
               Sajal K. Das},
  title     = {PS-Sim: {A} Framework for Scalable Simulation of Participatory Sensing
               Data},
  booktitle = {2018 {IEEE} International Conference on Smart Computing, {SMARTCOMP}
               2018, Taormina, Sicily, Italy, June 18-20, 2018},
  pages     = {195--202},
  year      = {2018},
  crossref  = {DBLP:conf/smartcomp/2018},
  url       = {https://doi.org/10.1109/SMARTCOMP.2018.00091},
  doi       = {10.1109/SMARTCOMP.2018.00091},
  timestamp = {Thu, 23 Aug 2018 17:16:52 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/smartcomp/BarnwalGGD18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/smartcomp/2018,
  title     = {2018 {IEEE} International Conference on Smart Computing, {SMARTCOMP}
               2018, Taormina, Sicily, Italy, June 18-20, 2018},
  publisher = {{IEEE} Computer Society},
  year      = {2018},
  url       = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=8421100},
  isbn      = {978-1-5386-4705-9},
  timestamp = {Thu, 02 Aug 2018 11:10:44 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/smartcomp/2018},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bogaleetal,
  author    = {Tadilo Endeshaw Bogale and
               Xianbin Wang and
               Long Bao Le},
  title     = {Machine Intelligence Techniques for Next-Generation Context-Aware
               Wireless Networks},
  journal   = {CoRR},
  volume    = {abs/1801.04223},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.04223},
  archivePrefix = {arXiv},
  eprint    = {1801.04223},
  timestamp = {Mon, 13 Aug 2018 16:45:59 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-04223},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zavalaetal,
title = "SACRE: Supporting contextual requirements’ adaptation in modern self-adaptive systems in the presence of uncertainty at runtime",
journal = "Expert Systems with Applications",
volume = "98",
pages = "166 - 188",
year = "2018",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2018.01.009",
url = "http://www.sciencedirect.com/science/article/pii/S0957417418300095",
author = "Edith Zavala and Xavier Franch and Jordi Marco and Alessia Knauss and Daniela Damian",
keywords = "Self-adaptive systems, Decentralized control loops, Machine learning, Requirements engineering, Contextual requirements, Requirements adaptation",
abstract = "Runtime uncertainty such as unpredictable resource unavailability, changing environmental conditions and user needs, as well as system intrusions or faults represents one of the main current challenges of self-adaptive systems. Moreover, today's systems are increasingly more complex, distributed, decentralized, etc. and therefore have to reason about and cope with more and more unpredictable events. Approaches to deal with such changing requirements in complex today's systems are still missing. This work presents SACRE (Smart Adaptation through Contextual REquirements), our approach leveraging an adaptation feedback loop to detect self-adaptive systems’ contextual requirements affected by uncertainty and to integrate machine learning techniques to determine the best operationalization of context based on sensed data at runtime. SACRE is a step forward of our former approach ACon which focus had been on adapting the context in contextual requirements, as well as their basic implementation. SACRE primarily focuses on architectural decisions, addressing self-adaptive systems’ engineering challenges. Furthering the work on ACon, in this paper, we perform an evaluation of the entire approach in different uncertainty scenarios in real-time in the extremely demanding domain of smart vehicles. The real-time evaluation is conducted in a simulated environment in which the smart vehicle is implemented through software components. The evaluation results provide empirical evidence about the applicability of SACRE in real and complex software system domains."
}

@article{zhouetal,
  author    = {Qunzhi Zhou and
               Yogesh Simmhan and
               Viktor K. Prasanna},
  title     = {Knowledge-infused and consistent Complex Event Processing over real-time
               and persistent streams},
  journal   = {Future Generation Comp. Syst.},
  volume    = {76},
  pages     = {391--406},
  year      = {2017},
  url       = {https://doi.org/10.1016/j.future.2016.10.030},
  doi       = {10.1016/j.future.2016.10.030},
  timestamp = {Fri, 30 Nov 2018 13:19:55 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/fgcs/ZhouSP17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@INPROCEEDINGS{xuandli,
author={Y. Xu and C. Li},
booktitle={2018 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)},
title={Research on the Early Intelligent Warning System of Lost Circulation Based on Fuzzy Expert System},
year={2018},
volume={},
number={},
pages={540-544},
keywords={alarm systems;expert systems;fuzzy reasoning;fuzzy set theory;fuzzy systems;inference mechanisms;fuzzy inference machine;early intelligent warning system;fuzzy expert system;drilling process;fuzzy information;intelligent model;fuzzy rule base;fuzzy production rules;lost circulation warning;early warning software system;Conferences;Transportation;Big Data;Smart cities;Lost Circulation;Intelligent Warning;Fuzzy Expert System;Rule;Knowledge},
doi={10.1109/ICITBS.2018.00142},
ISSN={},
month={Jan},}

@INPROCEEDINGS{duyenandnhon,
author={V. T. A. Duyen and D. V. Nhon},
booktitle={2016 Eighth International Conference on Knowledge and Systems Engineering (KSE)},
title={The intelligent guiding system that helps students to solve plane geometry problems},
year={2016},
volume={},
number={},
pages={156-162},
keywords={computer aided instruction;geometry;knowledge based systems;mathematics computing;teaching;intelligent guiding system;plane geometry problems;innovative teaching;teaching strategy;student ability development;instructive system;smart system;optimizations;planar geometrical problems;geometrical knowledge;knowledge base;Geometry;Education;Knowledge based systems;Computational modeling;Optimization;Physics;Software;Intelligent System;Problem Solving;Knowledge Representation;Reasoning},
doi={10.1109/KSE.2016.7758046},
ISSN={},
month={Oct},}

@ARTICLE{roffiaetal,
author={L. Roffia and F. Morandi and J. Kiljander and A. D’Elia and F. Vergari and F. Viola and L. Bononi and T. Salmon Cinotti},
journal={IEEE Internet of Things Journal},
title={A Semantic Publish-Subscribe Architecture for the Internet of Things},
year={2016},
volume={3},
number={6},
pages={1274-1296},
keywords={Internet of Things;message passing;query processing;semantic publish-subscribe architecture;Internet of Things;generic SPARQL endpoint;novel event detection algorithm;smart city lighting case;Internet of things;Semantics;Engines;Computer architecture;Interoperability;Resource description framework;Publish-subscribe;Internet of Things (IoT);interoperability;performance evaluation;publish-subscribe;semantic event processing;smart space applications;SPARQL},
doi={10.1109/JIOT.2016.2587380},
ISSN={2327-4662},
month={Dec},}

@ARTICLE{peraletal,
author={J. Peral and A. Ferrández and D. Gil and R. Muñoz-Terol and H. Mora},
journal={IEEE Access},
title={An Ontology-Oriented Architecture for Dealing With Heterogeneous Data Applied to Telemedicine Systems},
year={2018},
volume={6},
number={},
pages={41118-41138},
keywords={Data mining;Medical services;Sensors;Unified modeling language;Medical diagnostic imaging;Ontologies;Telemedicine;Ontology-oriented architecture;heterogeneous data;health sector;artificial intelligence methods;personalized medicine;telemedicine system;diabetes’ treatment},
doi={10.1109/ACCESS.2018.2857499},
ISSN={2169-3536},
month={},}

@ARTICLE{qiuetal,
author={J. Qiu and Y. Chai and Y. Liu and Z. Gu and S. Li and Z. Tian},
journal={IEEE Access},
title={Automatic Non-Taxonomic Relation Extraction from Big Data in Smart City},
year={2018},
volume={6},
number={},
pages={74854-74864},
keywords={Semantics;Big Data;Data mining;Ontologies;Task analysis;Smart cities;Syntactics;Non-taxonomic relations;semantic graph;dependency relations;smart city},
doi={10.1109/ACCESS.2018.2881422},
ISSN={2169-3536},
month={},}

@ARTICLE{shanandcao,
author={S. Shan and B. Cao},
journal={IET Software},
title={Follow a guide to solve urban problems: the creation and application of urban knowledge graph},
year={2017},
volume={11},
number={3},
pages={126-134},
keywords={expectation-maximisation algorithm;graph theory;inference mechanisms;knowledge acquisition;Gibbs algorithm;expectation-maximisation algorithm;EG;hybrid reasoning algorithm;urban knowledge acquisition;urban knowledge graph;urban problems},
doi={10.1049/iet-sen.2016.0189},
ISSN={1751-8806},
month={},}

@InProceedings{santosetal,
author="Santos, Henrique
and Dantas, Victor
and Furtado, Vasco
and Pinheiro, Paulo
and McGuinness, Deborah L.",
editor="Blomqvist, Eva
and Maynard, Diana
and Gangemi, Aldo
and Hoekstra, Rinke
and Hitzler, Pascal
and Hartig, Olaf",
title="From Data to City Indicators: A Knowledge Graph for Supporting Automatic Generation of Dashboards",
booktitle="The Semantic Web",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="94--108",
}

@INPROCEEDINGS{schoonenbergandfarid,
author={W. C. H. Schoonenberg and A. M. Farid},
booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
title={Modeling smart cities with hetero-functional graph theory},
year={2017},
volume={},
number={},
pages={1627-1632},
keywords={decision making;graph theory;smart cities;town and country planning;resource utilization;hetero-functional graph theory;integrated decision-making;dynamic modeling;smart city model;integrated smart city infrastructure models;modeling foundations;large population centers;highly dense population centers;megacities;urbanization;Mathematical model;Modeling;Graph theory;Smart cities;Knowledge based systems;Transportation;Medical services;Hetero-functional Graph Theory;Infrastructure;Smart City;Axiomatic Design;Engineering Systems},
doi={10.1109/SMC.2017.8122848},
ISSN={},
month={Oct},}

@article{aguilaretal,
   title = {{Ontological emergence based on context analysis as a service for intelligent environments}},
   journal = {{DYNA}},
   author={Aguilar, Jose AND Mendonça, Maribel AND Jerez, Marxjhony AND Sánchez, Manuel},
   ISSN = {0012-7353},
   language = {en},
   URL = {http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0012-73532017000100028&nrm=iso},
   volume = {84},
   year = {2017},
   month = {03},
   pages = {28 - 37},
   publisher = {scieloco},
   }

@InProceedings{aliandlee,
author="Ali, Taqdir
and Lee, Sungyoung",
editor="Chang, Carl K.
and Chiari, Lorenzo
and Cao, Yu
and Jin, Hai
and Mokhtari, Mounir
and Aloulou, Hamdi",
title="Wellness Concepts Model Use and Effectiveness in Intelligent Knowledge Authoring Environment",
booktitle="Inclusive Smart Cities and  Digital Health",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="271--282",
}

@article{haoetal,
title = "Recognizing multi-resident activities in non-intrusive sensor-based smart homes by formal concept analysis",
journal = "Neurocomputing",
volume = "318",
pages = "75 - 89",
year = "2018",
issn = "0925-2312",
doi = "https://doi.org/10.1016/j.neucom.2018.08.033",
url = "http://www.sciencedirect.com/science/article/pii/S0925231218309834",
author = "Jianguo Hao and Abdenour Bouzouane and Sébastien Gaboury",
keywords = "Multi-resident activity recognition, Formal concept analysis, Sequential pattern mining, Smart homes, Ambient intelligence",
}

 
@Article{kimandchung,
author="Kim, Joo-Chang
and Chung, Kyungyong",
title="Neural-network based adaptive context prediction model for ambient intelligence",
journal="Journal of Ambient Intelligence and Humanized Computing",
year="2018",
month="Aug",
day="18",
abstract="To overcome the limitations of the conventional medical service in terms of ageing and chronic diseases, AmI-based precision medicine has drawn particular attention. Precision medicine is a customized personal medical service using various information technologies such as personal health device, AI algorithm, image recognition, voice recognition, and natural language processing. In particular, the information technologies for follow-up care services for patients, such as context awareness, context information, and inference rules, are required. In PHD, contexts such as variable data include blood pressure, BMI, blood sugar, weather, and food. It has time-series characteristics, meaning that it changes often with time. Other kinds of health-related information, such as age, family history, smoking, and residential area, are intermittently changed. For inference that is highly related to a user, the context collected through AmI is presented with ontology. Ontology consists of a user's ambient data, weather data, and lifelog. Context is changed along with a user's ambient conditions and time. An inference engine is used to create the knowledge base and predict a change. This study proposes a neural-network based adaptive context prediction model for ambient intelligence. This is a learning model using neural network to calculate the similarity for recommendation in a mining lifecare platform. In a conventional prediction procedure, an error is used to update a weight. The proposed model learns the similarity weight of the users to become adapted to the user's ambient. Based on the knowledge base, user clustering and deviation from mean are applied to calculate the similarity weight. Collaborative filtering technology is used to predict a user's context and learn the similarity weight repeatedly using a neural network. According to the performance evaluation, the proposed neural-network based similarity weight method had the highest accuracy of prediction when the learning rate was 0.001. Consequently, we found that AmI is a new added-value technology to maintain a healthy lifestyle and contributes to developing the healthcare industry and improving the quality of life.",
issn="1868-5145",
doi="10.1007/s12652-018-0972-3",
url="https://doi.org/10.1007/s12652-018-0972-3"
}

 

@Article{chungetal2018,
author="Chung, Kyungyong
and Yoo, Hyun
and Choe, Do-Eun",
title="Ambient context-based modeling for health risk assessment using deep neural network",
journal="Journal of Ambient Intelligence and Humanized Computing",
year="2018",
month="Sep",
day="14",
abstract="Context computing is a branch of ambient intelligence (AmI) research, which has been rapidly emerging in the support of intelligent smart health platform solution. To develop reliable ambient computing using the hybrid peer-to-peer network and Internet of Things, machine learning, deep learning, artificial intelligence, and context awareness have been applied. This study proposes an ambient context-based modeling for a health risk assessment using deep neural network. In the proposed method, we collected medical information from chronic disease patients such as EMR, PHR, and medical histories, as well as environmental data from a health platform. Subsequently, heterogeneous data are integrated through selecting, cleaning, modeling, and evaluating the collected raw data and then the context is created. The structured input data such as a sensor data are normalized by transforming the time domain data to the frequency domain information. Using a deep neural network, the normalized data are applied to create an ambient context. A deep neural network is composed of the following three layers: input layers with treated and untreated data; hidden layers where connection strength is trained as a weight; and output layers of trained results. In the deep neural network layers, the control of the weight of training data enables repeated learning to create an ambient context pattern. Using an ontology inference engine, unstructured/structured data, including individual health data and environmental information, and their context is presented as ontology metadata. In the knowledge base, hidden association relationships are discovered through mining. To inform the individual health conditions exposed to the individual environmental contexts, a health risk assessment model is developed with a set of the ambient context pattern learned with metadata and a deep neural network. The Minkowski distance formula, which defines a normalized geometrical distance between two nodes, is used to measure the similarity between the patients with chronical disease and the individual user based on the context. In the proposed model, the risk is represented as a similarity-based index. The risk assessment model can be implemented into the individual risk alert/prevention system. The model may significantly impact the healthcare industry as well as ambient intelligence research, thus contributing to improve the quality of human life of the future society.",
issn="1868-5145",
doi="10.1007/s12652-018-1033-7",
url="https://doi.org/10.1007/s12652-018-1033-7"
}



@article{machadoetal,
title = "Reactive, proactive, and extensible situation-awareness in ambient assisted living",
journal = "Expert Systems with Applications",
volume = "76",
pages = "21 - 35",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2017.01.033",
url = "http://www.sciencedirect.com/science/article/pii/S095741741730043X",
author = "Alencar Machado and Vinícius Maran and Iara Augustin and Leandro Krug Wives and José Palazzo Moreira de Oliveira",
keywords = "Situation-awareness, Ambient intelligence, Probabilistic ontology, Ambient assisted living",
}

@INPROCEEDINGS{dimitrovetal,
author={T. Dimitrov and J. Pauli and E. Naroska and C. Ressel},
booktitle={2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
title={Structured Learning of Component Dependencies in AmI Systems},
year={2008},
volume={2},
number={},
pages={118-124},
keywords={home computing;inference mechanisms;knowledge based systems;learning (artificial intelligence);middleware;open systems;uncertainty handling;structured learning;component dependency;AmI system;information and communication technology;interoperable middleware;home environment;probabilistic knowledge base;semantic description;inference mechanism;smart application;uncertainty handling;Ambient intelligence;Motion detection;Uncertainty;Monitoring;Intelligent agent;Sensor systems;Event detection;Switches;Intelligent structures;Communications technology;ambient intelligence;probabilistic knowledge base;context-awareness;Bayesian inference},
doi={10.1109/WIIAT.2008.13},
ISSN={},
month={Dec},}

@Article{ontologiessmartcities,
AUTHOR = {Espinoza-Arias, Paola and Poveda-Villalón, María and García-Castro, Raúl and Corcho, Oscar},
TITLE = {Ontological Representation of Smart City Data: From Devices to Cities},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {32},
URL = {http://www.mdpi.com/2076-3417/9/1/32},
ISSN = {2076-3417},
}


@INPROCEEDINGS{rheeetal,
author={Sang Keun Rhee and K. Lee and H. Kim},
booktitle={2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)},
title={Ontology-based context and preference model for personal service robot},
year={2012},
volume={},
number={},
pages={216-217},
keywords={human-robot interaction;inference mechanisms;intelligent robots;ontologies (artificial intelligence);service robots;ubiquitous computing;ontology-based context and preference model;personal service robot usability;autonomous behaviour;service provision;service execution process;robotic device;environmental context information;higher-level contextual knowledge;rule-based reasoning;user preference knowledge;knowledge base;knowledge model;robotic agent system;Context;Context modeling;Service robots;Cognition;Robot sensing systems;Adaptation models;personal service robot;context awareness;user preference;personalisation;ontology},
doi={10.1109/URAI.2012.6462978},
ISSN={},
month={11},}

@InProceedings{Martinruizetal,
author="Martin-Ruiz, Mar{\'i}a-Luisa
and Valero, Miguel-Angel
and G{\'o}mez, Ana
and Torcal, Carmen",
editor="Mandler, Benny
and Marquez-Barja, Johann
and Mitre Campista, Miguel Elias
and Cag{\'a}{\v{n}}ov{\'a}, Dagmar
and Chaouchi, Hakima
and Zeadally, Sherali
and Badra, Mohamad
and Giordano, Stefano
and Fazio, Maria
and Somov, Andrey
and Vieriu, Radu-Laurentiu",
title="A Cooperative Decision Support System for Children's Neurodevelopment Monitoring",
booktitle="Internet of Things. IoT Infrastructures",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="461--466",
}

@article{sermetetal,
title = "An intelligent system on knowledge generation and communication about flooding",
journal = "Environmental Modelling \& Software",
volume = "108",
pages = "51 - 60",
year = "2018",
issn = "1364-8152",
doi = "https://doi.org/10.1016/j.envsoft.2018.06.003",
url = "http://www.sciencedirect.com/science/article/pii/S1364815217308368",
author = "Yusuf Sermet and Ibrahim Demir",
keywords = "Intelligent systems, Natural language processing, Knowledge generation, Ontology, Disaster preparedness, Information communication",
}

@inproceedings{fastetal,
 author = {Fast, Ethan and McGrath, William and Rajpurkar, Pranav and Bernstein, Michael S.},
 title = {Augur: Mining Human Behaviors from Fiction to Power Interactive Systems},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {San Jose, California, USA},
 pages = {237--247},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2858036.2858528},
 doi = {10.1145/2858036.2858528},
 acmid = {2858528},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowdsourcing, data mining, fiction, information extraction},
} 

@article{ribonietal,
title = "SmartFABER: Recognizing fine-grained abnormal behaviors for early detection of mild cognitive impairment",
journal = "Artificial Intelligence in Medicine",
volume = "67",
pages = "57 - 74",
year = "2016",
issn = "0933-3657",
doi = "https://doi.org/10.1016/j.artmed.2015.12.001",
url = "http://www.sciencedirect.com/science/article/pii/S0933365716000026",
author = "Daniele Riboni and Claudio Bettini and Gabriele Civitarese and Zaffar Haider Janjua and Rim Helaoui",
keywords = "Mild cognitive impairment, Cognitive decline, Abnormal behavior detection, Activity recognition, Pervasive computing",
}


@article{paval,
title = "PAVAL: A location-aware virtual personal assistant for retrieving geolocated points of interest and location-based services",
journal = "Engineering Applications of Artificial Intelligence",
volume = "77",
pages = "70 - 85",
year = "2019",
issn = "0952-1976",
doi = "https://doi.org/10.1016/j.engappai.2018.09.013",
url = "http://www.sciencedirect.com/science/article/pii/S0952197618301994",
author = "Lorenzo Massai and Paolo Nesi and Gianni Pantaleo",
keywords = "Virtual personal assistants, Location-aware recommender systems, Natural language processing, User-intent detection, Semantic web technologies, Geographic information retrieval, Geoparsing, Geocoding",
}

@article{siimobility-parking,
  author    = {Claudio Badii and
               Paolo Nesi and
               Irene Paoli},
  title     = {Predicting Available Parking Slots on Critical and Regular Services
               by Exploiting a Range of Open Data},
  journal   = {{IEEE} Access},
  volume    = {6},
  pages     = {44059--44071},
  year      = {2018},
  url       = {https://doi.org/10.1109/ACCESS.2018.2864157},
  doi       = {10.1109/ACCESS.2018.2864157},
  timestamp = {Fri, 02 Nov 2018 09:29:21 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/access/BadiiNP18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{siimobility-consult,
title = "Linked open graph: Browsing multiple SPARQL entry points to build your own LOD views",
journal = "Journal of Visual Languages \& Computing",
volume = "25",
number = "6",
pages = "703 - 716",
year = "2014",
note = "Distributed Multimedia Systems DMS2014 Part I",
issn = "1045-926X",
doi = "https://doi.org/10.1016/j.jvlc.2014.10.003",
url = "http://www.sciencedirect.com/science/article/pii/S1045926X14000962",
author = "Pierfrancesco Bellini and Paolo Nesi and Alessandro Venturi",
keywords = "LOD, LOD browsing, Knowledge base browsing, SPARQL entry points",
}

@inproceedings{Mikolov:2013:DRW:2999792.2999959,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
 title = {Distributed Representations of Words and Phrases and Their Compositionality},
 booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'13},
 year = {2013},
 location = {Lake Tahoe, Nevada},
 pages = {3111--3119},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999792.2999959},
 acmid = {2999959},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@article{brann1,
author = {Burden, Frank R. and Winkler, David A.},
title = {Robust QSAR Models Using Bayesian Regularized Neural Networks},
journal = {Journal of Medicinal Chemistry},
volume = {42},
number = {16},
pages = {3183-3187},
year = {1999},
doi = {10.1021/jm980697n},
    note ={PMID: 10447964},

URL = { 
        https://doi.org/10.1021/jm980697n
    
},
eprint = { 
        https://doi.org/10.1021/jm980697n
    
}

}

@article{brann2,
author = {MacKay, David J. C.},
title = {A Practical Bayesian Framework for Backpropagation Networks},
journal = {Neural Computation},
volume = {4},
number = {3},
pages = {448-472},
year = {1992},
doi = {10.1162/neco.1992.4.3.448},

URL = { 
        https://doi.org/10.1162/neco.1992.4.3.448
    
},
eprint = { 
        https://doi.org/10.1162/neco.1992.4.3.448
    
}
}

@INPROCEEDINGS{brann3,
author={F. Dan Foresee and M. T. Hagan},
booktitle={Proceedings of International Conference on Neural Networks (ICNN'97)},
title={Gauss-Newton approximation to Bayesian learning},
year={1997},
volume={3},
number={},
pages={1930-1935 vol.3},
keywords={feedforward neural nets;generalisation (artificial intelligence);approximation theory;optimisation;Hessian matrices;Bayes methods;learning (artificial intelligence);Gauss-Newton approximation;Bayesian learning;feedforward neural networks;Hessian matrix;Levenberg-Marquardt algorithm;generalization;Newton method;Least squares methods;Recursive estimation;Bayesian methods;Neural networks;Feedforward neural networks;Cities and towns;Computer networks;Application software;Testing},
doi={10.1109/ICNN.1997.614194},
ISSN={},
month={June},}

@article{fuzzyenvironment,
author = {Bellman, R. E. and Zadeh, L. A.},
title = {Decision-Making in a Fuzzy Environment},
journal = {Management Science},
volume = {17},
number = {4},
pages = {B-141-B-164},
year = {1970},
doi = {10.1287/mnsc.17.4.B141},

URL = { 
        https://doi.org/10.1287/mnsc.17.4.B141
    
},
eprint = { 
        https://doi.org/10.1287/mnsc.17.4.B141
    
}
}

@Inbook{pearsoncorrelation,
editor="Kirch, Wilhelm",
title="Pearson's Correlation Coefficient",
bookTitle="Encyclopedia of Public Health",
year="2008",
publisher="Springer Netherlands",
address="Dordrecht",
pages="1090--1091",
isbn="978-1-4020-5614-7",
doi="10.1007/978-1-4020-5614-7_2569",
url="https://doi.org/10.1007/978-1-4020-5614-7_2569"
}

@inproceedings{collaborativefiltering,
 author = {Sarwar, Badrul and Karypis, George and Konstan, Joseph and Riedl, John},
 title = {Item-based Collaborative Filtering Recommendation Algorithms},
 booktitle = {Proceedings of the 10th International Conference on World Wide Web},
 series = {WWW '01},
 year = {2001},
 isbn = {1-58113-348-0},
 location = {Hong Kong, Hong Kong},
 pages = {285--295},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/371920.372071},
 doi = {10.1145/371920.372071},
 acmid = {372071},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@incollection{collaborativefiltering2,
 author = {Schafer, J. Ben and Frankowski, Dan and Herlocker, Jon and Sen, Shilad},
 title = {Collaborative Filtering Recommender Systems},
 booktitle = {The Adaptive Web},
 editor = {Brusilovsky, Peter and Kobsa, Alfred and Nejdl, Wolfgang},
 year = {2007},
 isbn = {978-3-540-72078-2},
 pages = {291--324},
 numpages = {34},
 url = {http://dl.acm.org/citation.cfm?id=1768197.1768208},
 acmid = {1768208},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 
 

@book{carttrees,
  title={Classification and Regression Trees},
  author={Breiman, L.},
  isbn={9781351460491},
  url={https://books.google.es/books?id=MGlQDwAAQBAJ},
  year={2017},
  publisher={CRC Press}
}


@book{formalconceptanalysis,
  title={Formal concept analysis: mathematical foundations},
  author={Ganter, Bernhard and Wille, Rudolf},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@book{eclap,
  author={{The European Commission}},
  title={European Collected Library of Artistic Performance},
  year={2013},
  publisher={The European Commission},
  url={https://cordis.europa.eu/project/rcn/191718/factsheet/en},
}

@inproceedings{recommendationkge1,
 author = {Zhang, Fuzheng and Yuan, Nicholas Jing and Lian, Defu and Xie, Xing and Ma, Wei-Ying},
 title = {Collaborative Knowledge Base Embedding for Recommender Systems},
 booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {353--362},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939673},
 doi = {10.1145/2939672.2939673},
 acmid = {2939673},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {collaborative joint learning, knowledge base embedding, recommender systems},
}

@inproceedings{recommendationkge2,
 author = {Sun, Zhu and Yang, Jie and Zhang, Jie and Bozzon, Alessandro and Huang, Long-Kai and Xu, Chi},
 title = {Recurrent Knowledge Graph Embedding for Effective Recommendation},
 booktitle = {Proceedings of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 location = {Vancouver, British Columbia, Canada},
 pages = {297--305},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3240323.3240361},
 doi = {10.1145/3240323.3240361},
 acmid = {3240361},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {attention mechanism, knowledge graph, recurrent neural network, semantic representation},
} 

@Article{siimobility-journal,
AUTHOR = {Badii, Claudio and Bellini, Pierfrancesco and Difino, Angelo and Nesi, Paolo},
TITLE = {Sii-Mobility: An IoT/IoE Architecture to Enhance Smart City Mobility and Transportation Services},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {1},
URL = {http://www.mdpi.com/1424-8220/19/1/1},
ISSN = {1424-8220},
ABSTRACT = {The new Internet of Things/Everything (IoT/IoE) paradigm and architecture allows one to rethink the way Smart City infrastructures are designed and managed, but on the other hand, a number of problems have to be solved. In terms of mobility the cities that embrace the sensoring era can take advantage of this disruptive technology to improve the quality of life of their citizens, also thanks to the rationalization in the use of their resources. In Sii-Mobility, a national smart city project on mobility and transportation, a flexible platform has been designed and here, in this paper, is presented. It permits one to set up heterogeneous and complex scenarios that integrate sensors/actuators as IoT/IoE in an overall Big Data, Machine Learning and Data Analytics scenario. A detailed and complex case-study has been presented to validate the solution in the context of a system that dynamically reverse the traveling direction of a road segment, with all the safety conditions in place. This case study composes several building blocks of the IoT platform, which demonstrate that a flexible and dynamic set-up is possible, supporting security, safety, local, cloud and mixed solutions.},
DOI = {10.3390/s19010001}
}


@article{questionanswering,
  author    = {Antoine Bordes and
               Sumit Chopra and
               Jason Weston},
  title     = {Question Answering with Subgraph Embeddings},
  journal   = {CoRR},
  volume    = {abs/1406.3676},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.3676},
  archivePrefix = {arXiv},
  eprint    = {1406.3676},
  timestamp = {Mon, 13 Aug 2018 16:46:20 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BordesCW14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@INPROCEEDINGS{ripper,
    author = {William W. Cohen},
    title = {Fast Effective Rule Induction},
    booktitle = {In Proceedings of the Twelfth International Conference on Machine Learning},
    year = {1995},
    pages = {115--123},
    publisher = {Morgan Kaufmann}
}
@book{c45tree,
 author = {Quinlan, J. Ross},
 title = {C4.5: Programs for Machine Learning},
 year = {1993},
 isbn = {1558602402},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@article{mebn,
  title={MEBN: A language for first-order Bayesian knowledge bases},
  author={Laskey, Kathryn Blackmond},
  journal={Artificial intelligence},
  volume={172},
  number={2-3},
  pages={140--178},
  year={2008},
  publisher={Elsevier}
}

@article{randomforest,
 author = {Breiman, Leo},
 title = {Random Forests},
 journal = {Machine Learning},
 issue_date = {October 1 2001},
 volume = {45},
 number = {1},
 month = {10},
 year = {2001},
 issn = {0885-6125},
 pages = {5--32},
 numpages = {28},
 url = {https://doi.org/10.1023/A:1010933404324},
 doi = {10.1023/A:1010933404324},
 acmid = {570182},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {classification, ensemble, regression},
} 

@article{bayesiannetwork,
 author = {Friedman, Nir and Geiger, Dan and Goldszmidt, Moises},
 title = {Bayesian Network Classifiers},
 journal = {Machine Learning},
 issue_date = {Nov./Dec. 1997},
 volume = {29},
 number = {2-3},
 month = {11},
 year = {1997},
 issn = {0885-6125},
 pages = {131--163},
 numpages = {33},
 url = {https://doi.org/10.1023/A:1007465528199},
 doi = {10.1023/A:1007465528199},
 acmid = {274161},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Bayesian networks, classification},
} 

@incollection{transe,
title = {Translating Embeddings for Modeling Multi-relational Data},
author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {2787--2795},
year = {2013},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf}
}




@inproceedings{rescal,
 author = {Nickel, Maximilian and Tresp, Volker and Kriegel, Hans-Peter},
 title = {A Three-way Model for Collective Learning on Multi-relational Data},
 booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
 series = {ICML'11},
 year = {2011},
 isbn = {978-1-4503-0619-5},
 location = {Bellevue, Washington, USA},
 pages = {809--816},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=3104482.3104584},
 acmid = {3104584},
 publisher = {Omnipress},
 address = {USA},
} 


 
@article{NickelMTG15,
  author    = {Maximilian Nickel and
               Kevin Murphy and
               Volker Tresp and
               Evgeniy Gabrilovich},
  title     = {A Review of Relational Machine Learning for Knowledge Graphs},
  journal   = {Proceedings of the {IEEE}},
  volume    = {104},
  number    = {1},
  pages     = {11--33},
  year      = {2016},
  url       = {https://doi.org/10.1109/JPROC.2015.2483592},
  doi       = {10.1109/JPROC.2015.2483592},
  timestamp = {Wed, 14 Nov 2018 10:42:35 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/pieee/Nickel0TG16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{WangMWG17,
  added-at = {2018-07-04T00:00:00.000+0200},
  author = {Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},
  biburl = {https://www.bibsonomy.org/bibtex/263a91f10c97e47a155696dc3813ac74f/dblp},
  ee = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2017.2754499},
  interhash = {e99b558eceaf9644001d1d3980d2fa8e},
  intrahash = {63a91f10c97e47a155696dc3813ac74f},
  journal = {IEEE Trans. Knowl. Data Eng.},
  keywords = {dblp},
  number = 12,
  pages = {2724-2743},
  timestamp = {2018-07-05T11:36:12.000+0200},
  title = {Knowledge Graph Embedding: A Survey of Approaches and Applications.},
  url = {http://dblp.uni-trier.de/db/journals/tkde/tkde29.html#WangMWG17},
  volume = 29,
  year = 2017
}


 

@inproceedings{ntn,
 author = {Socher, Richard and Chen, Danqi and Manning, Christopher D. and Ng, Andrew Y.},
 title = {Reasoning with Neural Tensor Networks for Knowledge Base Completion},
 booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1},
 series = {NIPS'13},
 year = {2013},
 location = {Lake Tahoe, Nevada},
 pages = {926--934},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999611.2999715},
 acmid = {2999715},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 


@article{ANAND2018795,
title = "Governance and economics of smart cities: opportunities and challenges",
journal = "Telecommunications Policy",
volume = "42",
number = "10",
pages = "795 - 799",
year = "2018",
note = "Smart Cities: Governance and Economics",
issn = "0308-5961",
doi = "https://doi.org/10.1016/j.telpol.2018.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0308596118303483",
author = "P.B. Anand and Julio Navío-Marco",
keywords = "Smart cities, Governance, Economics, Smart governance, Financing",
abstract = "Summary
This editorial introduction to this special issue provides an overview and a conceptual framework of governance and economics of smart cities. We begin with a discussion of the background to smart cities and then it focuses on the key challenges for consideration in smart city economics. Here it is argued that there are four dimensions to smart city economics: the first is regarding the scale of global market for smart cities; the second issue concerns data to be used for smart city projects; the third concerns market competition and structure and the fourth concerns the impact on local economy. Likewise, smart city governance framework has to be considered a layered and multi-level concept focusing on issues of transparency and accountability to the citizens."
}

 
@INPROCEEDINGS{reviewontiot, 
author={I. {Szilagyi} and P. {Wira}}, 
booktitle={IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society}, 
title={Ontologies and Semantic Web for the Internet of Things - a survey}, 
year={2016}, 
volume={}, 
number={}, 
pages={6949-6954}, 
keywords={data integration;Internet of Things;ontologies (artificial intelligence);open systems;semantic Web;ontologies;Internet of Things;data integration;interoperability;IoT systems;Semantic Web Stack;semantic web;internet of things;ontology;schema IoT;OWL}, 
doi={10.1109/IECON.2016.7793744}, 
ISSN={}, 
month={Oct},}


@inproceedings{Preuveneers2004TowardsAE,
  title={Towards an Extensible Context Ontology for Ambient Intelligence},
  author={Davy Preuveneers and Jan Van den Bergh and Dennis Wagelaar and Andy Georges and Peter Rigole and Tim Clerckx and Yolande Berbers and Karin Coninx and Viviane Jonckers and Koen De Bosschere},
  booktitle={EUSAI},
  year={2004}
}

 

@inproceedings{kgeconv,
  author    = {Dai Quoc Nguyen and
               Tu Dinh Nguyen and
               Dat Quoc Nguyen and
               Dinh Q. Phung},
  title     = {A Novel Embedding Model for Knowledge Base Completion Based on Convolutional
               Neural Network},
  booktitle = {{NAACL-HLT} {(2)}},
  pages     = {327--333},
  publisher = {Association for Computational Linguistics},
  year      = {2018}
}

@Article{augustoetal,
author="Augusto, Juan C.
and Callaghan, Vic
and Cook, Diane
and Kameas, Achilles
and Satoh, Ichiro",
title="``Intelligent Environments: a manifesto''",
journal="Human-centric Computing and Information Sciences",
year="2013",
month="Jun",
day="15",
volume="3",
number="1",
pages="12",
abstract="We explain basic features of an emerging area called Intelligent Environments. We give a short overview on how it has developed, what is the current state of the art and what are the challenges laying ahead. The aim of the article is to make aware the Computer Science community of this new development, the differences with previous dominant paradigms and the opportunities that this area offers to the scientific community and society.",
issn="2192-1962",
doi="10.1186/2192-1962-3-12",
url="https://doi.org/10.1186/2192-1962-3-12"
}

@article{AmItaxonomy,
author = {Ahmed, Ejaz and Yaqoob, Ibrar and Gani, Abdullah and Imran, Muhammad and Guizani, Mohsen},
year = {2016},
month = {10},
pages = {},
title = {Internet of Things based Smart Environments: State-of-the-art, Taxonomy, and Open Research Challenges},
volume = {23},
journal = {IEEE Wireless Communications},
doi = {10.1109/MWC.2016.7721736}
}

@inproceedings{transe,
  title={Translating embeddings for modeling multi-relational data},
  author={Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
  booktitle={Advances in Neural Information Processing Systems 26},
  pages={2787--2795},
  year={2013}
}

@inproceedings{Bollacker:2008:FCC:1376616.1376746,
 author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
 title = {Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge},
 booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD},
 year = {2008},
 isbn = {978-1-60558-102-6},
 location = {Vancouver, Canada},
 pages = {1247--1250},
 numpages = {4},
 acmid = {1376746},
 keywords = {collaborative systems, semantic network, tuple store},
}% url = {http://doi.acm.org/10.1145/1376616.1376746},
%doi = {10.1145/1376616.1376746},
%publisher = {ACM},  address = {New York, NY, USA},

@techreport{noy2001ontology,
  title={Ontology development 101{: A} guide to creating your first ontology},
  author={Noy, Natalya F and McGuinness, Deborah L},
  year={2001},
  institution={Stanford Knowledge Systems Laboratory KSL-01-05 and Stanford Medical Informatics SMI-2001-0880, Stanford, CA},
}

@inproceedings{transr,
  title={Learning entity and relation embeddings for knowledge graph completion},
  author={Lin, Yankai and Liu, Zhiyuan and Sun, Maosong and Liu, Yang and Zhu, Xuan},
  booktitle={Proceedings of the 29th AAAI Conference on Artificial Intelligence},
  year={2015}
}

 @InProceedings{analogy, title = {Analogical Inference for Multi-relational Embeddings}, author = {Hanxiao Liu and Yuexin Wu and Yiming Yang}, pages = {2168--2178}, year = {2017}, editor = {Doina Precup and Yee Whye Teh}, volume = {70}, booktitle = {Proceedings of Machine Learning Research} } 
 
@incollection{simple,
title = {SimplE Embedding for Link Prediction in Knowledge Graphs},
author = {Kazemi, Seyed Mehran and Poole, David},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {4284--4295},
year = {2018},
}
%url = {http://papers.nips.cc/paper/7682-simple-embedding-for-link-prediction-in-knowledge-graphs.pdf}
%editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
%publisher = {Curran Associates, Inc.}

@article{fasttext1,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  year={2017},
  issn={2307-387X},
  pages={135--146}
}

@inproceedings{fasttext2,
  title={Advances in Pre-Training Distributed Word Representations},
  author={Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
  booktitle={Proceedings of the International Conference on Language Resources and Evaluation},
  year={2018}
} %(LREC 2018)

@inproceedings{elmo,
  author={Peters, Matthew E. and  Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  title={Deep contextualized word representations},
  booktitle={Proceedings of the North American Chapter of the Association for Computational Linguistics},
  year={2018}
}


@inproceedings{wangetal,
 author = {Wang, Quan and Wang, Bin and Guo, Li},
 title = {Knowledge Base Completion Using Embeddings and Rules},
 booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
 year = {2015},
 isbn = {978-1-57735-738-4},
 location = {Buenos Aires, Argentina},
 pages = {1859--1865},
 numpages = {7},
 acmid = {2832507},
} % url = {http://dl.acm.org/citation.cfm?id=2832415.2832507},

@inproceedings{guo2016jointly,
  title={Jointly embedding knowledge graphs and logical rules},
  author={Guo, Shu and Wang, Quan and Wang, Lihong and Wang, Bin and Guo, Li},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={192--202},
  year={2016}
}


@article{pengweietal,
  author    = {Pengwei Wang and
               Dejing Dou and
               Fangzhao Wu and
               Nisansa de Silva and
               Lianwen Jin},
  title     = {Logic Rules Powered Knowledge Graph Embedding},
  journal   = {CoRR},
  volume    = {abs/1903.03772},
  year      = {2019},
  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}%  url       = {http://arxiv.org/abs/1903.03772},
%  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-03772},
%  archivePrefix = {arXiv},
%eprint    = {1903.03772},

@article{bert,
  title={{BERT: Pre-training} of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year={2018}, 
journal   = {CoRR},
  volume    = {abs/1810.04805},
}

@inproceedings{transd,
  title={Knowledge graph embedding via dynamic mapping matrix},
  author={Ji, Guoliang and He, Shizhu and Xu, Liheng and Liu, Kang and Zhao, Jun},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing},
  pages={687--696},
  year={2015}
} %(Volume 1: Long Papers)},
%volume={1},

@inproceedings{rescal,
  title={A Three-Way Model for Collective Learning on Multi-Relational Data.},
  author={Nickel, Maximilian and Tresp, Volker and Kriegel, Hans-Peter},
  booktitle={Proceedings of the 28th International Conference on Machine Learning},
  pages={809--816},
  year={2011}
} %volume={11},

@inproceedings{distmult,
  author = {Yang, Bishan and Yih, Scott Wen-tau and He, Xiaodong and Gao, Jianfeng and Deng, Li},
    title = {Embedding Entities and Relations for Learning and Inference in Knowledge Bases},
    booktitle = {Proceedings of the International Conference on Learning Representations 2015},
    year = {2015},
    month = {May},
    
}

@inproceedings{complex,
  title={Complex embeddings for simple link prediction},
  author={Trouillon, Th{\'e}o and Welbl, Johannes and Riedel, Sebastian and Gaussier, {\'E}ric and Bouchard, Guillaume},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  pages={2071--2080},
  year={2016}
}

@inproceedings{neuraltensornetwork,
  title={Reasoning with neural tensor networks for knowledge base completion},
  author={Socher, Richard and Chen, Danqi and Manning, Christopher D and Ng, Andrew},
  booktitle={Advances in Neural Information Processing Systems},
  pages={926--934},
  year={2013}
}



@inproceedings{word2vec,
  author    = {Tomas Mikolov and
               Kai Chen and
               Greg Corrado and
               Jeffrey Dean},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  booktitle = {1st International Conference on Learning Representations, Workshop Track Proceedings},
  year      = {2013},
}



@inproceedings{dim_reduction,
  title = "Effective Dimensionality Reduction for Word Embeddings",
    author = "Raunak, Vikas  and
      Gupta, Vivek  and
      Metze, Florian",
    booktitle = "Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)",
    month = aug,
    year = "2019",
    pages = "235--243",
}%  url       = {http://arxiv.org/abs/1708.03629},
%  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-03629},
%  archivePrefix = {arXiv},
%eprint    = {1708.03629},



@ARTICLE{Miller95wordnet:a,
    author = {George A. Miller},
    title = {{WordNet: A} Lexical Database for {E}nglish},
    journal = {Communications of the ACM},
    year = {1995},
    volume = {38},
    pages = {39--41}
}

@misc{Wn_ont,
  title = {WordNet RDF/OWL Files},
  howpublished = {\url{https://www.w3.org/2006/03/wn/wn20/}},
  note = {Last Accessed: 2019-05-21}
}
@misc{DB_ont,
  author = {Resource},
  title = {{DBpedia Ontology}},
  howpublished = {\url{https://wiki.dbpedia.org/services-resources/ontology}},
  note = {Last Accessed: 2019-05-21}, year = {2019},
}

@misc{GKG_ont,
    author = {Resource},
  title = {{Google Knowledge Graph} Search},
  howpublished = {\url{https://developers.google.com/knowledge-graph/}},
  note = {Last Accessed: 2019-05-21}, year = {2019},
}

@misc{GoogleNewsMethod,
    author = {Resource},
  title = {{Word2Vec} model trained over the {GoogleNews} dataset},
  howpublished = {\url{https://code.google.com/archive/p/word2vec/}},
  note = {Last Accessed: 2019-05-21}, year = {2019},
}


@article{paulheim2017knowledge,
  added-at = {2017-12-16T10:38:39.000+0100},
  author = {Paulheim, Heiko},
  description = {https://scholar.googleusercontent.com/scholar.bib?q=info:rRDKBM4v_o4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWjTr5I9MM9FPDCW4nTZKpSPRGRVkvDWl&scisf=4&ct=citation&cd=-1&hl=de&scfhb=1},
  interhash = {cdf7f890166be5fb798cdcf100110138},
  intrahash = {162302e3d7692d550c88462476fa0604},
  journal = {Semantic Web},
  keywords = {graph knowledge refinement},
  number = 3,
  pages = {489--508},
  publisher = {IOS Press},
  timestamp = {2017-12-16T10:38:39.000+0100},
  title = {Knowledge graph refinement: A survey of approaches and evaluation methods},
  volume = 8,
  year = 2017
}%  biburl = {https://www.bibsonomy.org/bibtex/2162302e3d7692d550c88462476fa0604/thoni},

@inproceedings{hamaguchi_etal,
	title = {Knowledge Transfer for Out-of-Knowledge-Base Entities: {A} Graph Neural Network Approach},
	isbn = {978-0-9992411-0-3},
	shorttitle = {Knowledge {Transfer} for {Out}-of-{Knowledge}-{Base} {Entities}},
	abstract = {Knowledge base completion (KBC) aims to predict missing information in a knowledge base. In this paper, we address the out-of-knowledge-base (OOKB) entity problem in KBC: how to answer queries concerning test entities not observed at training time. Existing embedding-based KBC models assume that all test entities are available at training time, making it unclear how to obtain embeddings for new entities without costly retraining. To solve the OOKB entity problem without retraining, we use graph neural networks (Graph-NNs) to compute the embeddings of OOKB entities, exploiting the limited auxiliary knowledge provided at test time. The experimental results show the effectiveness of our proposed model in the OOKB setting. Additionally, in the standard KBC setting in which OOKB entities are not involved, our model achieves state-of-the-art performance on the WordNet dataset.},
	language = {en},
	urldate = {2020-05-14},
	booktitle = {Proceedings of the 26th {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Hamaguchi, Takuo and Oiwa, Hidekazu and Shimbo, Masashi and Matsumoto, Yuji},
	month = aug,
	year = {2017},
	pages = {1802--1808},
}%address = {Melbourne, Australia},url = {https://www.ijcai.org/proceedings/2017/250},doi = {10.24963/ijcai.2017/250},	publisher = {IJCAI},

@article{Patrick,
  title = "Ontology Reasoning with Deep Neural Networks",
  author = "Patrick Hohenecker and Thomas Lukasiewicz",
  year = "2020",
  journal = "Journal of Artificial Intelligence Research",
  month = "July",
  pages = "503--540", 
  volume = "68",
} %url = "https://doi.org/10.1613/jair.1.11661",

@article{Patrick02,
  author    = {Patrick Hohenecker and
               Thomas Lukasiewicz},
  title     = {Ontology Reasoning with Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1808.07980},
  year      = {2018}
}

@article{dkge,
	title = {Efficiently Embedding Dynamic Knowledge Graphs},
	abstract = {Knowledge graph (KG) embedding encodes the entities and relations from a KG into low-dimensional vector spaces to support various applications such as KG completion, question answering, and recommender systems. In real world, knowledge graphs (KGs) are dynamic and evolve over time with addition or deletion of triples. However, most existing models focus on embedding static KGs while neglecting dynamics. To adapt to the changes in a KG, these models need to be re-trained on the whole KG with a high time cost. In this paper, to tackle the aforementioned problem, we propose a new context-aware Dynamic Knowledge Graph Embedding (DKGE) method which supports the embedding learning in an online fashion. DKGE introduces two different representations (i.e., knowledge embedding and contextual element embedding) for each entity and each relation, in the joint modeling of entities and relations as well as their contexts, by employing two attentive graph convolutional networks, a gate strategy, and translation operations. This effectively helps limit the impacts of a KG update in certain regions, not in the entire graph, so that DKGE can rapidly acquire the updated KG embedding by a proposed online learning algorithm. Furthermore, DKGE can also learn KG embedding from scratch. Experiments on the tasks of link prediction and question answering in a dynamic environment demonstrate the effectiveness and efficiency of DKGE.},
	urldate = {2020-05-14},
	journal = {CoRR},
	author = {Wu, Tianxing and Khan, Arijit and Gao, Huan and Li, Cheng},
	month = oct,
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases},
	volume={abs/1910.06708}
} %url = {http://arxiv.org/abs/1910.06708},

@inproceedings{shah_open-world_2019,
	title = {An Open-World Extension to Knowledge Graph Completion Models},
	issn = {2374-3468, 2159-5399},
	abstract = {We present a novel extension to embedding-based knowledge graph completion models which enables them to perform open-world link prediction, i.e. to predict facts for entities unseen in training based on their textual description. Our model combines a regular link prediction model learned from a knowledge graph with word embeddings learned from a textual corpus. After training both independently, we learn a transformation to map the embeddings of an entity's name and description to the graph-based embedding space. In experiments on several datasets including FB20k, DBPedia50k and our new dataset FB15k-237-OWE, we demonstrate competitive results. Particularly, our approach exploits the full knowledge graph structure even when textual descriptions are scarce, does not require a joint training on graph and text, and can be applied to any embedding-based link prediction model, such as TransE, ComplEx and DistMult.},
	booktitle = {Proceedings of the 33rd AAAI Conference on Artificial Intelligence},
	author = {Shah, Haseeb and Villmow, Johannes and Ulges, Adrian and Schwanecke, Ulrich and Shafait, Faisal},
	month = jul,
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	pages = {3044--3051},
}	%url = {http://arxiv.org/abs/1906.08382},
	%doi = {10.1609/aaai.v33i01.33013044},
	%note = {arXiv: 1906.08382},volume = {33},


@inproceedings{putranse,
	title = {Non-Parametric Estimation of Multiple Embeddings for Link Prediction on Dynamic Knowledge Graphs},
	author    = {Yi Tay and
               Anh Tuan Luu and
               Siu Cheung Hui},
  editor    = {Satinder P. Singh and
               Shaul Markovitch},
  title     = {Non-Parametric Estimation of Multiple Embeddings for Link Prediction
               on Dynamic Knowledge Graphs},
  booktitle = {Proceedings of the 31st {AAAI} Conference on Artificial Intelligence},
  pages     = {1243--1249},
  year      = {2017},
}

@article{zhang_knowledge_2020,
	title = {Knowledge graphs completion via probabilistic reasoning},
	volume = {521},
	issn = {0020-0255},
	abstract = {Constructing large-scale knowledge base has encountered a bottleneck because of the limitation of natural language processing. Many approaches have been put forward to infer new facts based on existing knowledge. Graph feature models mine rule-like patterns from a knowledge base and use them to predict missing edges. These models take account of the graph structure information and they can explain the existence of a fact reasonably. Existing models only describe local interaction between entities, but how to model co-relationships among facts globally is a tough problem. In this paper, we develop an efficient model which uses association rules to make inferences. First, we use a rule mining model to detect simple association rules and use them to produce large amounts of evidence. Second, based on all the produced evidence and the connections among them, we construct a factor graph which represents the inference space. Then, we develop an EM inference model, wherein the E-step we use Belief Propagation to calculate the marginal distribution of candidate edges and, in the M-step we propose a Generalized Iterative Proportional Fitting algorithm to re-learn the confidence of soft rules. Experiments show that our approach outperforms state-of-the-art approaches in knowledge base completion (KBC) tasks.},
	language = {en},
	urldate = {2020-06-23},
	journal = {Information Sciences},
	author = {Zhang, Richong and Mao, Yongyi and Zhao, Weihua},
	month = jun,
	year = {2020},
	keywords = {Knowledge graph completion, knowledge graph reasoning, Rule-based inference},
	pages = {144--159},
}	%url = {http://www.sciencedirect.com/science/article/pii/S0020025520300918},
	%doi = {10.1016/j.ins.2020.02.016},



@Inbook{Reiter1978,
author="Reiter, Raymond",
editor="Gallaire, Herv{\'e}
and Minker, Jack",
title="On Closed World Data Bases",
bookTitle="Logic and Data Bases",
year="1978",
publisher="Springer US",
address="Boston, MA",
pages="55--76",
abstract="Deductive question-answering systems generally evaluate queries under one of two possible assumptions which we in this paper refer to as the open and closed world assumptions. The open world assumption corresponds to the usual first order approach to query evaluation: Given a data base DB and a query Q, the only answers to Q are those which obtain from proofs of Q given DB as hypotheses. Under the closed world assumption, certain answers are admitted as a result of failure to find a proof. More specifically, if no proof of a positive ground literal exists, then the negation of that literal is assumed true.",
isbn="978-1-4684-3384-5",
}%doi="10.1007/978-1-4684-3384-5_3",
%url="https://doi.org/10.1007/978-1-4684-3384-5_3"

@article{adagrad,
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
year = {2011},
issue_date = {2/1/2011},
publisher = {JMLR.org},
volume = {12},
number = {null},
issn = {1532-4435},
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
journal = {Journal of Machine Learning Research},
month = jul,
pages = {2121--2159},
numpages = {39}
}


@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, 
                Conference Track Proceedings},
  year      = {2015},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}%San Diego, CA, USA, May 7-9, 2015, url       = {http://arxiv.org/abs/1412.6980},editor    = {Yoshua Bengio and   Yann LeCun},%{ICLR} 2015,

@inproceedings{sun2018rotate,
  author    = {Zhiqing Sun and
               Zhi{-}Hong Deng and
               Jian{-}Yun Nie and
               Jian Tang},
  title     = {{RotatE: K}nowledge Graph Embedding by Relational Rotation in Complex
               Space},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations},
  year      = {2019},
}

@inproceedings{crosse,
author = {Zhang, Wen and Paudel, Bibek and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
title = {Interaction Embeddings for Prediction and Explanation in Knowledge Graphs},
year = {2019},
isbn = {9781450359405},
booktitle = {Proceedings of the 12th ACM International Conference on Web Search and Data Mining},
pages = {96--104},
numpages = {9},
keywords = {explanation, knowledge graph embedding, crossover interactions, link prediction},
}%url = {https://doi.org/10.1145/3289600.3291014},
%doi = {10.1145/3289600.3291014},


@article{TANG2019809,
title = {Knowledge representation learning with entity descriptions, hierarchical types, and textual relations},
journal = {Information Processing \& Management},
volume = {56},
number = {3},
pages = {809--822},
year = {2019},
issn = {0306-4573},
author = {Xing Tang and Ling Chen and Jun Cui and Baogang Wei},
keywords = "Knowledge representation, Multi-source, Textual information",
}%doi = "https://doi.org/10.1016/j.ipm.2019.01.005",
%url = "http://www.sciencedirect.com/science/article/pii/S0306457318303698",




@article{DBLP:journals/corr/abs-1812-08434,
  author    = {Jie Zhou and
               Ganqu Cui and
               Zhengyan Zhang and
               Cheng Yang and
               Zhiyuan Liu and
               Maosong Sun},
               
  title     = {Graph Neural Networks: {A} Review of Methods and Applications},
  journal   = {CoRR},
  volume    = {abs/1812.08434},
  year      = {2019},
  month = {07},
  day= {10},
  version = {v4},
  timestamp = {Wed, 02 Sep 2020 13:29:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-08434.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
} %url       = {http://arxiv.org/abs/1812.08434},archivePrefix = {arXiv}, eprint    = {1812.08434},

@article{arora2020survey,
      title={A Survey on Graph Neural Networks for Knowledge Graph Completion}, 
      author={Siddhant Arora},
      year={2020},
      month={07},
      day={24}, journal   = {CoRR},
  volume    = {abs/2007.12374},
}
 %      primaryClass={cs.CL},
  %     url={https://arxiv.org/abs/2007.12374},
   %    version={v1}
 %eprint={2007.12374},
   %   archivePrefix={arXiv},  

@inproceedings{nathani2019learning,
    title = "Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs",
    author = "Nathani, Deepak  and
      Chauhan, Jatin  and
      Sharma, Charu  and
      Kaul, Manohar",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = "jul",
    year = "2019",
    pages = "4710--4723",
    abstract = "The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity{'}s neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.",
} %address = "Florence, Italy", url = "https://www.aclweb.org/anthology/P19-1466",
   % doi = "10.18653/v1/P19-1466",  publisher = "Association for Computational Linguistics",

@article{zhang2020efficient,
      title={Efficient Probabilistic Logic Reasoning with Graph Neural Networks}, 
      author={Yuyu Zhang and Xinshi Chen and Yuan Yang and Arun Ramamurthy and Bo Li and Yuan Qi and Le Song},
      year={2020},
      month={02},
      day={04},
      journal   = {CoRR},
    volume    = {abs/2001.11850},
      primaryClass={cs.AI},
      version={v2},
}      % url={https://arxiv.org/abs/2001.11850}, archivePrefix={arXiv},

@inproceedings{hake,
  author    = {Zhanqiu Zhang and
               Jianyu Cai and
               Yongdong Zhang and
               Jie Wang},
  title     = {Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction},
  booktitle = {Proceedings of the 34th {AAAI} Conference on Artificial Intelligence},
  pages     = {3065--3072},
  year      = {2020},
}  %url       = {https://aaai.org/ojs/index.php/AAAI/article/view/5701},


@article{DBLP:journals/sensors/Amador-Dominguez19,
  author    = {Elvira Amador{-}Dom{\'{\i}}nguez and
               Emilio Serrano and
               Daniel Manrique and
               Juan F. De Paz},
  title     = {Prediction and Decision-Making in Intelligent Environments Supported
               by Knowledge Graphs, {A} Systematic Review},
  journal   = {Sensors},
  volume    = {19},
  number    = {8},
  pages     = {1774},
  year      = {2019},
  url       = {10.3390/s19081774},
  doi       = {10.3390/s19081774},
}

@article{sarkheyli-hagele_fuzzy_2017,
	title = {Fuzzy {SOM}-based {Case}-{Based} {Reasoning} for individualized situation recognition applied to supervision of human operators},
	volume = {137},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705117303933},
	doi = {10.1016/j.knosys.2017.09.012},
	language = {en},
	urldate = {2020-04-29},
	journal = {Knowledge-Based Systems},
	author = {Sarkheyli-Hägele, Arezoo and Söffker, Dirk},
	month = dec,
	year = {2017},
	keywords = {Case-Based Reasoning, Fuzzy logic, Individualization, Knowledge representation, Learning, Situation recognition},
	pages = {42--53},
}


@article{lupiani_monitoring_2017,
	title = {Monitoring elderly people at home with temporal {Case}-{Based} {Reasoning}},
	volume = {134},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705117303477},
	doi = {10.1016/j.knosys.2017.07.025},
	language = {en},
	urldate = {2020-04-29},
	journal = {Knowledge-Based Systems},
	author = {Lupiani, Eduardo and Juarez, Jose M. and Palma, Jose and Marin, Roque},
	month = {oct},
	year = {2017},
	keywords = {Case-base maintenance, Case-based reasoning, Smart homes},
	pages = {116--134}}
}

@article{qin_towards_2018,
	title = {Towards an ontology-supported case-based reasoning approach for computer-aided tolerance specification},
	volume = {141},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705117305348},
	doi = {10.1016/j.knosys.2017.11.013},
	language = {en},
	urldate = {2020-04-29},
	journal = {Knowledge-Based Systems},
	author = {Qin, Yuchu and Lu, Wenlong and Qi, Qunfen and Liu, Xiaojun and Huang, Meifa and Scott, Paul J and Jiang, Xiangqian},
	month = feb,
	year = {2018},
	keywords = {Case-based reasoning, Computer-aided tolerance specification, Ontology, Similarity measure, Tolerance specification problem, Tolerance specification scheme},
	pages = {129--147},
}

@article{daengdej_using_1999,
	title = {Using statistical models and case-based reasoning in claims prediction: experience from a real-world problem},
	volume = {12},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705199000155},
	doi= {10.1016/S0950-7051(99)00015-5},
	language = {en},
	number = {5},
	urldate = {2020-04-29},
	journal = {Knowledge-Based Systems},
	author = {Daengdej, J. and Lukose, D. and Murison, R.},
	month = oct,
	year = {1999},
	keywords = {Case-based reasoning, Algorithm, Dataset},
	pages = {239--245},
}


@article{bentaiba-lagrid_case-based_2020,
	title = {A case-based reasoning system for supervised classification problems in the medical field},
	volume = {150},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417420301603},
	doi = {10.1016/j.eswa.2020.113335},
	language = {en},
	urldate = {2020-04-30},
	journal = {Expert Systems with Applications},
	author = {Bentaiba-Lagrid, Miled Basma and Bouzar-Benlabiod, Lydia and Rubin, Stuart H. and Bouabana-Tebibel, Thouraya and Hanini, Maria R.},
	month = jul,
	year = {2020},
	keywords = {Case randomization, Case validation, Case-Based Reasoning (CBR), Medical diagnosis, Supervised classification problems},
	pages = {113335},
}

@article{costa_silva_artificial_2020,
	title = {An artificial immune systems approach to {Case}-based {Reasoning} applied to fault detection and diagnosis},
	volume = {140},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417419306244},
	doi = {10.1016/j.eswa.2019.112906},
	language = {en},
	urldate = {2020-05-04},
	journal = {Expert Systems with Applications},
	author = {Costa Silva, Guilherme and Carvalho, Eduardo E. O. and Caminhas, Walmir Matos},
	month = feb,
	year = {2020},
	keywords = {Antibody, Antigen, Artificial immune system, Case-based Reasoning, Direct current motor simulation, Fault detection},
	pages = {112906},
}

@article{waring_automated_2020,
	title = {Automated machine learning: {Review} of the state-of-the-art and opportunities for healthcare},
	volume = {104},
	issn = {0933-3657},
	shorttitle = {Automated machine learning},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365719310437},
	doi = {10.1016/j.artmed.2020.101822},
	language = {en},
	urldate = {2020-05-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Waring, Jonathan and Lindvall, Charlotta and Umeton, Renato},
	month = apr,
	year = {2020},
	keywords = {Automated machine learning, AutoML, Deep learning, Healthcare, Machine learning},
	pages = {101822},
}


@article{torrent-fontbona_case-base_2019,
	title = {Case-base maintenance of a personalised and adaptive {CBR} bolus insulin recommender system for type 1 diabetes},
	volume = {121},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417418308042},
	doi = {10.1016/j.eswa.2018.12.036},
	language = {en},
	urldate = {2020-05-05},
	journal = {Expert Systems with Applications},
	author = {Torrent-Fontbona, Ferran and Massana, Joaquim and López, Beatriz},
	month = may,
	year = {2019},
	keywords = {Attribute weight learning, Case-base maintenance, Case-based reasoning, Diabetes, Insulin recommender system, Patient empowerment},
	pages = {338--346},
}


@article{lamy_explainable_2019,
	title = {Explainable artificial intelligence for breast cancer: {A} visual case-based reasoning approach},
	volume = {94},
	issn = {0933-3657},
	shorttitle = {Explainable artificial intelligence for breast cancer},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365718304846},
	doi = {10.1016/j.artmed.2019.01.001},
	language = {en},
	urldate = {2020-05-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Lamy, Jean-Baptiste and Sekar, Boomadevi and Guezennec, Gilles and Bouaud, Jacques and Séroussi, Brigitte},
	month = mar,
	year = {2019},
	keywords = {Case-based reasoning, Breast cancer, Data-driven decision making, Explainable Artificial Intelligence, Multidimensional Scaling, Visual explanation},
	pages = {42--53},
}


@article{corbat_fusion_2020,
	title = {A fusion method based on {Deep} {Learning} and {Case}-{Based} {Reasoning} which improves the resulting medical image segmentations},
	volume = {147},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417420300269},
	doi = {10.1016/j.eswa.2020.113200},
	language = {en},
	urldate = {2020-05-06},
	journal = {Expert Systems with Applications},
	author = {Corbat, Lisa and Nauval, Mohammad and Henriet, Julien and Lapayre, Jean-Christophe},
	month = {jun},
	year = {2020},
	keywords = {Case-based reasoning, Deep learning, Cancer tumour, Conflict management, Fusion, Segmentation},
	pages = {113200},
}


@article{hoang_learning_2019,
	title = {Learning and recommending treatments using electronic medical records},
	volume = {181},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705119302436},
	doi = {10.1016/j.knosys.2019.05.031},
	language = {en},
	urldate = {2020-05-06},
	journal = {Knowledge-Based Systems},
	author = {Hoang, Khanh Hung and Ho, Tu Bao},
	month = {oct},
	year = {2019},
	keywords = {Electronic medical records, Healthcare mining, Treatment patterns, Treatment recommendation, Treatment regimen},
	pages = {104788},
}


@article{nasiri_knowledge_2019,
	title = {Knowledge representation and management based on an ontological {CBR} system for dementia caregiving},
	volume = {350},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S092523121930551X},
	doi = {10.1016/j.neucom.2019.04.027},
	language = {en},
	urldate = {2020-05-04},
	journal = {Neurocomputing},
	author = {Nasiri, Sara and Zahedi, Golnaz and Kuntz, Simone and Fathi, Madjid},
	month = {jul},
	year = {2019},
	keywords = {Case-based reasoning, Ontology, Caregiving, DePicT Dementia CLASS, Semantic retrieval, WHO ICF codes},
	pages = {181--194},
}



@ARTICLE{med_image_seg_1,
  author={Z. {Gu} and J. {Cheng} and H. {Fu} and K. {Zhou} and H. {Hao} and Y. {Zhao} and T. {Zhang} and S. {Gao} and J. {Liu}},
  journal={IEEE Transactions on Medical Imaging}, 
  title={CE-Net: Context Encoder Network for 2D Medical Image Segmentation}, 
  year={2019},
  volume={38},
  number={10},
  pages={2281-2292},
  doi={10.1109/TMI.2019.2903562}}


@INPROCEEDINGS{med_image_seg_2,
  author={D. {Jha} and P. H. {Smedsrud} and M. A. {Riegler} and D. {Johansen} and T. D. {Lange} and P. {Halvorsen} and H. {D. Johansen}},
  booktitle={2019 IEEE International Symposium on Multimedia (ISM)}, 
  title={ResUNet++: An Advanced Architecture for Medical Image Segmentation}, 
  year={2019},
  volume={},
  number={},
  address={San Diego, CA, USA},
  pages={225-2255},
  doi={10.1109/ISM46123.2019.00049}}


@InProceedings{med_image_seg_3,
author="Jha, Debesh
and Smedsrud, Pia H.
and Riegler, Michael A.
and Halvorsen, P{\aa}l
and de Lange, Thomas
and Johansen, Dag
and Johansen, H{\aa}vard D.",
editor="Ro, Yong Man
and Cheng, Wen-Huang
and Kim, Junmo
and Chu, Wei-Ta
and Cui, Peng
and Choi, Jung-Woo
and Hu, Min-Chun
and De Neve, Wesley",
title="Kvasir-SEG: A Segmented Polyp Dataset",
booktitle="MultiMedia Modeling",
year="2020",
publisher="Springer International Publishing",
address="New York, New York, USA",
pages="451--462",
isbn="978-3-030-37734-2",
doi="10.1007/978-3-030-37734-2_37"
}



@InProceedings{3d_image_1,
author = {Avetisyan, Armen and Dahnert, Manuel and Dai, Angela and Savva, Manolis and Chang, Angel X. and Niessner, Matthias},
title = {Scan2CAD: Learning CAD Model Alignment in RGB-D Scans},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019},
address= {Long Beach, California, USA}
} 



@Article{3d_image_2,
author={Yang, Bo
and Wang, Sen
and Markham, Andrew
and Trigoni, Niki},
title={Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction},
journal={International Journal of Computer Vision},
year={2020},
month={Jan},
day={01},
volume={128},
number={1},
pages={53-73},
issn={1573-1405},
doi={10.1007/s11263-019-01217-w},
url={10.1007/s11263-019-01217-w}
}


 @InProceedings{diagnosis_1,
 title = {Deep EHR: Chronic Disease Prediction Using Medical Notes}, 
 author = {Liu, Jingshu and Zhang, Zachariah and Razavian, Narges}, 
 booktitle = {Proceedings of the 3rd Machine Learning for Healthcare Conference}, 
 pages = {440--464}, year = {2018}, 
 editor = {Finale Doshi-Velez and Jim Fackler and Ken Jung and David Kale and Rajesh Ranganath and Byron Wallace and Jenna Wiens}, 
 volume = {85}, 
 series = {Proceedings of Machine Learning Research}, address = {Palo Alto, California}, month = {17--18 Aug}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v85/liu18b/liu18b.pdf}, url = {http://proceedings.mlr.press/v85/liu18b.html}} 

@article{diagnosis_2,
   title={Disease prediction using graph convolutional networks: Application to Autism Spectrum Disorder and Alzheimer’s disease},
   volume={48},
   ISSN={1361-8415},
   url={http://dx.doi.org/10.1016/j.media.2018.06.001},
   DOI={10.1016/j.media.2018.06.001},
   journal={Medical Image Analysis},
   publisher={Elsevier BV},
   author={Parisot, Sarah and Ktena, Sofia Ira and Ferrante, Enzo and Lee, Matthew and Guerrero, Ricardo and Glocker, Ben and Rueckert, Daniel},
   year={2018},
   month={Aug},
   pages={117–130}
}

@book{kolodner,
author = {Kolodner, Janet},
title = {Case-Based Reasoning},
year = {1993},
isbn = {1558602372},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, California, USA}
}

@book{richter_webber,
author = {Richter, Michael M. and Weber, Rosina O.},
title = {Case-Based Reasoning: A Textbook},
year = {2013},
isbn = {364240166X},
address = {New York City, New York, USA},
publisher = {Springer Publishing Company, Incorporated}
}

 
@article{brown_temporal_2018,
	title = {Temporal case-based reasoning for type 1 diabetes mellitus bolus insulin decision support},
	volume = {85},
	issn = {0933-3657},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365717300428},
	doi = {10.1016/j.artmed.2017.09.007},
	language = {en},
	urldate = {2020-05-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Brown, Daniel and Aldea, Arantza and Harrison, Rachel and Martin, Clare and Bayley, Ian},
	month = apr,
	year = {2018},
	keywords = {Case-based reasoning, Diabetes, Feature selection, Knowledge based systems, Similarity measures, Temporal},
	pages = {28--42},
}

@article{marie_segmentation_2019,
	title = {Segmentation of deformed kidneys and nephroblastoma using {Case}-{Based} {Reasoning} and {Convolutional} {Neural} {Network}},
	volume = {127},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417419301642},
	doi = {10.1016/j.eswa.2019.03.010},
	language = {en},
	urldate = {2020-05-08},
	journal = {Expert Systems with Applications},
	author = {Marie, Florent and Corbat, Lisa and Chaussy, Yann and Delavelle, Thibault and Henriet, Julien and Lapayre, Jean-Christophe},
	month = aug,
	year = {2019},
	keywords = {Case-based reasoning, Deep learning, Convolutional neural networks, Healthcare imaging, Image segmentation, Tumor},
	pages = {282--294}
}

@article{ayed_evidential_2020,
	title = {An evidential integrated method for maintaining case base and vocabulary containers within {CBR} systems},
	volume = {529},
	issn = {0020-0255},
	url = {http://www.sciencedirect.com/science/article/pii/S0020025519310540},
	doi = {10.1016/j.ins.2019.11.009},
	journal = {Information Sciences},
	author = {Ayed, Safa Ben and Elouedi, Zied and Lefevre, Eric},
	year = {2020},
	keywords = {Belief function theory, Case base maintenance, Case-Based reasoning, Machine learning, Uncertainty, Vocabulary maintenance},
	pages = {214 -- 229}
}



@article{mujtaba_clinical_2019,
	title = {Clinical text classification research trends: {Systematic} literature review and open issues},
	volume = {116},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417418306110},
	doi = {10.1016/j.eswa.2018.09.034},
	journal = {Expert Systems with Applications},
	author = {Mujtaba, Ghulam and Shuib, Liyana and Idris, Norisma and Hoo, Wai Lam and Raj, Ram Gopal and Khowaja, Kamran and Shaikh, Khairunisa and Nweke, Henry Friday},
	year = {2019},
	keywords = {Clinical text classification, Feature engineering, Performance metrics, Rule-based text classification, Supervised machine learning},
	pages = {494 -- 520}
}


@article{oliva_classification_2019,
	title = {Classification for {EEG} report generation and epilepsy detection},
	volume = {335},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231219300803},
	doi = {10.1016/j.neucom.2019.01.053},
	journal = {Neurocomputing},
	author = {Oliva, Jefferson Tales and Rosa, João Luís Garcia},
	year = {2019},
	keywords = {Electroencephalogram, Epilepsy, Machine learning, Medical report, Multiclass classification, Signal processing},
	pages = {81 -- 95}
}


@article{baccianella_variable-constraint_2013,
	title = {Variable-constraint classification and quantification of radiology reports under the {ACR} {Index}},
	volume = {40},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417412012936},
	doi = {10.1016/j.eswa.2012.12.052},
	number = {9},
	journal = {Expert Systems with Applications},
	author = {Baccianella, Stefano and Esuli, Andrea and Sebastiani, Fabrizio},
	year = {2013},
	keywords = {Automatic classification, Medical reports, Text classification},
	pages = {3441 -- 3449}
}


@article{negi_novel_2019,
	title = {A novel method for drug-adverse event extraction using machine learning},
	volume = {17},
	issn = {2352-9148},
	url = {http://www.sciencedirect.com/science/article/pii/S2352914819300991},
	doi = {10.1016/j.imu.2019.100190},
	journal = {Informatics in Medicine Unlocked},
	author = {Negi, Kajal and Pavuri, Arun and Patel, Ladle and Jain, Chirag},
	year = {2019},
	keywords = {Machine learning, Natural language processing, Pharmacovigilance, Text analytics},
	pages = {100190}
}


@article{lopez-ubeda_detection_2020,
	title = {Detection of unexpected findings in radiology reports: {A} comparative study of machine learning approaches},
	volume = {160},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417420304711},
	doi = {10.1016/j.eswa.2020.113647},
	year = {2020},
	keywords = {Deep learning, Machine learning, Natural language processing, Spanish radiology reports, Text report classification, Unexpected findings},
	pages = {113647}
}


@article{olsen_clinical_2020,
	title = {Clinical applications of machine learning in the diagnosis, classification, and prediction of heart failure},
	issn = {0002-8703},
	url = {http://www.sciencedirect.com/science/article/pii/S0002870320302155},
	doi = {10.1016/j.ahj.2020.07.009},
	journal = {American Heart Journal},
	author = {Olsen, Cameron R. and Mentz, Robert J. and Anstrom, Kevin J. and Page, David and Patel, Priyesh A.},
	pages = {1-17},
	year = {2020}
}

@article{dudchenko_diagnoses_2019,
	title = {Diagnoses {Detection} in {Short} {Snippets} of {Narrative} {Medical} {Texts}},
	volume = {156},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050919311093},
	doi = {10.1016/j.procs.2019.08.190},
	journal = {Procedia Computer Science},
	author = {Dudchenko, Aleksei and Ganzinger, Matthias and Kopanitsa, Georgy},
	year = {2019},
	keywords = {medical records, natural language processing},
	pages = {150 -- 157}
}


@article{toledo_web_2019,
	title = {Web {System} {Prototype} based on speech recognition to construct medical reports in {Brazilian} {Portuguese}},
	volume = {121},
	issn = {1386-5056},
	url = {http://www.sciencedirect.com/science/article/pii/S1386505618302879},
	doi = {10.1016/j.ijmedinf.2018.10.010},
	journal = {International Journal of Medical Informatics},
	author = {Toledo, Thiago Ferreira de and Lee, Huei Diana and Spolaôr, Newton and Coy, Cláudio Saddy Rodrigues and Wu, Feng Chung},
	year = {2019},
	keywords = {ASR, Computational system, Health informatics, Java Web, Model view control},
	pages = {39 -- 52}
}


@article{donnelly_using_2019,
	title = {Using a {Natural} {Language} {Processing} and {Machine} {Learning} {Algorithm} {Program} to {Analyze} {Inter}-{Radiologist} {Report} {Style} {Variation} and {Compare} {Variation} {Between} {Radiologists} {When} {Using} {Highly} {Structured} {Versus} {More} {Free} {Text} {Reporting}},
	volume = {48},
	issn = {0363-0188},
	url = {http://www.sciencedirect.com/science/article/pii/S0363018818302081},
	doi = {10.1067/j.cpradiol.2018.09.005},
	number = {6},
	journal = {Current Problems in Diagnostic Radiology},
	author = {Donnelly, Lane F. and Grzeszczuk, Robert and Guimaraes, Carolina V. and Zhang, Wei and III, George S. Bisset},
	year = {2019},
	pages = {524 -- 530}
}


@InProceedings{image_surf,
author="Bay, Herbert
and Tuytelaars, Tinne
and Van Gool, Luc",
editor="Leonardis, Ale{\v{s}}
and Bischof, Horst
and Pinz, Axel",
title="SURF: Speeded Up Robust Features",
booktitle="Computer Vision -- ECCV 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg, Germany",
doi="10.1007/11744023_32",
pages="404--417",
isbn="978-3-540-33833-8"
}



@inproceedings{KAZE_images,
author = {Alcantarilla, Pablo Fernandez and Bartoli, Adrien and Davison, Andrew J.},
title = {KAZE Features},
year = {2012},
isbn = {9783642337826},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-33783-3_16},
booktitle = {Proceedings of the 12th European Conference on Computer Vision - Volume Part VI},
pages = {214–227},
numpages = {14},
location = {Florence, Italy},
series = {ECCV'12}
}

@inproceedings{ORB_image,
author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
title = {ORB: An Efficient Alternative to SIFT or SURF},
year = {2011},
isbn = {9781457711015},
publisher = {IEEE Computer Society},
address = {USA},
doi = {10.1109/ICCV.2011.6126544},
booktitle = {Proceedings of the 2011 International Conference on Computer Vision},
pages = {2564–2571},
numpages = {8},
series = {ICCV '11}
}

@incollection{word2vec,
title = {Distributed Representations of Words and Phrases and their Compositionality},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {3111--3119},
year = {2013},
publisher = {Curran Associates, Inc.},
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

 @InProceedings{word_mover_distance, title = {From Word Embeddings To Document Distances}, author = {Matt Kusner and Yu Sun and Nicholas Kolkin and Kilian Weinberger}, pages = {957--966}, year = {2015}, editor = {Francis Bach and David Blei}, volume = {37}, series = {Proceedings of Machine Learning Research}, address = {Lille, France}, month = {07--09 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v37/kusnerb15.pdf}, url = {http://proceedings.mlr.press/v37/kusnerb15.html} } 
 
 @inproceedings{cliner,
  author    = {Willie Boag and
               Elena Sergeeva and
               Saurabh Kulshreshtha and
               Peter Szolovits and
               Anna Rumshisky and
               Tristan Naumann},
  title     = {CliNER 2.0: Accessible and Accurate Clinical Concept Extraction},
  booktitle = {ML4H: Machine Learning for Health Workshop at Advances in Neural Information Processing Systems},
  series = {NIPS '17},
  year = {2017},
  location = {Long Beach, California, USA},
}

@article{biobert,
    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
    title = "{BioBERT: a pre-trained biomedical language representation model for biomedical text mining}",
    journal = {Bioinformatics},
    volume = {36},
    number = {4},
    pages = {1234-1240},
    year = {2019},
    month = {09},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btz682},
    url = {10.1093/bioinformatics/btz682},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/4/1234/32527770/btz682.pdf},
}


@inproceedings{scibert,
    title = "{S}ci{BERT}: A Pretrained Language Model for Scientific Text",
    author = "Beltagy, Iz  and
      Lo, Kyle  and
      Cohan, Arman",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1371",
    doi = "10.18653/v1/D19-1371",
    pages = "3615--3620",
}


@article{overview_cbr,
author = {Aamodt, Agnar and Plaza, Enric},
title = {Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches},
year = {1994},
issue_date = {March 1994},
publisher = {IOS Press},
address = {NLD},
volume = {7},
number = {1},
issn = {0921-7126},
journal = {AI Commun.},
doi={10.3233/AIC-1994-7104},
month = mar,
pages = {39–59},
numpages = {21}
}

@software{spacy2,
  author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
  title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
  year = 2020,
  publisher = {Zenodo},
  doi = {10.5281/zenodo.1212303},
  url = {10.5281/zenodo.1212303}
}

@article{openi,
  title={Design and development of a multimodal biomedical information retrieval system},
  author={Demner-Fushman, Dina and Antani, Sameer and Simpson, Matthew and Thoma, George R},
  journal={Journal of Computing Science and Engineering},
  volume={6},
  doi={10.5626/JCSE.2012.6.2.168},
  number={2},
  pages={168--177},
  year={2012}
}

@article{mimic-cxr,
author={Johnson, Alistair E. W.
and Pollard, Tom J.
and Berkowitz, Seth J.
and Greenbaum, Nathaniel R.
and Lungren, Matthew P.
and Deng, Chih-ying
and Mark, Roger G.
and Horng, Steven},
title={MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports},
journal={Scientific Data},
year={2019},
month={Dec},
day={12},
volume={6},
number={1},
pages={317},
issn={2052-4463},
doi={10.1038/s41597-019-0322-0},
url={https://doi.org/10.1038/s41597-019-0322-0}
}

@ARTICLE{levenshtein,
       author = {{Levenshtein}, V.~I.},
        title = "{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}",
      journal = {Soviet Physics Doklady},
         year = 1966,
        month = feb,
       volume = {10},
        pages = {707},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1966SPhD...10..707L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Tang20191819,
author={Tang, V. and Choy, K.L. and Ho, G.T.S. and Lam, H.Y. and Tsang, Y.P.},
title={An IoMT-based geriatric care management system for achieving smart health in nursing homes},
journal={Industrial Management and Data Systems},
year={2019},
volume={119},
number={8},
pages={1819-1840},
doi={10.1108/IMDS-01-2019-0024},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Forbes2019185,
author={Forbes, G.},
title={Employing multi-modal sensors for personalised smart home health monitoring},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2567},
pages={185-190},
source={Scopus},
}

@ARTICLE{Massie2018249,
author={Massie, S. and Forbes, G. and Craw, S. and Fraser, L. and Hamilton, G.},
title={FITsense: Employing Multi-modal Sensors in Smart Homes to Predict Falls},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11156 LNAI},
pages={249-263},
doi={10.1007/978-3-030-01081-2},
source={Scopus},
}

@article{pradaetal,
author={Prada, J. and Gala, Y. and Sierra, A.L.},
title={COVID-19 Mortality Risk Prediction Using X-Ray Images},
year={2021},
journal={International Journal of Interactive Multimedia and Artificial Intelligence},
volume={6},
number={6},
pages={7-14},
doi={10.9781/ijimai.2021.04.001},
}


@misc{ai4eu_scientific_vision,
  title = {The AI4EU Scientific Vision},
  howpublished = {\url{https://www.ai4eu.eu/ai4eu-scientific-vision}},
  note = {Accessed: 2020-12-21}
}

@misc{ai4eu_project,
title={AI4EU},
howpublished = {\url{https://www.ai4eu.eu/}},
note = {Accessed: 2020-12-21}

}

@misc{raidologist,
title={AI4EU},
howpublished = {\url{https://www.ai4eu.eu/resource/raidologist}},
note = {Accessed: 2020-12-21}

}


@misc{SalesReport,
  title = {Annual Report},
  year = {2017},
  author = {SalesForce},
  note = { Retrieved from \url{https://c1.sfdcstatic.com/content/dam/web/en_us/www/assets/pdf/datasheets/salesforce-research-fourth-annual-state-of-marketing.pdf}. Accessed July 30, 2019}
}

@book{Ferber:1999:MSI:520715,
 author = {Ferber, Jacques},
 title = {Multi-Agent Systems: An Introduction to Distributed Artificial Intelligence},
 year = {1999},
 isbn = {0201360489},
 edition = {1st},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
} 

@article{Gao_2016, 
title={A Context-Aware Mobile User Behavior-Based Neighbor Finding Approach for Preference Profile Construction}, 
volume={16}, 
ISSN={1424-8220}, 
DOI={10.3390/s16081230}, 
journal={Sensors}, 
author={Gao, Qian and Fu, Deqian and Dong, Xiangjun}, year={2016}, pages={1230}}

@article{Kim2013ACB,
author = {Kim, Jee and Gao, Qian and Cho, Young},
year = {2014},
pages = {122-129},
title = {A Context-Awareness Modeling User Profile Construction Method for Personalized Information Retrieval System},
volume = {14},
journal = {International Journal of Fuzzy Logic and Intelligent Systems},
doi = {10.5391/IJFIS.2014.14.2.122}
}

@article{Bhowmick2010OntologyBU,
  title={Ontology Based User Modeling for Personalized Information Access},
  author={Plaban Kumar Bhowmick and Sudeshna Sarkar and Anupam Basu},
  journal={International Journal on Computational Science and Applications},
  year={2010},
  volume={7},
  pages={1-22}
}

@InProceedings{SinghSharma,
author="Singh, Aarti
and Sharma, Anu",
editor="Hoda, M. N.
and Chauhan, Naresh
and Quadri, S. M. K.
and Srivastava, Praveen Ranjan",
title="A Multi-agent Framework for Context-Aware Dynamic User Profiling for Web Personalization",
booktitle="Software Engineering",
year="2019",
publisher="Springer Singapore",
address="Singapore",
pages="1--16",
isbn="978-981-10-8848-3"
}

@article{LI2019287,
title = "Offensive pricing strategies for online platforms",
journal = "International Journal of Production Economics",
volume = "216",
pages = "287 - 304",
year = "2019",
issn = "0925-5273",
doi = "https://doi.org/10.1016/j.ijpe.2019.06.009",
author = "Feng Li and Timon Chih-ting Du and Ying Wei",
keywords = "Offensive pricing strategies, Online platform, Message dissemination, Word-of-mouth marketing",
}

@InProceedings{Duarteetal,
author="Duarte, Duarte
and Ferreira, Hugo Sereno
and Dias, Jo{\~a}o Pedro
and Kokkinogenis, Zafeiris",
title="Towards a Framework for Agent-Based Simulation of User Behaviour in E-Commerce Context",
booktitle="Trends in Cyber-Physical Multi-Agent Systems. The PAAMS Collection - 15th International Conference",
year="2018",
address="Cham",
pages="30--38",
isbn="978-3-319-61578-3"
}

@InProceedings{Changetal,
author="Chang, Cheng-Yen
and Tsai, Chi-Hsuan
and Chu, Ming-Chuan",
editor="Moon, Ilkyeong
and Lee, Gyu M.
and Park, Jinwoo
and Kiritsis, Dimitris
and von Cieminski, Gregor",
title="Construct a Customized Product Service System Utilizing Multi-agent System",
booktitle="Advances in Production Management Systems. Production Management for Data-Driven, Intelligent, Collaborative, and Sustainable Manufacturing",
year="2018",
address="Cham",
pages="193--200",
isbn="978-3-319-99704-9"
}

@INPROCEEDINGS{Dehurietal,
author={S. {Dehuri} and S. {Cho} and A. K. {Jagadev}},
booktitle={2008 International Conference on Information Technology},
title={Honey Bee Behavior: A Multi-agent Approach for Multiple Campaigns Assignment Problem},
year={2008},
volume={},
number={},
pages={24-29},
doi={10.1109/ICIT.2008.14},
}

@article{Zhangetal,
title = "Agent-based simulation of consumer purchase decision-making and the decoy effect",
journal = "Journal of Business Research",
volume = "60",
number = "8",
pages = "912 - 922",
year = "2007",
issn = "0148-2963",
doi = "https://doi.org/10.1016/j.jbusres.2007.02.006",
author = "Tao Zhang and David Zhang",
}

@INPROCEEDINGS{YangandLi,
author={S. {Yang} and L. {Li}},
booktitle={2017 5th International Conference on Enterprise Systems},
title={Personalization in Dynamic Assortment Planning: An Analysis Based on Multi-Agent Simulation Method},
year={2017},
volume={},
number={},
pages={157-162},
doi={10.1109/ES.2017.32},
ISSN={2572-6609},
month={Sep.},}

@INPROCEEDINGS{Ennajietal,
author={F. Z. {Ennaji} and A. {El Fazziki} and H. {El Alaouiel Abdallaoui} and A. {Sadiq} and M. {Sadgal} and D. {Benslimane}},
booktitle={2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA)},
title={Multi-agent framework for social CRM: Extracting and analyzing opinions},
year={2016},
volume={},
number={},
pages={1-8},
doi={10.1109/AICCSA.2016.7945700},
ISSN={2161-5330},
month={Nov},}

@INPROCEEDINGS{Yusofetal,
author={A. {Yusof} and M. A. {Mahmoud} and M. S. {Ahmad}},
booktitle={2016 2nd International Symposium on Agent, Multi-Agent Systems and Robotics (ISAMSR)},
title={A Conceptual Multi-agent Semantic Web Model of a self-adaptive website for intelligent strategic marketing in learning institutions},
year={2016},
volume={},
number={},
pages={133-138},
doi={10.1109/ISAMSR.2016.7810016},
ISSN={},
month={Aug},}

@article{Trifaetal,
title = {Enhancing assessment of Personalized Multi-Agent System through ConvLSTM},
journal = {Procedia Computer Science},
volume = {112},
pages = {249-259},
year = {2017},
note = {Knowledge-Based and Intelligent Information \& Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.08.239},
author = {Amal Trifa and Aroua Hedhili Sbai and Wided Lejouad Chaari},
}

@article{KAZIENKO20072269,
title = "AdROSA—Adaptive personalization of web advertising",
journal = "Information Sciences",
volume = "177",
number = "11",
pages = "2269 - 2295",
year = "2007",
issn = "0020-0255",
doi = "https://doi.org/10.1016/j.ins.2007.01.002",
author = "Przemysław Kazienko and Michał Adamski",
}

@inproceedings{Mohammed2018ImplementingAA,
title={Implementing an Agent-based Multi-Natural Language Anti-Spam Model},
author={Mazin Abed Mohammed and Saraswathy Shamini Gunasekaran and Salama A. Mostafa and Aida Mustafa and Mohd Khanapi Abd Ghani},
booktitle={2018 International Symposium on Agent, Multi-Agent Systems and Robotics (ISAMSR)},
year={2018},
pages={1-5}
}

@inproceedings{He2015DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={770-778}
}

@INPROCEEDINGS{CNNRNN,
author={J. {Wang} and Y. {Yang} and J. {Mao} and Z. {Huang} and C. {Huang} and W. {Xu}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={CNN-RNN: A Unified Framework for Multi-label Image Classification},
year={2016},
volume={},
number={},
pages={2285-2294},
doi={10.1109/CVPR.2016.251},
ISSN={1063-6919}}

@INPROCEEDINGS{HersheyCEGJMPPS16,  
author={Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel P. W. and Gemmeke, Jort F. and Jansen, Aren and Moore, R. Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A. and Seybold, Bryan and Slaney, Malcolm and Weiss, Ron J. and Wilson, Kevin},  
booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   
title={CNN architectures for large-scale audio classification},   
year={2017},  volume={},  number={},  
pages={131-135},  doi={10.1109/ICASSP.2017.7952132}}

@INPROCEEDINGS{speechtotext,  
author={Chiu, Chung-Cheng and Sainath, Tara N. and Wu, Yonghui and Prabhavalkar, Rohit and Nguyen, Patrick and Chen, Zhifeng and Kannan, Anjuli and Weiss, Ron J. and Rao, Kanishka and Gonina, Ekaterina and Jaitly, Navdeep and Li, Bo and Chorowski, Jan and Bacchiani, Michiel},  
booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   
title={State-of-the-Art Speech Recognition with Sequence-to-Sequence Models}, year={2018},  volume={},  number={},  
pages={4774-4778},  
doi={10.1109/ICASSP.2018.8462105}}

@inproceedings{joulin2016bag,
    title = "Bag of Tricks for Efficient Text Classification",
    author = "Joulin, Armand  and
      Grave, Edouard  and
      Bojanowski, Piotr  and
      Mikolov, Tomas",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    pages = "427--431",
}
@article{joulin2016fasttext,
  title={FastText.zip: Compressing text classification models},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\'e}gou, H{\'e}rve and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1612.03651},
  year={2016}
}

@article{MIRONCZUK201836,
title = "A recent overview of the state-of-the-art elements of text classification",
journal = "Expert Systems with Applications",
volume = "106",
pages = "36 - 54",
year = "2018",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2018.03.058",
author = "Marcin Michał Mirończuk and Jarosław Protasiewicz",
}

@article{Alghamdi2015,
title = {A Survey of Topic Modeling in Text Mining},
journal = {International Journal of Advanced Computer Science and Applications},
doi = {10.14569/IJACSA.2015.060121},
year = {2015},
publisher = {The Science and Information Organization},
volume = {6},
number = {1},
author = {Rubayyi Alghamdi and Khalid Alfalqi},
} 



@InProceedings{pmlr-v15-nallapati11a,
  title = 	 {TopicFlow Model: Unsupervised Learning of Topic-specific Influences of Hyperlinked Documents},
  author = 	 {Ramesh Nallapati and Daniel McFarland and Christopher Manning},
  booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {543--551},
  year = 	 {2011},
  volume = 	 {15},
  address = 	 {Fort Lauderdale, FL, USA},
  publisher = 	 {PMLR},
}

@MISC{Neto00documentclustering,
    author = {Joel Larocca Neto and Alexandre D. Santos and Celso A.A. Kaestner and Neto Alexandre and D. Santos and Celso A. A and Kaestner Alex and Alex A. Freitas and Catolica Parana},
    title = {Document Clustering and Text Summarization},
    year = {2000}
}

@article{YOUSEFIAZAR201793,
title = "Text summarization using unsupervised deep learning",
journal = "Expert Systems with Applications",
volume = "68",
pages = "93 - 105",
year = "2017",
issn = "0957-4174",
doi = "https://doi.org/10.1016/j.eswa.2016.10.017",
author = "Mahmood Yousefi-Azar and Len Hamey",
}

@Inbook{Oikonomakou2005,
author="Oikonomakou, Nora
and Vazirgiannis, Michalis",
editor="Maimon, Oded
and Rokach, Lior",
title="A Review of Web Document Clustering Approaches",
bookTitle="Data Mining and Knowledge Discovery Handbook",
year="2005",
publisher="Springer US",
address="Boston, MA",
pages="921--943",
isbn="978-0-387-25465-4",
doi="10.1007/0-387-25465-X_43",
}

@INPROCEEDINGS{Zhangetal2,
author={S. {Zhang} and X. {Zheng} and C. {Hu}},
booktitle={2015 IEEE International Conference on Big Data (Big Data)},
title={A survey of semantic similarity and its application to social network analysis},
year={2015},
volume={},
number={},
pages={2362-2367},
ISSN={},
month={Oct},}

@inproceedings{Rawashdeh2015SimilarityMF,
  title={Similarity Measure for Social Networks - A Brief Survey},
  author={Ahmad Rawashdeh and Anca L. Ralescu},
  booktitle={Modern Artificial Intelligence and Cognitive Sciences Conference},
  year={2015}
}

@article{deepcnns,
author = {Rawat, Waseem and Wang, Zenghui},
title = {Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review},
journal = {Neural Computation},
volume = {29},
number = {9},
pages = {2352-2449},
year = {2017},
}

@INPROCEEDINGS{speechrecognition,
author={A. {Graves} and A. {Mohamed} and G. {Hinton}},
booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
title={Speech recognition with deep recurrent neural networks},
year={2013},
volume={},
number={},
pages={6645-6649},
doi={10.1109/ICASSP.2013.6638947},
ISSN={1520-6149},
month={May},}

@inproceedings{sentimentanalysis,
title = "Document Modeling with Gated Recurrent Neural Network for Sentiment Classification",
author = "Tang, Duyu  and Qin, Bing  and Liu, Ting",
booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
month = "sep",
year = "2015",
address = "Lisbon, Portugal",
doi = "10.18653/v1/D15-1167",
pages = "1422--1432",
}

@book{eudataprotection,
  author={{European Commission}},
  title={COMMUNICATION FROM THE COMMISSION TO THE EUROPEAN PARLIAMENT AND THE COUNCIL},
  subtitle={Data protection rules as a trust-enabler in the EU and beyond –taking stock },
  year={2019},
  publisher={The European Commission},
}

 
@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@article{DBLP:journals/corr/Moody16,
  author    = {Christopher E. Moody},
  title     = {Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec},
  journal   = {CoRR},
  volume    = {abs/1605.02019},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.02019},
  archivePrefix = {arXiv},
  eprint    = {1605.02019},
}

@article{SerranoI16,
  author    = {Emilio Serrano and
               Carlos Angel Iglesias},
  title     = {Validating viral marketing strategies in Twitter via agent-based social
               simulation},
  journal   = {Expert Systems with Applications},
  volume    = {50},
  pages     = {140--150},
  year      = {2016},
  doi       = {10.1016/j.eswa.2015.12.021},
}


@inproceedings{Amador19,
  author    = {Elvira Amador{-}Dom{\'{\i}}nguez and
               Emilio Serrano and
               Juan David Mateos{-}Nobre and
               Alfredo Ayala{-}Mu{\~{n}}oz},
  title     = {An Intelligent and Autoadaptive System of Virtual Identities Based
               on Deep Learning for the Analysis of Online Advertising Networks},
  booktitle = {Highlights of Practical Applications of Survivable Agents and Multi-Agent
               Systems. The {PAAMS} Collection - International Workshops of {PAAMS}
               2019, {\'{A}}vila, Spain, June 26-28, 2019, Proceedings},
  pages     = {302--309},
  year      = {2019},
  doi       = {10.1007/978-3-030-24299-2\_26},
}
@proceedings{DBLP:conf/paams/2019w,
  editor    = {Fernando de la Prieta and
               Alfonso Gonz{\'{a}}lez{-}Briones and
               Pawel Pawlewski and
               Davide Calvaresi and
               Elena del Val and
               Fernando Lopes and
               Vicente Juli{\'{a}}n and
               Eneko Osaba and
               Ramon Sanchez{-}Iborra},
  title     = {Highlights of Practical Applications of Survivable Agents and Multi-Agent
               Systems. The {PAAMS} Collection - International Workshops of {PAAMS}
               2019, {\'{A}}vila, Spain, June 26-28, 2019, Proceedings},
  series    = {Communications in Computer and Information Science},
  volume    = {1047},
  year      = {2019},
  doi       = {10.1007/978-3-030-24299-2},
  isbn      = {978-3-030-24298-5},
}


@article{valverdeCSVB12,
  author    = {Teresa Garc{\'{\i}}a{-}Valverde and
               Francisco Campuzano and
               Emilio Serrano and
               Ana Villa and
               Juan A. Bot{\'{\i}}a},
  title     = {Simulation of human behaviours for the validation of Ambient Intelligence
               services: {A} methodological approach},
  journal   = {Journal of Ambient Intelligence and Smart Environments},
  volume    = {4},
  number    = {3},
  pages     = {163--181},
  year      = {2012},
  url       = {https://doi.org/10.3233/AIS-2012-0147},
  doi       = {10.3233/AIS-2012-0147},
}


@article{Gomaaetal,
title = {Performance Evaluation of Virtual Identity Approaches for Anonymous Communication in Distributed Environments},
journal = {Procedia Computer Science},
volume = {109},
pages = {710-717},
year = {2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.05.382},
author = {Ibrahim Gomaa and Adel M. Said and Emad Abd-Elrahman and Alaa Hamdy and Elsayed M. Saad},

}


@article{Gomaaetal2,
title = {A Novel Virtual Identity Implementation for Anonymous Communication in Cloud Environments},
journal = {Procedia Computer Science},
volume = {63},
pages = {32-39},
year = {2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.309},
author = {Ibrahim A. Gomaa and Emad Abd-Elrahman},
}

@article{JIN20122160,
title = {The virtual malleable self and the virtual identity discrepancy model: Investigative frameworks for virtual possible selves and others in avatar-based identity construction and social interaction},
journal = {Computers in Human Behavior},
volume = {28},
number = {6},
pages = {2160-2168},
year = {2012},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2012.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S0747563212001744},
author = {Seung-A. Annie Jin},

}

@INPROCEEDINGS{Sulaymanetal,  author={Abu Sulayman, Iman I. M. and Ouda, Abdelkader},  booktitle={2020 International Symposium on Networks, Computers and Communications (ISNCC)},   title={Designing Security User Profiles via Anomaly Detection for User Authentication},   year={2020},  volume={},  number={},  pages={1-6},  doi={10.1109/ISNCC49221.2020.9297252}}

@inproceedings{Xuetal,
author = {Xu, Kerui and Yang, Jingxuan and Xu, Jun and Gao, Sheng and Guo, Jun and Wen, Ji-Rong},
title = {Adapting User Preference to Online Feedback in Multi-Round Conversational Recommendation},
year = {2021},
isbn = {9781450382977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437963.3441791},
doi = {10.1145/3437963.3441791},
booktitle = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
pages = {364–372},
numpages = {9},
keywords = {user preference, multi-round conversational recommendation},
location = {Virtual Event, Israel},
series = {WSDM '21}
}

@article{Doniecetal,
title = {Purchase intention-based agent for customer behaviours},
journal = {Information Sciences},
volume = {521},
pages = {380-397},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.02.054},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520301377},
author = {Arnaud Doniec and Stéphane Lecoeuche and René Mandiau and Antoine Sylvain},
keywords = {Agent-based modelling, Customer behaviours, Purchase intention, Stores’ simulation},
}

@article{amadoretalontodl,
  author    = {Elvira Amador{-}Dom{\'{\i}}nguez and
               Emilio Serrano and
               Daniel Manrique and
               Patrick Hohenecker and
               Thomas Lukasiewicz},
  title     = {An ontology-based deep learning approach for triple classification
               with out-of-knowledge-base entities},
  journal   = {Inf. Sci.},
  volume    = {564},
  pages     = {85--102},
  year      = {2021},
  url       = {https://doi.org/10.1016/j.ins.2021.02.018},
  doi       = {10.1016/j.ins.2021.02.018},
  timestamp = {Mon, 17 May 2021 17:04:39 +0200},
  biburl    = {https://dblp.org/rec/journals/isci/Amador-Dominguez21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{boxologyfrank,
  author    = {Frank Van Harmelen and
               Annette Ten Teije},
  title     = {A Boxology of Design Patterns for Hybrid Learning and Reasoning Systems},
  journal   = {CoRR},
  volume    = {abs/1905.12389},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12389},
  eprinttype = {arXiv},
  eprint    = {1905.12389},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-12389.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{transe,
  title={Translating embeddings for modeling multi-relational data},
  author={Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
  booktitle={Advances in Neural Information Processing Systems 26},
  pages={2787--2795},
  year={2013}
}

@inproceedings{Bollacker:2008:FCC:1376616.1376746,
 author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
 title = {Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge},
 booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD},
 year = {2008},
 isbn = {978-1-60558-102-6},
 location = {Vancouver, Canada},
 pages = {1247--1250},
 numpages = {4},
 acmid = {1376746},
 keywords = {collaborative systems, semantic network, tuple store},
}% url = {http://doi.acm.org/10.1145/1376616.1376746},
%doi = {10.1145/1376616.1376746},
%publisher = {ACM},  address = {New York, NY, USA},

@techreport{noy2001ontology,
  title={Ontology development 101{: A} guide to creating your first ontology},
  author={Noy, Natalya F and McGuinness, Deborah L},
  year={2001},
  institution={Stanford Knowledge Systems Laboratory KSL-01-05 and Stanford Medical Informatics SMI-2001-0880, Stanford, CA},
}

@inproceedings{transr,
  title={Learning entity and relation embeddings for knowledge graph completion},
  author={Lin, Yankai and Liu, Zhiyuan and Sun, Maosong and Liu, Yang and Zhu, Xuan},
  booktitle={Proceedings of the 29th AAAI Conference on Artificial Intelligence},
  year={2015}
}

 @InProceedings{analogy, title = {Analogical Inference for Multi-relational Embeddings}, author = {Hanxiao Liu and Yuexin Wu and Yiming Yang}, pages = {2168--2178}, year = {2017}, editor = {Doina Precup and Yee Whye Teh}, volume = {70}, booktitle = {Proceedings of Machine Learning Research} } 
 
@incollection{simple,
title = {SimplE Embedding for Link Prediction in Knowledge Graphs},
author = {Kazemi, Seyed Mehran and Poole, David},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {4284--4295},
year = {2018},
}
%url = {http://papers.nips.cc/paper/7682-simple-embedding-for-link-prediction-in-knowledge-graphs.pdf}
%editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
%publisher = {Curran Associates, Inc.}

@article{fasttext1,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  year={2017},
  issn={2307-387X},
  pages={135--146}
}

@inproceedings{fasttext2,
  title={Advances in Pre-Training Distributed Word Representations},
  author={Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
  booktitle={Proceedings of the International Conference on Language Resources and Evaluation},
  year={2018}
} %(LREC 2018)

@inproceedings{elmo,
  author={Peters, Matthew E. and  Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  title={Deep contextualized word representations},
  booktitle={Proceedings of the North American Chapter of the Association for Computational Linguistics},
  year={2018}
}


@inproceedings{wangetal,
 author = {Wang, Quan and Wang, Bin and Guo, Li},
 title = {Knowledge Base Completion Using Embeddings and Rules},
 booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
 year = {2015},
 isbn = {978-1-57735-738-4},
 location = {Buenos Aires, Argentina},
 pages = {1859--1865},
 numpages = {7},
 acmid = {2832507},
} % url = {http://dl.acm.org/citation.cfm?id=2832415.2832507},

@inproceedings{guo2016jointly,
  title={Jointly embedding knowledge graphs and logical rules},
  author={Guo, Shu and Wang, Quan and Wang, Lihong and Wang, Bin and Guo, Li},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={192--202},
  year={2016}
}


@article{pengweietal,
  author    = {Pengwei Wang and
               Dejing Dou and
               Fangzhao Wu and
               Nisansa de Silva and
               Lianwen Jin},
  title     = {Logic Rules Powered Knowledge Graph Embedding},
  journal   = {CoRR},
  volume    = {abs/1903.03772},
  year      = {2019},
  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}%  url       = {http://arxiv.org/abs/1903.03772},
%  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-03772},
%  archivePrefix = {arXiv},
%eprint    = {1903.03772},

@article{bert,
  title={{BERT: Pre-training} of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year={2018}, 
journal   = {CoRR},
  volume    = {abs/1810.04805},
}

@inproceedings{transd,
  title={Knowledge graph embedding via dynamic mapping matrix},
  author={Ji, Guoliang and He, Shizhu and Xu, Liheng and Liu, Kang and Zhao, Jun},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing},
  pages={687--696},
  year={2015}
} %(Volume 1: Long Papers)},
%volume={1},

@inproceedings{rescal,
  title={A Three-Way Model for Collective Learning on Multi-Relational Data.},
  author={Nickel, Maximilian and Tresp, Volker and Kriegel, Hans-Peter},
  booktitle={Proceedings of the 28th International Conference on Machine Learning},
  pages={809--816},
  year={2011}
} %volume={11},

@inproceedings{distmult,
  author = {Yang, Bishan and Yih, Scott Wen-tau and He, Xiaodong and Gao, Jianfeng and Deng, Li},
    title = {Embedding Entities and Relations for Learning and Inference in Knowledge Bases},
    booktitle = {Proceedings of the International Conference on Learning Representations 2015},
    year = {2015},
    month = {May},
    
}

@inproceedings{complex,
  title={Complex embeddings for simple link prediction},
  author={Trouillon, Th{\'e}o and Welbl, Johannes and Riedel, Sebastian and Gaussier, {\'E}ric and Bouchard, Guillaume},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  pages={2071--2080},
  year={2016}
}

@inproceedings{neuraltensornetwork,
  title={Reasoning with neural tensor networks for knowledge base completion},
  author={Socher, Richard and Chen, Danqi and Manning, Christopher D and Ng, Andrew},
  booktitle={Advances in Neural Information Processing Systems},
  pages={926--934},
  year={2013}
}



@inproceedings{word2vec,
  author    = {Tomas Mikolov and
               Kai Chen and
               Greg Corrado and
               Jeffrey Dean},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  booktitle = {1st International Conference on Learning Representations, Workshop Track Proceedings},
  year      = {2013},
}



@inproceedings{dim_reduction,
  title = "Effective Dimensionality Reduction for Word Embeddings",
    author = "Raunak, Vikas  and
      Gupta, Vivek  and
      Metze, Florian",
    booktitle = "Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)",
    month = aug,
    year = "2019",
    pages = "235--243",
}%  url       = {http://arxiv.org/abs/1708.03629},
%  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-03629},
%  archivePrefix = {arXiv},
%eprint    = {1708.03629},



@ARTICLE{Miller95wordnet:a,
    author = {George A. Miller},
    title = {{WordNet: A} Lexical Database for {E}nglish},
    journal = {Communications of the ACM},
    year = {1995},
    volume = {38},
    pages = {39--41}
}

@misc{Wn_ont,
  title = {WordNet RDF/OWL Files},
  howpublished = {\url{https://www.w3.org/2006/03/wn/wn20/}},
  note = {Last Accessed: 2019-05-21}
}
@misc{DB_ont,
  author = {Resource},
  title = {{DBpedia Ontology}},
  howpublished = {\url{https://wiki.dbpedia.org/services-resources/ontology}},
  note = {Last Accessed: 2019-05-21}, year = {2019},
}

@misc{GKG_ont,
    author = {Resource},
  title = {{Google Knowledge Graph} Search},
  howpublished = {\url{https://developers.google.com/knowledge-graph/}},
  note = {Last Accessed: 2019-05-21}, year = {2019},
}

@misc{GoogleNewsMethod,
    author = {Resource},
  title = {{Word2Vec} model trained over the {GoogleNews} dataset},
  howpublished = {\url{https://code.google.com/archive/p/word2vec/}},
  note = {Last Accessed: 2019-05-21}, year = {2019},
}


@article{paulheim2017knowledge,
  added-at = {2017-12-16T10:38:39.000+0100},
  author = {Paulheim, Heiko},
  description = {https://scholar.googleusercontent.com/scholar.bib?q=info:rRDKBM4v_o4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWjTr5I9MM9FPDCW4nTZKpSPRGRVkvDWl&scisf=4&ct=citation&cd=-1&hl=de&scfhb=1},
  interhash = {cdf7f890166be5fb798cdcf100110138},
  intrahash = {162302e3d7692d550c88462476fa0604},
  journal = {Semantic Web},
  keywords = {graph knowledge refinement},
  number = 3,
  pages = {489--508},
  publisher = {IOS Press},
  timestamp = {2017-12-16T10:38:39.000+0100},
  title = {Knowledge graph refinement: A survey of approaches and evaluation methods},
  volume = 8,
  year = 2017
}%  biburl = {https://www.bibsonomy.org/bibtex/2162302e3d7692d550c88462476fa0604/thoni},

@inproceedings{hamaguchi_etal,
	title = {Knowledge Transfer for Out-of-Knowledge-Base Entities: {A} Graph Neural Network Approach},
	isbn = {978-0-9992411-0-3},
	shorttitle = {Knowledge {Transfer} for {Out}-of-{Knowledge}-{Base} {Entities}},
	abstract = {Knowledge base completion (KBC) aims to predict missing information in a knowledge base. In this paper, we address the out-of-knowledge-base (OOKB) entity problem in KBC: how to answer queries concerning test entities not observed at training time. Existing embedding-based KBC models assume that all test entities are available at training time, making it unclear how to obtain embeddings for new entities without costly retraining. To solve the OOKB entity problem without retraining, we use graph neural networks (Graph-NNs) to compute the embeddings of OOKB entities, exploiting the limited auxiliary knowledge provided at test time. The experimental results show the effectiveness of our proposed model in the OOKB setting. Additionally, in the standard KBC setting in which OOKB entities are not involved, our model achieves state-of-the-art performance on the WordNet dataset.},
	language = {en},
	urldate = {2020-05-14},
	booktitle = {Proceedings of the 26th {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Hamaguchi, Takuo and Oiwa, Hidekazu and Shimbo, Masashi and Matsumoto, Yuji},
	month = aug,
	year = {2017},
	pages = {1802--1808},
}%address = {Melbourne, Australia},url = {https://www.ijcai.org/proceedings/2017/250},doi = {10.24963/ijcai.2017/250},	publisher = {IJCAI},

@article{Patrick,
  title = "Ontology Reasoning with Deep Neural Networks",
  author = "Patrick Hohenecker and Thomas Lukasiewicz",
  year = "2020",
  journal = "Journal of Artificial Intelligence Research",
  month = "July",
  pages = "503--540", 
  volume = "68",
} %url = "https://doi.org/10.1613/jair.1.11661",

@article{Patrick02,
  author    = {Patrick Hohenecker and
               Thomas Lukasiewicz},
  title     = {Ontology Reasoning with Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1808.07980},
  year      = {2018}
}

@article{dkge,
	title = {Efficiently Embedding Dynamic Knowledge Graphs},
	abstract = {Knowledge graph (KG) embedding encodes the entities and relations from a KG into low-dimensional vector spaces to support various applications such as KG completion, question answering, and recommender systems. In real world, knowledge graphs (KGs) are dynamic and evolve over time with addition or deletion of triples. However, most existing models focus on embedding static KGs while neglecting dynamics. To adapt to the changes in a KG, these models need to be re-trained on the whole KG with a high time cost. In this paper, to tackle the aforementioned problem, we propose a new context-aware Dynamic Knowledge Graph Embedding (DKGE) method which supports the embedding learning in an online fashion. DKGE introduces two different representations (i.e., knowledge embedding and contextual element embedding) for each entity and each relation, in the joint modeling of entities and relations as well as their contexts, by employing two attentive graph convolutional networks, a gate strategy, and translation operations. This effectively helps limit the impacts of a KG update in certain regions, not in the entire graph, so that DKGE can rapidly acquire the updated KG embedding by a proposed online learning algorithm. Furthermore, DKGE can also learn KG embedding from scratch. Experiments on the tasks of link prediction and question answering in a dynamic environment demonstrate the effectiveness and efficiency of DKGE.},
	urldate = {2020-05-14},
	journal = {CoRR},
	author = {Wu, Tianxing and Khan, Arijit and Gao, Huan and Li, Cheng},
	month = oct,
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases},
	volume={abs/1910.06708}
} %url = {http://arxiv.org/abs/1910.06708},

@inproceedings{shah_open-world_2019,
	title = {An Open-World Extension to Knowledge Graph Completion Models},
	issn = {2374-3468, 2159-5399},
	abstract = {We present a novel extension to embedding-based knowledge graph completion models which enables them to perform open-world link prediction, i.e. to predict facts for entities unseen in training based on their textual description. Our model combines a regular link prediction model learned from a knowledge graph with word embeddings learned from a textual corpus. After training both independently, we learn a transformation to map the embeddings of an entity's name and description to the graph-based embedding space. In experiments on several datasets including FB20k, DBPedia50k and our new dataset FB15k-237-OWE, we demonstrate competitive results. Particularly, our approach exploits the full knowledge graph structure even when textual descriptions are scarce, does not require a joint training on graph and text, and can be applied to any embedding-based link prediction model, such as TransE, ComplEx and DistMult.},
	booktitle = {Proceedings of the 33rd AAAI Conference on Artificial Intelligence},
	author = {Shah, Haseeb and Villmow, Johannes and Ulges, Adrian and Schwanecke, Ulrich and Shafait, Faisal},
	month = jul,
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	pages = {3044--3051},
}	%url = {http://arxiv.org/abs/1906.08382},
	%doi = {10.1609/aaai.v33i01.33013044},
	%note = {arXiv: 1906.08382},volume = {33},


@inproceedings{putranse,
	title = {Non-Parametric Estimation of Multiple Embeddings for Link Prediction on Dynamic Knowledge Graphs},
	author    = {Yi Tay and
               Anh Tuan Luu and
               Siu Cheung Hui},
  editor    = {Satinder P. Singh and
               Shaul Markovitch},
  title     = {Non-Parametric Estimation of Multiple Embeddings for Link Prediction
               on Dynamic Knowledge Graphs},
  booktitle = {Proceedings of the 31st {AAAI} Conference on Artificial Intelligence},
  pages     = {1243--1249},
  year      = {2017},
}

@article{zhang_knowledge_2020,
	title = {Knowledge graphs completion via probabilistic reasoning},
	volume = {521},
	issn = {0020-0255},
	abstract = {Constructing large-scale knowledge base has encountered a bottleneck because of the limitation of natural language processing. Many approaches have been put forward to infer new facts based on existing knowledge. Graph feature models mine rule-like patterns from a knowledge base and use them to predict missing edges. These models take account of the graph structure information and they can explain the existence of a fact reasonably. Existing models only describe local interaction between entities, but how to model co-relationships among facts globally is a tough problem. In this paper, we develop an efficient model which uses association rules to make inferences. First, we use a rule mining model to detect simple association rules and use them to produce large amounts of evidence. Second, based on all the produced evidence and the connections among them, we construct a factor graph which represents the inference space. Then, we develop an EM inference model, wherein the E-step we use Belief Propagation to calculate the marginal distribution of candidate edges and, in the M-step we propose a Generalized Iterative Proportional Fitting algorithm to re-learn the confidence of soft rules. Experiments show that our approach outperforms state-of-the-art approaches in knowledge base completion (KBC) tasks.},
	language = {en},
	urldate = {2020-06-23},
	journal = {Information Sciences},
	author = {Zhang, Richong and Mao, Yongyi and Zhao, Weihua},
	month = jun,
	year = {2020},
	keywords = {Knowledge graph completion, knowledge graph reasoning, Rule-based inference},
	pages = {144--159},
}	%url = {http://www.sciencedirect.com/science/article/pii/S0020025520300918},
	%doi = {10.1016/j.ins.2020.02.016},



@Inbook{Reiter1978,
author="Reiter, Raymond",
editor="Gallaire, Herv{\'e}
and Minker, Jack",
title="On Closed World Data Bases",
bookTitle="Logic and Data Bases",
year="1978",
publisher="Springer US",
address="Boston, MA",
pages="55--76",
abstract="Deductive question-answering systems generally evaluate queries under one of two possible assumptions which we in this paper refer to as the open and closed world assumptions. The open world assumption corresponds to the usual first order approach to query evaluation: Given a data base DB and a query Q, the only answers to Q are those which obtain from proofs of Q given DB as hypotheses. Under the closed world assumption, certain answers are admitted as a result of failure to find a proof. More specifically, if no proof of a positive ground literal exists, then the negation of that literal is assumed true.",
isbn="978-1-4684-3384-5",
}%doi="10.1007/978-1-4684-3384-5_3",
%url="https://doi.org/10.1007/978-1-4684-3384-5_3"

@article{adagrad,
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
year = {2011},
issue_date = {2/1/2011},
publisher = {JMLR.org},
volume = {12},
number = {null},
issn = {1532-4435},
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
journal = {Journal of Machine Learning Research},
month = jul,
pages = {2121--2159},
numpages = {39}
}


@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, 
                Conference Track Proceedings},
  year      = {2015},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}%San Diego, CA, USA, May 7-9, 2015, url       = {http://arxiv.org/abs/1412.6980},editor    = {Yoshua Bengio and   Yann LeCun},%{ICLR} 2015,

@inproceedings{sun2018rotate,
  author    = {Zhiqing Sun and
               Zhi{-}Hong Deng and
               Jian{-}Yun Nie and
               Jian Tang},
  title     = {{RotatE: K}nowledge Graph Embedding by Relational Rotation in Complex
               Space},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations},
  year      = {2019},
}

@inproceedings{crosse,
author = {Zhang, Wen and Paudel, Bibek and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
title = {Interaction Embeddings for Prediction and Explanation in Knowledge Graphs},
year = {2019},
isbn = {9781450359405},
booktitle = {Proceedings of the 12th ACM International Conference on Web Search and Data Mining},
pages = {96--104},
numpages = {9},
keywords = {explanation, knowledge graph embedding, crossover interactions, link prediction},
}%url = {https://doi.org/10.1145/3289600.3291014},
%doi = {10.1145/3289600.3291014},


@article{TANG2019809,
title = {Knowledge representation learning with entity descriptions, hierarchical types, and textual relations},
journal = {Information Processing \& Management},
volume = {56},
number = {3},
pages = {809--822},
year = {2019},
issn = {0306-4573},
author = {Xing Tang and Ling Chen and Jun Cui and Baogang Wei},
keywords = "Knowledge representation, Multi-source, Textual information",
}%doi = "https://doi.org/10.1016/j.ipm.2019.01.005",
%url = "http://www.sciencedirect.com/science/article/pii/S0306457318303698",




@article{DBLP:journals/corr/abs-1812-08434,
  author    = {Jie Zhou and
               Ganqu Cui and
               Zhengyan Zhang and
               Cheng Yang and
               Zhiyuan Liu and
               Maosong Sun},
               
  title     = {Graph Neural Networks: {A} Review of Methods and Applications},
  journal   = {CoRR},
  volume    = {abs/1812.08434},
  year      = {2019},
  month = {07},
  day= {10},
  version = {v4},
  timestamp = {Wed, 02 Sep 2020 13:29:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-08434.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
} %url       = {http://arxiv.org/abs/1812.08434},archivePrefix = {arXiv}, eprint    = {1812.08434},

@article{arora2020survey,
      title={A Survey on Graph Neural Networks for Knowledge Graph Completion}, 
      author={Siddhant Arora},
      year={2020},
      month={07},
      day={24}, journal   = {CoRR},
  volume    = {abs/2007.12374},
}
 %      primaryClass={cs.CL},
  %     url={https://arxiv.org/abs/2007.12374},
   %    version={v1}
 %eprint={2007.12374},
   %   archivePrefix={arXiv},  

@inproceedings{nathani2019learning,
    title = "Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs",
    author = "Nathani, Deepak  and
      Chauhan, Jatin  and
      Sharma, Charu  and
      Kaul, Manohar",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = "jul",
    year = "2019",
    pages = "4710--4723",
    abstract = "The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity{'}s neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.",
} %address = "Florence, Italy", url = "https://www.aclweb.org/anthology/P19-1466",
   % doi = "10.18653/v1/P19-1466",  publisher = "Association for Computational Linguistics",

@article{zhang2020efficient,
      title={Efficient Probabilistic Logic Reasoning with Graph Neural Networks}, 
      author={Yuyu Zhang and Xinshi Chen and Yuan Yang and Arun Ramamurthy and Bo Li and Yuan Qi and Le Song},
      year={2020},
      month={02},
      day={04},
      journal   = {CoRR},
    volume    = {abs/2001.11850},
      primaryClass={cs.AI},
      version={v2},
}      % url={https://arxiv.org/abs/2001.11850}, archivePrefix={arXiv},

@inproceedings{hake,
  author    = {Zhanqiu Zhang and
               Jianyu Cai and
               Yongdong Zhang and
               Jie Wang},
  title     = {Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction},
  booktitle = {Proceedings of the 34th {AAAI} Conference on Artificial Intelligence},
  pages     = {3065--3072},
  year      = {2020},
}  %url       = {https://aaai.org/ojs/index.php/AAAI/article/view/5701},


@incollection{corea_ai_2019,
	address = {Cham},
	title = {{AI} {Knowledge} {Map}: {How} to {Classify} {AI} {Technologies}},
	volume = {50},
	isbn = {978-3-030-04467-1 978-3-030-04468-8},
	shorttitle = {{AI} {Knowledge} {Map}},
	url = {http://link.springer.com/10.1007/978-3-030-04468-8_4},
	urldate = {2021-01-27},
	booktitle = {An {Introduction} to {Data}},
	publisher = {Springer International Publishing},
	author = {Corea, Francesco},
	collaborator = {Corea, Francesco},
	year = {2019},
	doi = {10.1007/978-3-030-04468-8_4},
	note = {Series Title: Studies in Big Data},
	pages = {25--29},
	file = {Corea - 2019 - AI Knowledge Map How to Classify AI Technologies.pdf:/Users/eamador/Zotero/storage/KUB9CGNJ/Corea - 2019 - AI Knowledge Map How to Classify AI Technologies.pdf:application/pdf},
}

@article{burkart_survey_2021,
	title = {A {Survey} on the {Explainability} of {Supervised} {Machine} {Learning}},
	volume = {70},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://www.jair.org/index.php/jair/article/view/12228},
	doi = {10.1613/jair.1.12228},
	language = {en},
	urldate = {2021-01-25},
	journal = {Journal of Artificial Intelligence Research},
	author = {Burkart, Nadia and Huber, Marco F.},
	month = jan,
	year = {2021},
	keywords = {knowledge discovery, machine learning, neural networks, rule learning},
	pages = {245--317},
	file = {Snapshot:/Users/eamador/Zotero/storage/KGJPDB63/12228.html:text/html;Full Text PDF:/Users/eamador/Zotero/storage/93U635NX/Burkart y Huber - 2021 - A Survey on the Explainability of Supervised Machi.pdf:application/pdf},
}

@article{loyola-gonzalez_black-box_2019,
	title = {Black-{Box} vs. {White}-{Box}: {Understanding} {Their} {Advantages} and {Weaknesses} {From} a {Practical} {Point} of {View}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {Black-{Box} vs. {White}-{Box}},
	doi = {10.1109/ACCESS.2019.2949286},
	abstract = {Nowadays, in the international scientific community of machine learning, there exists an enormous discussion about the use of black-box models or explainable models; especially in practical problems. On the one hand, a part of the community defends that black-box models are more accurate than explainable models in some contexts, like image preprocessing. On the other hand, there exist another part of the community alleging that explainable models are better than black-box models because they can obtain comparable results and also they can explain these results in a language close to a human expert by using patterns. In this paper, advantages and weaknesses for each approach are shown; taking into account a state-of-the-art review for both approaches, their practical applications, trends, and future challenges. This paper shows that both approaches are suitable for solving practical problems, but experts in machine learning need to understand the input data, the problem to solve, and the best way for showing the output data before applying a machine learning model. Also, we propose some ideas for fusing both, explainable and black-box, approaches to provide better solutions to experts in real-world domains. Additionally, we show one way to measure the effectiveness of the applied machine learning model by using expert opinions jointly with statistical methods. Throughout this paper, we show the impact of using explainable and black-box models on the security and medical applications.},
	journal = {IEEE Access},
	author = {Loyola-González, O.},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {applied machine learning model, Biological neural networks, Biological system modeling, Black-box, black-box models, Computational modeling, deep learning, explainable artificial intelligence, explainable models, Gallium nitride, learning (artificial intelligence), Machine learning, Mathematical model, statistical analysis, Statistical analysis, white-box},
	pages = {154096--154113},
	file = {IEEE Xplore Abstract Record:/Users/eamador/Zotero/storage/BWUT5PSW/8882211.html:text/html;IEEE Xplore Full Text PDF:/Users/eamador/Zotero/storage/ILNC2P3Q/Loyola-González - 2019 - Black-Box vs. White-Box Understanding Their Advan.pdf:application/pdf},
}

@article{harmelen_boxology_2019,
	title = {A {Boxology} of {Design} {Patterns} {forHybrid} {Learningand} {Reasoning} {Systems}},
	volume = {18},
	issn = {1540-9589},
	url = {http://www.riverpublishers.com/journal_read_html_article.php?j=JWE/18/1/3},
	doi = {10.13052/jwe1540-9589.18133},
	abstract = {We propose a set of compositional design patterns to describe a large variety of systems that combine statistical techniques from machine learning with symbolic techniques from knowledge representation. As in other areas of computer science (knowledge engineering, software engineering, ontology engineering, process mining and others), such design patterns help to systematize the literature, clarify which combinations of techniques serve which purposes, and encourage re-use of software components. We have validated our set of compositional design patterns against a large body of recent literature.},
	language = {en},
	number = {1},
	urldate = {2021-06-25},
	journal = {Journal of Web Engineering},
	author = {Harmelen, Frank van and {Department of Computer Science, Vrije Universiteit Amsterdam, Netherlands} and Teije, Annette ten and {Department of Computer Science, Vrije Universiteit Amsterdam, Netherlands}},
	year = {2019},
	pages = {97--124},
	file = {Harmelen et al. - 2019 - A Boxology of Design Patterns forHybrid Learningan.pdf:/Users/eamador/Zotero/storage/SCGZPME3/Harmelen et al. - 2019 - A Boxology of Design Patterns forHybrid Learningan.pdf:application/pdf},
}

@article{marra_statistical_2021,
	title = {From {Statistical} {Relational} to {Neural} {Symbolic} {Artificial} {Intelligence}: a {Survey}},
	shorttitle = {From {Statistical} {Relational} to {Neural} {Symbolic} {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2108.11451},
	abstract = {Neural-symbolic and statistical relational artificial intelligence both integrate frameworks for learning with logical reasoning. This survey identifies several parallels across seven different dimensions between these two fields. These cannot only be used to characterize and position neural-symbolic artificial intelligence approaches but also to identify a number of directions for further research.},
	urldate = {2021-09-07},
	journal = {arXiv:2108.11451 [cs]},
	author = {Marra, Giuseppe and Dumančić, Sebastijan and Manhaeve, Robin and De Raedt, Luc},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.11451},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/eamador/Zotero/storage/L5VA2NGU/Marra et al. - 2021 - From Statistical Relational to Neural Symbolic Art.pdf:application/pdf;arXiv.org Snapshot:/Users/eamador/Zotero/storage/IYW8RBX8/2108.html:text/html},
}

@article{marcus_deep_2018,
	title = {Deep {Learning}: {A} {Critical} {Appraisal}},
	shorttitle = {Deep {Learning}},
	url = {http://arxiv.org/abs/1801.00631},
	abstract = {Although deep learning has historical roots going back decades, neither the term "deep learning" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.},
	urldate = {2021-12-15},
	journal = {arXiv:1801.00631 [cs, stat]},
	author = {Marcus, Gary},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.00631},
	keywords = {97R40, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.0, I.2.6, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/eamador/Zotero/storage/6S5CL82M/Marcus - 2018 - Deep Learning A Critical Appraisal.pdf:application/pdf;arXiv.org Snapshot:/Users/eamador/Zotero/storage/L3LC4J9X/1801.html:text/html},
}

@article{hohenecker_ontology_2020,
	title = {Ontology reasoning with deep neural networks},
	volume = {68},
	issn = {1076-9757},
	doi = {10.1613/JAIR.1.11661},
	abstract = {The ability to conduct logical reasoning is a fundamental aspect of intelligent human behavior, and thus an important problem along the way to human-level artificial intelligence. Traditionally, logic-based symbolic methods from the field of knowledge representation and reasoning have been used to equip agents with capabilities that resemble human logical reasoning qualities. More recently, however, there has been an increasing interest in using machine learning rather than logic-based symbolic formalisms to tackle these tasks. In this paper, we employ state-of-the-art methods for training deep neural networks to devise a novel model that is able to learn how to effectively perform logical reasoning in the form of basic ontology reasoning. This is an important and at the same time very natural logical reasoning task, which is why the presented approach is applicable to a plethora of important real-world problems. We present the outcomes of several experiments, which show that our model is able to learn to perform highly accurate ontology reasoning on very large, diverse, and challenging benchmarks. Furthermore, it turned out that the suggested approach suffers much less from different obstacles that prohibit logic-based symbolic reasoning, and, at the same time, is surprisingly plausible from a biological point of view. © 2020 AI Access Foundation. All rights reserved.},
	language = {English},
	journal = {Journal of Artificial Intelligence Research},
	author = {Hohenecker, P. and Lukasiewicz, T.},
	year = {2020},
	pages = {503--540},
	file = {Snapshot:/Users/eamador/Zotero/storage/6D535DSZ/display.html:text/html;Full Text:/Users/eamador/Zotero/storage/6N6XKG93/Hohenecker and Lukasiewicz - 2020 - Ontology reasoning with deep neural networks.pdf:application/pdf},
}

@article{korteling_human-_2021,
	title = {Human- versus {Artificial} {Intelligence}},
	volume = {4},
	issn = {2624-8212},
	doi = {10.3389/frai.2021.622364},
	abstract = {AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed. © Copyright © 2021 Korteling, van de Boer-Visschedijk, Blankendaal, Boonekamp and Eikelboom.},
	language = {English},
	journal = {Frontiers in Artificial Intelligence},
	author = {Korteling, J.E. and van de Boer-Visschedijk, G.C. and Blankendaal, R.A.M. and Boonekamp, R.C. and Eikelboom, A.R.},
	year = {2021},
	keywords = {artificial general intelligence, artificial intelligence, cognitive bias, cognitive complexity, human intelligence, human-AI collaboration, human-level artificial intelligence, narrow artificial intelligence},
	file = {Snapshot:/Users/eamador/Zotero/storage/JFSNXUWZ/display.html:text/html;Full Text:/Users/eamador/Zotero/storage/2IB6JAEK/Korteling et al. - 2021 - Human- versus Artificial Intelligence.pdf:application/pdf},
}

@article{chou_counterfactuals_2022,
	title = {Counterfactuals and causability in explainable artificial intelligence: {Theory}, algorithms, and applications},
	volume = {81},
	issn = {1566-2535},
	shorttitle = {Counterfactuals and causability in explainable artificial intelligence},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253521002281},
	doi = {10.1016/j.inffus.2021.11.003},
	abstract = {Deep learning models have achieved high performance across different domains, such as medical decision-making, autonomous vehicles, decision support systems, among many others. However, despite this success, the inner mechanisms of these models are opaque because their internal representations are too complex for a human to understand. This opacity makes it hard to understand the how or the why of the predictions of deep learning models. There has been a growing interest in model-agnostic methods that make deep learning models more transparent and explainable to humans. Some researchers recently argued that for a machine to achieve human-level explainability, this machine needs to provide human causally understandable explanations, also known as causability. A specific class of algorithms that have the potential to provide causability are counterfactuals. This paper presents an in-depth systematic review of the diverse existing literature on counterfactuals and causability for explainable artificial intelligence (AI). We performed a Latent Dirichlet topic modelling analysis (LDA) under a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework to find the most relevant literature articles. This analysis yielded a novel taxonomy that considers the grounding theories of the surveyed algorithms, together with their underlying properties and applications to real-world data. Our research suggests that current model-agnostic counterfactual algorithms for explainable AI are not grounded on a causal theoretical formalism and, consequently, cannot promote causability to a human decision-maker. Furthermore, our findings suggest that the explanations derived from popular algorithms in the literature provide spurious correlations rather than cause/effects relationships, leading to sub-optimal, erroneous, or even biased explanations. Thus, this paper also advances the literature with new directions and challenges on promoting causability in model-agnostic approaches for explainable AI.},
	language = {en},
	urldate = {2021-12-21},
	journal = {Information Fusion},
	author = {Chou, Yu-Liang and Moreira, Catarina and Bruza, Peter and Ouyang, Chun and Jorge, Joaquim},
	month = may,
	year = {2022},
	keywords = {Deep learning, Causability, Causality, Counterfactuals, Explainable AI},
	pages = {59--83},
	file = {Submitted Version:/Users/eamador/Zotero/storage/BBWRUXAY/Chou et al. - 2022 - Counterfactuals and causability in explainable art.pdf:application/pdf},
}

@article{pearl_theoretical_2018,
	title = {Theoretical {Impediments} to {Machine} {Learning} {With} {Seven} {Sparks} from the {Causal} {Revolution}},
	url = {http://arxiv.org/abs/1801.04016},
	abstract = {Current machine learning systems operate, almost exclusively, in a statistical, or model-free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.},
	urldate = {2021-12-21},
	journal = {arXiv:1801.04016 [cs, stat]},
	author = {Pearl, Judea},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.04016},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/Users/eamador/Zotero/storage/6XYY3ECQ/1801.html:text/html;arXiv Fulltext PDF:/Users/eamador/Zotero/storage/6C6F3H4F/Pearl - 2018 - Theoretical Impediments to Machine Learning With S.pdf:application/pdf},
}

@article{darwiche_human-level_2017,
	title = {Human-{Level} {Intelligence} or {Animal}-{Like} {Abilities}?},
	url = {http://arxiv.org/abs/1707.04327},
	abstract = {The vision systems of the eagle and the snake outperform everything that we can make in the laboratory, but snakes and eagles cannot build an eyeglass or a telescope or a microscope. (Judea Pearl)},
	urldate = {2021-12-21},
	journal = {arXiv:1707.04327 [cs, stat]},
	author = {Darwiche, Adnan},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.04327},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computers and Society},
	file = {arXiv.org Snapshot:/Users/eamador/Zotero/storage/AVY7I5P2/1707.html:text/html;arXiv Fulltext PDF:/Users/eamador/Zotero/storage/EA94DJ2C/Darwiche - 2017 - Human-Level Intelligence or Animal-Like Abilities.pdf:application/pdf},
}

@book{russell_artificial_2010,
	address = {Upper Saddle River},
	edition = {3rd ed},
	series = {Prentice {Hall} series in artificial intelligence},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial intelligence},
	language = {en},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter and Davis, Ernest},
	year = {2010},
	keywords = {Artificial intelligence},
	file = {Russell et al. - 2010 - Artificial intelligence a modern approach.pdf:/Users/eamador/Zotero/storage/CE5CXFVX/Russell et al. - 2010 - Artificial intelligence a modern approach.pdf:application/pdf},
}


@article{futia_integration_2020,
	title = {On the integration of knowledge graphs into deep learning models for a more comprehensible {AI}-{Three} challenges for future research},
	volume = {11},
	issn = {2078-2489},
	doi = {10.3390/info11020122},
	abstract = {Deep learning models contributed to reaching unprecedented results in prediction and classification tasks of Artificial Intelligence (AI) systems. However, alongside this notable progress, they do not provide human-understandable insights on how a specific result was achieved. In contexts where the impact of AI on human life is relevant (e.g., recruitment tools, medical diagnoses, etc.), explainability is not only a desirable property, but it is-or, in some cases, it will be soon-a legal requirement. Most of the available approaches to implement eXplainable Artificial Intelligence (XAI) focus on technical solutions usable only by experts able to manipulate the recursive mathematical functions in deep learning algorithms. A complementary approach is represented by symbolic AI, where symbols are elements of a lingua franca between humans and deep learning. In this context, Knowledge Graphs (KGs) and their underlying semantic technologies are the modern implementation of symbolic AI-while being less flexible and robust to noise compared to deep learning models, KGs are natively developed to be explainable. In this paper, we review the main XAI approaches existing in the literature, underlying their strengths and limitations, and we propose neural-symbolic integration as a cornerstone to design an AI which is closer to non-insiders comprehension. Within such a general direction, we identify three specific challenges for future research-knowledge matching, cross-disciplinary explanations and interactive explanations. © 2020 by the author.},
	language = {English},
	number = {2},
	journal = {Information (Switzerland)},
	author = {Futia, G. and Vetrò, A.},
	year = {2020},
	keywords = {Deep learning, Knowledge graphs, EXplainable artificial intelligence},
	file = {Full Text:/home/eamador/Zotero/storage/UPFQUDMF/Futia and Vetrò - 2020 - On the integration of knowledge graphs into deep l.pdf:application/pdf;Snapshot:/home/eamador/Zotero/storage/KNY8TEYV/display.html:text/html},
}




@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {1566-2535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	language = {en},
	urldate = {2021-12-22},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	keywords = {Explainable Artificial Intelligence, Accountability, Comprehensibility, Data Fusion, Deep Learning, Fairness, Interpretability, Machine Learning, Privacy, Responsible Artificial Intelligence, Transparency},
	pages = {82--115},
	file = {Accepted Version:/home/eamador/Zotero/storage/IIZ6QQ8Y/Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:application/pdf},
}

@article{Bouraoui_Jameel_Schockaert_2017, title={Inductive Reasoning about Ontologies Using Conceptual Spaces}, volume={31}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11162}, abstractNote={ &lt;p&gt; Structured knowledge about concepts plays an increasingly important role in areas such as information retrieval. The available ontologies and knowledge graphs that encode such conceptual knowledge, however, are inevitably incomplete. This observation has led to a number of methods that aim to automatically complete existing knowledge bases. Unfortunately, most existing approaches rely on black box models, e.g. formulated as global optimization problems, which makes it difficult to support the underlying reasoning process with intuitive explanations. In this paper, we propose a new method for knowledge base completion, which uses interpretable conceptual space representations and an explicit model for inductive inference that is closer to human forms of commonsense reasoning. Moreover, by separating the task of representation learning from inductive reasoning, our method is easier to apply in a wider variety of contexts. Finally, unlike optimization based approaches, our method can naturally be applied in settings where various logical constraints between the extensions of concepts need to be taken into account. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Bouraoui, Zied and Jameel, Shoaib and Schockaert, Steven}, year={2017}, month={Feb.} }

@article{bianchi_kge_explainability_2020,
  author    = {Federico Bianchi and
               Gaetano Rossiello and
               Luca Costabello and
               Matteo Palmonari and
               Pasquale Minervini},
  title     = {Knowledge Graph Embeddings and Explainable {AI}},
  journal   = {CoRR},
  volume    = {abs/2004.14843},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.14843},
  archivePrefix = {arXiv},
  eprint    = {2004.14843},
  timestamp = {Sun, 03 May 2020 17:39:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-14843.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/eswa/Amador-Dominguez21,
  author    = {Elvira Amador{-}Dom{\'{\i}}nguez and
               Emilio Serrano and
               Daniel Manrique},
  title     = {A hierarchical multi-agent architecture based on virtual identities
               to explain black-box personalization policies},
  journal   = {Expert Syst. Appl.},
  volume    = {186},
  pages     = {115731},
  year      = {2021},
  url       = {https://doi.org/10.1016/j.eswa.2021.115731},
  doi       = {10.1016/j.eswa.2021.115731},
  timestamp = {Wed, 03 Nov 2021 08:24:48 +0100},
  biburl    = {https://dblp.org/rec/journals/eswa/Amador-Dominguez21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{ying_2019_gnnexplainer,
      title={GNNExplainer: Generating Explanations for Graph Neural Networks}, 
      author={Rex Ying and Dylan Bourgeois and Jiaxuan You and Marinka Zitnik and Jure Leskovec},
      year={2019},
      eprint={1903.03894},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{pezeshkpour_2019_investigating,
    title = "Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications",
    author = "Pezeshkpour, Pouya  and
      Tian, Yifan  and
      Singh, Sameer",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1337",
    doi = "10.18653/v1/N19-1337",
    pages = "3336--3347",
    abstract = "Representing entities and relations in an embedding space is a well-studied approach for machine learning on relational data. Existing approaches, however, primarily focus on improving accuracy and overlook other aspects such as robustness and interpretability. In this paper, we propose adversarial modifications for link prediction models: identifying the fact to add into or remove from the knowledge graph that changes the prediction for a target fact after the model is retrained. Using these single modifications of the graph, we identify the most influential fact for a predicted link and evaluate the sensitivity of the model to the addition of fake facts. We introduce an efficient approach to estimate the effect of such modifications by approximating the change in the embeddings when the knowledge graph changes. To avoid the combinatorial search over all possible facts, we train a network to decode embeddings to their corresponding graph components, allowing the use of gradient-based optimization to identify the adversarial modification. We use these techniques to evaluate the robustness of link prediction models (by measuring sensitivity to additional facts), study interpretability through the facts most responsible for predictions (by identifying the most influential neighbors), and detect incorrect facts in the knowledge base.",
}


@article{arya_one_2019,
	title = {One {Explanation} {Does} {Not} {Fit} {All}: {A} {Toolkit} and {Taxonomy} of {AI} {Explainability} {Techniques}},
	shorttitle = {One {Explanation} {Does} {Not} {Fit} {All}},
	url = {http://arxiv.org/abs/1909.03012},
	abstract = {As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, present different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 3601, an open-source software toolkit featuring eight diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. We also discuss enhancements to bring research innovations closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, to tutorials and an interactive web demo to introduce AI explainability to different audiences and application domains. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.},
	language = {en},
	urldate = {2021-12-22},
	journal = {arXiv:1909.03012 [cs, stat]},
	author = {Arya, Vijay and Bellamy, Rachel K. E. and Chen, Pin-Yu and Dhurandhar, Amit and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Liao, Q. Vera and Luss, Ronny and Mojsilović, Aleksandra and Mourad, Sami and Pedemonte, Pablo and Raghavendra, Ramya and Richards, John and Sattigeri, Prasanna and Shanmugam, Karthikeyan and Singh, Moninder and Varshney, Kush R. and Wei, Dennis and Zhang, Yunfeng},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.03012},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction},
	file = {Arya et al. - 2019 - One Explanation Does Not Fit All A Toolkit and Ta.pdf:/home/eamador/Zotero/storage/5KVMCAW3/Arya et al. - 2019 - One Explanation Does Not Fit All A Toolkit and Ta.pdf:application/pdf},
}


@article{gilpin_explainability_2018,
  author    = {Leilani H. Gilpin and
               David Bau and
               Ben Z. Yuan and
               Ayesha Bajwa and
               Michael A. Specter and
               Lalana Kagal},
  title     = {Explaining Explanations: An Approach to Evaluating Interpretability
               of Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1806.00069},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.00069},
  eprinttype = {arXiv},
  eprint    = {1806.00069},
  timestamp = {Wed, 15 Sep 2021 11:19:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-00069.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{adadi_explainability_2018,  author={Adadi, Amina and Berrada, Mohammed},  journal={IEEE Access},   title={Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)},   year={2018},  volume={6},  number={},  pages={52138-52160},  doi={10.1109/ACCESS.2018.2870052}}

@misc{phillips_explainability_2021,
  author = {P. Phillips and Carina Hahn and Peter Fontana and Amy Yates and Kristen Greene and David Broniatowski and Mark Przybocki},
  title = {Four Principles of Explainable Artificial Intelligence},
  year = {2021},
  month = {2021-09-29 04:09:00},
  publisher = {NIST Interagency/Internal Report (NISTIR), National Institute of Standards and Technology, Gaithersburg, MD},
  url = {https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=933399},
  doi = {https://doi.org/10.6028/NIST.IR.8312},
  language = {en},
}


@article{guidotti_explainability_2018,
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
title = {A Survey of Methods for Explaining Black Box Models},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
journal = {ACM Comput. Surv.},
month = {aug},
articleno = {93},
numpages = {42},
keywords = {transparent models, Open the black box, interpretability, explanations}
}

@article{burkart_survey_2021,
	title = {A {Survey} on the {Explainability} of {Supervised} {Machine} {Learning}},
	volume = {70},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://www.jair.org/index.php/jair/article/view/12228},
	doi = {10.1613/jair.1.12228},
	language = {en},
	urldate = {2021-01-25},
	journal = {Journal of Artificial Intelligence Research},
	author = {Burkart, Nadia and Huber, Marco F.},
	month = jan,
	year = {2021},
	keywords = {neural networks, knowledge discovery, machine learning, rule learning},
	pages = {245--317},
	file = {Snapshot:/home/eamador/Zotero/storage/KGJPDB63/12228.html:text/html;Full Text PDF:/home/eamador/Zotero/storage/93U635NX/Burkart y Huber - 2021 - A Survey on the Explainability of Supervised Machi.pdf:application/pdf},
}


@article{asim_ontology_2018,
    author = {Asim, Muhammad Nabeel and Wasim, Muhammad and Khan, Muhammad Usman Ghani and Mahmood, Waqar and Abbasi, Hafiza Mahnoor},
    title = "{A survey of ontology learning techniques and applications}",
    journal = {Database},
    volume = {2018},
    year = {2018},
    month = {10},
    abstract = "{Ontologies have gained a lot of popularity and recognition in the semantic web because of their extensive use in Internet-based applications. Ontologies are often considered a fine source of semantics and interoperability in all artificially smart systems. Exponential increase in unstructured data on the web has made automated acquisition of ontology from unstructured text a most prominent research area. Several methodologies exploiting numerous techniques of various fields (machine learning, text mining, knowledge representation and reasoning, information retrieval and natural language processing) are being proposed to bring some level of automation in the process of ontology acquisition from unstructured text. This paper describes the process of ontology learning and further classification of ontology learning techniques into three classes (linguistics, statistical and logical) and discusses many algorithms under each category. This paper also explores ontology evaluation techniques by highlighting their pros and cons. Moreover, it describes the scope and use of ontology learning in several industries. Finally, the paper discusses challenges of ontology learning along with their corresponding future directions.}",
    issn = {1758-0463},
    doi = {10.1093/database/bay101},
    url = {https://doi.org/10.1093/database/bay101},
    note = {bay101},
    eprint = {https://academic.oup.com/database/article-pdf/doi/10.1093/database/bay101/27329264/bay101.pdf},
}





@article{wong_ontology_2012,
author = {Wong, Wilson and Liu, Wei and Bennamoun, Mohammed},
title = {Ontology Learning from Text: A Look Back and into the Future},
year = {2012},
issue_date = {August 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2333112.2333115},
doi = {10.1145/2333112.2333115},
abstract = {Ontologies are often viewed as the answer to the need for interoperable semantics in modern information systems. The explosion of textual information on the Read/Write Web coupled with the increasing demand for ontologies to power the Semantic Web have made (semi-)automatic ontology learning from text a very promising research area. This together with the advanced state in related areas, such as natural language processing, have fueled research into ontology learning over the past decade. This survey looks at how far we have come since the turn of the millennium and discusses the remaining challenges that will define the research directions in this area in the near future.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {20},
numpages = {36},
keywords = {concept discovery, term recognition, Ontology learning, application of ontologies, semantic relation acquisition}
}



@article{calegari_integration_2020,
	title = {On the integration of symbolic and sub-symbolic techniques for {XAI}: {A} survey},
	volume = {14},
	issn = {1724-8035},
	shorttitle = {On the integration of symbolic and sub-symbolic techniques for {XAI}},
	url = {https://content.iospress.com/articles/intelligenza-artificiale/ia190036},
	doi = {10.3233/IA-190036},
	abstract = {The more intelligent systems based on sub-symbolic techniques pervade our everyday lives, the less human can understand them. This is why symbolic approaches are getting more and more attention in the general effort to make AI interpretable, explain},
	language = {en},
	number = {1},
	urldate = {2021-12-22},
	journal = {Intelligenza Artificiale},
	author = {Calegari, Roberta and Ciatto, Giovanni and Omicini, Andrea},
	month = jan,
	year = {2020},
	note = {Publisher: IOS Press},
	pages = {7--32},
	file = {Snapshot:/Users/eamador/Zotero/storage/X4TMNUFU/ia190036.html:text/html},
}

@article{arya_one_2019,
	title = {One {Explanation} {Does} {Not} {Fit} {All}: {A} {Toolkit} and {Taxonomy} of {AI} {Explainability} {Techniques}},
	shorttitle = {One {Explanation} {Does} {Not} {Fit} {All}},
	url = {http://arxiv.org/abs/1909.03012},
	abstract = {As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, present different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 3601, an open-source software toolkit featuring eight diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. We also discuss enhancements to bring research innovations closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, to tutorials and an interactive web demo to introduce AI explainability to different audiences and application domains. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.},
	language = {en},
	urldate = {2021-12-22},
	journal = {arXiv:1909.03012 [cs, stat]},
	author = {Arya, Vijay and Bellamy, Rachel K. E. and Chen, Pin-Yu and Dhurandhar, Amit and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Liao, Q. Vera and Luss, Ronny and Mojsilović, Aleksandra and Mourad, Sami and Pedemonte, Pablo and Raghavendra, Ramya and Richards, John and Sattigeri, Prasanna and Shanmugam, Karthikeyan and Singh, Moninder and Varshney, Kush R. and Wei, Dennis and Zhang, Yunfeng},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.03012},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction},
	file = {Arya et al. - 2019 - One Explanation Does Not Fit All A Toolkit and Ta.pdf:/Users/eamador/Zotero/storage/5KVMCAW3/Arya et al. - 2019 - One Explanation Does Not Fit All A Toolkit and Ta.pdf:application/pdf},
}

@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {1566-2535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	language = {en},
	urldate = {2021-12-22},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	keywords = {Explainable Artificial Intelligence, Accountability, Comprehensibility, Data Fusion, Deep Learning, Fairness, Interpretability, Machine Learning, Privacy, Responsible Artificial Intelligence, Transparency},
	pages = {82--115},
	file = {Accepted Version:/Users/eamador/Zotero/storage/IIZ6QQ8Y/Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:application/pdf},
}

@article{van_bekkum_modular_2021,
	title = {Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases},
	volume = {51},
	issn = {0924-669X},
	shorttitle = {Modular design patterns for hybrid learning and reasoning systems},
	doi = {10.1007/s10489-021-02394-3},
	abstract = {The unification of statistical (data-driven) and symbolic (knowledge-driven) methods is widely recognized as one of the key challenges of modern AI. Recent years have seen a large number of publications on such hybrid neuro-symbolic AI systems. That rapidly growing literature is highly diverse, mostly empirical, and is lacking a unifying view of the large variety of these hybrid systems. In this paper, we analyze a large body of recent literature and we propose a set of modular design patterns for such hybrid, neuro-symbolic systems. We are able to describe the architecture of a very large number of hybrid systems by composing only a small set of elementary patterns as building blocks. The main contributions of this paper are: 1) a taxonomically organised vocabulary to describe both processes and data structures used in hybrid systems; 2) a set of 15+ design patterns for hybrid AI systems organized in a set of elementary patterns and a set of compositional patterns; 3) an application of these design patterns in two realistic use-cases for hybrid AI systems. Our patterns reveal similarities between systems that were not recognized until now. Finally, our design patterns extend and refine Kautz’s earlier attempt at categorizing neuro-symbolic architectures. © 2021, The Author(s).},
	language = {English},
	number = {9},
	journal = {Applied Intelligence},
	author = {Van Bekkum, M. and de Boer, M. and van Harmelen, F. and Meyer-Vitali, A. and Teije, A.},
	year = {2021},
	keywords = {Design patterns, Neuro-symbolic systems},
	pages = {6528--6546},
	file = {Snapshot:/Users/eamador/Zotero/storage/KV48JMXV/display.html:text/html;Full Text:/Users/eamador/Zotero/storage/9ZIW68W2/van Bekkum et al. - 2021 - Modular design patterns for hybrid learning and re.pdf:application/pdf},
}

@article{chou_counterfactuals_2022-1,
	title = {Counterfactuals and causability in explainable artificial intelligence: {Theory}, algorithms, and applications},
	volume = {81},
	issn = {1566-2535},
	shorttitle = {Counterfactuals and causability in explainable artificial intelligence},
	doi = {10.1016/j.inffus.2021.11.003},
	abstract = {Deep learning models have achieved high performance across different domains, such as medical decision-making, autonomous vehicles, decision support systems, among many others. However, despite this success, the inner mechanisms of these models are opaque because their internal representations are too complex for a human to understand. This opacity makes it hard to understand the how or the why of the predictions of deep learning models. There has been a growing interest in model-agnostic methods that make deep learning models more transparent and explainable to humans. Some researchers recently argued that for a machine to achieve human-level explainability, this machine needs to provide human causally understandable explanations, also known as causability. A specific class of algorithms that have the potential to provide causability are counterfactuals. This paper presents an in-depth systematic review of the diverse existing literature on counterfactuals and causability for explainable artificial intelligence (AI). We performed a Latent Dirichlet topic modelling analysis (LDA) under a Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) framework to find the most relevant literature articles. This analysis yielded a novel taxonomy that considers the grounding theories of the surveyed algorithms, together with their underlying properties and applications to real-world data. Our research suggests that current model-agnostic counterfactual algorithms for explainable AI are not grounded on a causal theoretical formalism and, consequently, cannot promote causability to a human decision-maker. Furthermore, our findings suggest that the explanations derived from popular algorithms in the literature provide spurious correlations rather than cause/effects relationships, leading to sub-optimal, erroneous, or even biased explanations. Thus, this paper also advances the literature with new directions and challenges on promoting causability in model-agnostic approaches for explainable AI. © 2021 Elsevier B.V.},
	language = {English},
	journal = {Information Fusion},
	author = {Chou, Y.-L. and Moreira, C. and Bruza, P. and Ouyang, C. and Jorge, J.},
	year = {2022},
	keywords = {Deep learning, Causability, Causality, Counterfactuals, Explainable AI},
	pages = {59--83},
	file = {Submitted Version:/Users/eamador/Zotero/storage/L53FJR62/Chou et al. - 2022 - Counterfactuals and causability in explainable art.pdf:application/pdf;Snapshot:/Users/eamador/Zotero/storage/LSX6RT3I/display.html:text/html},
}

@article{angelov_explainable_2021,
	title = {Explainable artificial intelligence: an analytical review},
	volume = {11},
	issn = {1942-4787},
	shorttitle = {Explainable artificial intelligence},
	doi = {10.1002/widm.1424},
	abstract = {This paper provides a brief analytical review of the current state-of-the-art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested. This article is categorized under: Technologies {\textgreater} Artificial Intelligence Fundamental Concepts of Data and Knowledge {\textgreater} Explainable AI. © 2021 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals LLC.},
	language = {English},
	number = {5},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	author = {Angelov, P.P. and Soares, E.A. and Jiang, R. and Arnold, N.I. and Atkinson, P.M.},
	year = {2021},
	keywords = {deep learning, machine learning, black-box models, explainable AI, prototype-based models, surrogate models},
	file = {Snapshot:/Users/eamador/Zotero/storage/A2AW6Q9M/display.html:text/html;Accepted Version:/Users/eamador/Zotero/storage/D4IGELMM/Angelov et al. - 2021 - Explainable artificial intelligence an analytical.pdf:application/pdf},
}

@article{calegari_integration_nodate,
	title = {On the integration of symbolic and sub-symbolic techniques for {XAI}: {A} survey},
	abstract = {The more intelligent systems based on sub-symbolic techniques pervade our everyday lives, the less human can understand them. This is why symbolic approaches are getting more and more attention in the general effort to make AI interpretable, explainable, and trustable. Understanding the current state of the art of AI techniques integrating symbolic and sub-symbolic approaches is then of paramount importance, nowadays—in particular in the XAI perspective. This is why this paper provides an overview of the main symbolic/sub-symbolic integration techniques, focussing in particular on those targeting explainable AI systems.},
	language = {en},
	author = {Calegari, Roberta and Ciatto, Giovanni and Omicini, Andrea},
	pages = {26},
	file = {Calegari et al. - On the integration of symbolic and sub-symbolic te.pdf:/Users/eamador/Zotero/storage/JMFDSKWA/Calegari et al. - On the integration of symbolic and sub-symbolic te.pdf:application/pdf},
}

@article{hilario_overview_nodate,
	title = {An {Overview} of {Strategies} for {Neurosymbolic} {Integration}},
	abstract = {At the crossroads of symbolic and neural processing, researchers have been actively investigating the synergies that might be obtained from combining the strengths of these two paradigms. Neurosymbolic integration comes in two avors: unifed and hybrid. Uni ed approaches strive to attain full symbol-processing functionalities using neural techniques alone while hybrid approaches blend symbolic reasoning and representational models with neural networks. This papers attempts to clarify and compare the objectives, mechanisms, variants and underlying assumptions of these major integration approaches.},
	language = {en},
	author = {Hilario, Melanie},
	pages = {6},
	year= {1995},
	file = {Hilario - An Overview of Strategies for Neurosymbolic Integr.pdf:/Users/eamador/Zotero/storage/LPCKZ66I/Hilario - An Overview of Strategies for Neurosymbolic Integr.pdf:application/pdf},
}

@inproceedings{wagner_neural-symbolic_2021,
	title = {Neural-symbolic integration for fairness in {AI}},
	volume = {2846},
	abstract = {Deep learning has achieved state-of-the-art results in various application domains ranging from image recognition to language translation and game playing. However, it is now generally accepted that deep learning alone has not been able to satisfy the requirement of fairness and, ultimately, trust in Artificial Intelligence (AI). In this paper, we propose an interactive neural-symbolic approach for fairness in AI based on the Logic Tensor Network (LTN) framework. We show that the extraction of symbolic knowledge from LTN-based deep networks combined with fairness constraints offer a general method for instilling fairness into deep networks via continual learning. Explainable AI approaches which otherwise could identify but not fix fairness issues are shown to be enriched with an ability to improve fairness results. Experimental results on three real-world data sets used to predict income, credit risk and recidivism in financial applications show that our approach can satisfy fairness metrics while maintaining state-of-the-art classification performance. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)},
	language = {English},
	author = {Wagner, B. and D'Avila Garcez, A.},
	year = {2021},
	note = {ISSN: 1613-0073},
	keywords = {Deep learning with knowledge representation, Explainability, Fairness, Neurosymbolic AI},
}

@article{mira_neurosymbolic_2004,
	title = {Neurosymbolic ntegration: {The} knowledge level approach},
	volume = {2809},
	issn = {1611-3349},
	shorttitle = {Neurosymbolic ntegration},
	abstract = {The time when the connectionist and symbolic perspectives of Artificial Intelligence (AI) competed against each other is now over. The rivalry was due essentially to ignorance on the implications of the knowledge level, as introduced by Newell and Marr. Now it is generally accepted that they are different and complementary forms of modeling and operationalizing the inferences in terms of which a problem solving method (PSM) decomposes a task. All these tasks, methods, inferences, and formal operators belong to a broad library of reusable components for knowledge modeling. The final configuration of a problem solving method, with symbolic and connectionist components, is only dependent on the particular balance between data and knowledge available for the specific application under consideration. Various approaches have been explored for neurosymbolic integration. In this paper we propose a classification of these approaches (unified, hybrid and system level) and strongly support that the integration has to be made at the knowledge level and in the domain of the external observer (the "house" of models). © Springer-Verlag 2003.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Mira, J. and Delgado, A.E. and Taboada, M.J.},
	year = {2004},
	pages = {460--470},
}


@article{corchado_neuro-symbolic_1995,
	title = {Neuro-symbolic reasoning system for modelling complex behaviours},
	abstract = {A neuro-symbolic reasoning strategy for modelling a complex system is presented in which the aim is to forecast, in real time, the physical parameter values of a dynamic environment: the ocean. In situations in which the rules that determine a system are unknown the prediction of the parameter values that determine the characteristic behaviour of the system can be a problematic task. In such a situation it has been found that a case-based reasoning system, in combination with an artifical neural network, can provide a more effective means of performing such predictions than other connectionist or symbolic techniques. The case-based reasoning system incorporates a radial basis function artificial neural network for the case adaptation. The results obtained from experiments, in which the system operated in real time in the oceanographic environment, are presented.},
	language = {en},
	author = {Corchado, Juan M and Aiken, Jim and Rees, Nigel},
	pages = {32},
	year={1995},
	file = {Corchado et al. - Neuro-symbolic reasoning system for modelling comp.pdf:/home/eamador/Zotero/storage/IIFY3K9J/Corchado et al. - Neuro-symbolic reasoning system for modelling comp.pdf:application/pdf},
}

@incollection{medsker2020models,
  title={Models and guidelines for integrating expert systems and neural networks},
  author={Medsker, Larry R and Bailey, David L},
  booktitle={Hybrid architectures for intelligent systems},
  pages={153--171},
  year={1992},
  publisher={CRC Press}
}


@article{ilkou_symbolic_nodate,
	title = {Symbolic {Vs} {Sub}-symbolic {AI} {Methods}: {Friends} or {Enemies}?},
	abstract = {There is a long and unresolved debate between the symbolic and sub-symbolic methods. However, in recent years, there is a push towards in-between methods. In this work, we provide a comprehensive overview of the symbolic, sub-symbolic and in-between approaches focused in the domain of knowledge graphs, namely, schema representation, schema matching, knowledge graph completion, link prediction, entity resolution, entity classification and triple classification. We critically present key characteristics, advantages and disadvantages of the main algorithms in each domain, and review the use of these methods in knowledge graph related applications.},
	language = {en},
	author = {Ilkou, Eleni and Koutraki, Maria},
	pages = {8},
	file = {Ilkou y Koutraki - Symbolic Vs Sub-symbolic AI Methods Friends or En.pdf:/Users/eamador/Zotero/storage/B3LGPQXG/Ilkou y Koutraki - Symbolic Vs Sub-symbolic AI Methods Friends or En.pdf:application/pdf},
}

@INCOLLECTION{description_logics,
  title     = "Description Logics",
  booktitle = "Encyclopedia of Social Network Analysis and Mining",
  author    = "Krisnadhi, Adila and Hitzler, Pascal",
  publisher = "Springer New York",
  pages     = "572--581",
  year      =  2018,
  address   = "New York, NY"
}



@article{garcez_neural-symbolic_2019,
  author={Artur D'Avila Garcez and Marco Gori and Luís C. Lamb and Luciano Serafini and Michael Spranger and Son N. Tran},
  title={Neural-symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning},
  year={2019},
  cdate={1546300800000},
  journal={FLAP},
  volume={6},
  number={4},
  pages={611-632},
  url={https://collegepublications.co.uk/ifcolog/?00033}
}

@incollection{bader_dimensions_2005,
  author    = {Sebastian Bader and Pascal Hitzler},
  title     = {Dimensions of neural-symbolic integration {\textemdash} a
               structured survey},
  editor    = {S. Artemov and H. Barringer and A. S. {d'Avila} Garcez and L. C.
               Lamb and J. Woods},
  booktitle = {We Will Show Them: Essays in Honour of Dov Gabbay},
  volume    = {1},
  publisher = {King's College Publications},
  year      = {2005},
  pages     = {167-194}
}
@article{lieberman_symbolic_nodate,
	title = {Symbolic vs. {Subsymbolic} {AI}},
	language = {en},
	year = {2009},
	author = {Lieberman, Henry},
	pages = {11},
	file = {Lieberman - Symbolic vs. Subsymbolic AI.pdf:/Users/eamador/Zotero/storage/DM4KN2MG/Lieberman - Symbolic vs. Subsymbolic AI.pdf:application/pdf},
}

@article{jacobsson_rule_2005,
	title = {Rule {Extraction} from {Recurrent} {Neural} {Networks}: {ATaxonomy} and {Review}},
	volume = {17},
	issn = {0899-7667, 1530-888X},
	shorttitle = {Rule {Extraction} from {Recurrent} {Neural} {Networks}},
	url = {https://direct.mit.edu/neco/article/17/6/1223-1263/6977},
	doi = {10.1162/0899766053630350},
	abstract = {Rule extraction (RE) from recurrent neural networks (RNNs) refers to ﬁnding models of the underlying RNN, typically in the form of ﬁnite state machines, that mimic the network to a satisfactory degree while having the advantage of being more transparent. RE from RNNs can be argued to allow a deeper and more profound form of analysis of RNNs than other, more or less ad hoc methods. RE may give us understanding of RNNs in the intermediate levels between quite abstract theoretical knowledge of RNNs as a class of computing devices and quantitative performance evaluations of RNN instantiations. The development of techniques for extraction of rules from RNNs has been an active ﬁeld since the early nineties. In this paper, the progress of this development is reviewed and analysed in detail. In order to structure the survey and to evaluate the techniques, a taxonomy, speciﬁcally designed for this purpose, has been developed. Moreover, important open research issues are identiﬁed, that, if addressed properly, possibly can give the ﬁeld a signiﬁcant push forward.},
	language = {en},
	number = {6},
	urldate = {2021-12-28},
	journal = {Neural Computation},
	author = {Jacobsson, Henrik},
	month = jun,
	year = {2005},
	pages = {1223--1263},
	file = {Jacobsson - 2005 - Rule Extraction from Recurrent Neural Networks AT.pdf:/Users/eamador/Zotero/storage/S3A3MJGM/Jacobsson - 2005 - Rule Extraction from Recurrent Neural Networks AT.pdf:application/pdf},
}


@Article{amador_systematic_review_2019,
AUTHOR = {Amador-Domínguez, Elvira and Serrano, Emilio and Manrique, Daniel and De Paz, Juan F.},
TITLE = {Prediction and Decision-Making in Intelligent Environments Supported by Knowledge Graphs, A Systematic Review},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {1774},
URL = {https://www.mdpi.com/1424-8220/19/8/1774},
ISSN = {1424-8220},
ABSTRACT = {Ambient Intelligence is currently a lively application domain of Artificial Intelligence and has become the central subject of multiple initiatives worldwide. Several approaches inside this domain make use of knowledge bases or knowledge graphs, both previously existing and ad hoc. This form of representation allows heterogeneous data gathered from diverse sources to be contextualized and combined to create relevant information for intelligent systems, usually following higher level constraints defined by an ontology. In this work, we conduct a systematic review of the existing usages of knowledge bases in intelligent environments, as well as an in-depth study of the predictive and decision-making models employed. Finally, we present a use case for smart homes and illustrate the use and advantages of Knowledge Graph Embeddings in this context.},
DOI = {10.3390/s19081774}
}

@article{marra_learning_2021,
	title = {Learning {Representations} for {Sub}-{Symbolic} {Reasoning}},
	url = {http://arxiv.org/abs/2106.00393},
	abstract = {Neuro-symbolic methods integrate neural architectures, knowledge representation and reasoning. However, they have been struggling at both dealing with the intrinsic uncertainty of the observations and scaling to real world applications. This paper presents Relational Reasoning Networks (R2N), a novel end-to-end model that performs relational reasoning in the latent space of a deep learner architecture, where the representations of constants, ground atoms and their manipulations are learned in an integrated fashion. Unlike ﬂat architectures like Knowledge Graph Embedders, which can only represent relations between entities, R2Ns deﬁne an additional computational structure, accounting for higher-level relations among the ground atoms. The considered relations can be explicitly known, like the ones deﬁned by logic formulas, or deﬁned as unconstrained correlations among groups of ground atoms. R2Ns can be applied to purely symbolic tasks or as a neuro-symbolic platform to integrate learning and reasoning in heterogeneous problems with both symbolic and feature-based represented entities. The proposed model bridges the gap between previous neuro-symbolic methods that have been either limited in terms of scalability or expressivity. The proposed methodology is shown to achieve stateof-the-art results in different experimental settings.},
	language = {en},
	urldate = {2021-12-29},
	journal = {arXiv:2106.00393 [cs]},
	author = {Marra, Giuseppe and Diligenti, Michelangelo and Giannini, Francesco},
	month = oct,
	year = {2021},
	note = {arXiv: 2106.00393},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Marra et al. - 2021 - Learning Representations for Sub-Symbolic Reasonin.pdf:/Users/eamador/Zotero/storage/C8N5ZH6G/Marra et al. - 2021 - Learning Representations for Sub-Symbolic Reasonin.pdf:application/pdf},
}


@incollection{frechtling_2015,
title = {Logic Models},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {299-305},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.10549-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868105495},
author = {Joy A. Frechtling},
keywords = {Communication, Conceptual framework, Context of evaluation, Continuous improvement, Dissemination, Evaluability assessment, Logic model, Mixed methods, Outcome evaluation, Planning evaluation, Process evaluation, Project management, Project monitoring, Shared vision, Theory of change},
abstract = {The purpose of this article is to discuss the use of logic models as a tool and consider how logic models can best be used to strengthen research and evaluation studies. We define logic models as a range of visual depictions of a project or program's theory of change or theory of action. The article provides examples of logic models, suggests some historical roots, discusses the development of logic models and how they can be used, and offers a list of their strengths and weaknesses.}
}ç

@Article{roberta_logic-based_2020,
AUTHOR = {Calegari, Roberta and Ciatto, Giovanni and Denti, Enrico and Omicini, Andrea},
TITLE = {Logic-Based Technologies for Intelligent Systems: State of the Art and Perspectives},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {167},
URL = {https://www.mdpi.com/2078-2489/11/3/167},
ISSN = {2078-2489},
ABSTRACT = {Together with the disruptive development of modern sub-symbolic approaches to artificial intelligence (AI), symbolic approaches to classical AI are re-gaining momentum, as more and more researchers exploit their potential to make AI more comprehensible, explainable, and therefore trustworthy. Since logic-based approaches lay at the core of symbolic AI, summarizing their state of the art is of paramount importance now more than ever, in order to identify trends, benefits, key features, gaps, and limitations of the techniques proposed so far, as well as to identify promising research perspectives. Along this line, this paper provides an overview of logic-based approaches and technologies by sketching their evolution and pointing out their main application areas. Future perspectives for exploitation of logic-based technologies are discussed as well, in order to identify those research fields that deserve more attention, considering the areas that already exploit logic-based approaches as well as those that are more likely to adopt logic-based approaches in the future.},
DOI = {10.3390/info11030167}
}

@article{mccarthy_1958, title={John McCarthy and Claude Shannon. Preface. Automata studies, edited by C. E. Shannon and J. McCarthy, Annals of Mathematics studies no. 34, lithoprinted, Princeton University Press, Princeton1956, pp. v–viii. - S. C. Kleene. Representations of events in nerve nets and finite automata. Automata studies, edited by C. E. Shannon and J. McCarthy, Annals of Mathematics studies no. 34, lithoprinted, Princeton University Press, Princeton1956, pp. 3–41.}, volume={23}, DOI={10.2307/2964499}, number={1}, journal={Journal of Symbolic Logic}, publisher={Cambridge University Press}, author={Duda, W. L.}, year={1958}, pages={59–60}}


@Inbook{hopgood_2009_knowledge-based,
author={Hopgood, Adrian A.},
title={Knowledge-Based Systems},
series={Encyclopedia of Artificial Intelligence},
year={2009},
publisher={IGI Global},
address={Hershey, PA, USA},
pages={989-995},
abstract={The tools of artificial intelligence (AI) can be divided into two broad types: knowledge-based systems (KBSs) and computational intelligence (CI). KBSs use explicit representations of knowledge in the form of words and symbols. This explicit representation makes the knowledge more easily read and understood by a human than the numerically derived implicit models in computational intelligence. KBSs include techniques such as rule-based, modelbased, and case-based reasoning. They were among the first forms of investigation into AI and remain a major theme. Early research focused on specialist applications in areas such as chemistry, medicine, and computer hardware. These early successes generated great optimism in AI, but more broad-based representations of human intelligence have remained difficult to achieve (Hopgood, 2003; Hopgood, 2005).},
isbn={9781599048499},
doi={10.4018/978-1-59904-849-9.ch146},
url={https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-59904-849-9.ch146},
url={https://doi.org/10.4018/978-1-59904-849-9.ch146}
}


@Article{Muggleton1991,
author={Muggleton, Stephen},
title={Inductive logic programming},
journal={New Generation Computing},
year={1991},
month={Feb},
day={01},
volume={8},
number={4},
pages={295-318},
abstract={A new research area, Inductive Logic Programming, is presently emerging. While inheriting various positive characteristics of the parent subjects of Logic Programming and Machine Learning, it is hoped that the new area will overcome many of the limitations of its forebears. The background to present developments within this area is discussed and various goals and aspirations for the increasing body of researchers are identified. Inductive Logic Programming needs to be based on sound principles from both Logic and Statistics. On the side of statistical justification of hypotheses we discuss the possible relationship between Algorithmic Complexity theory and Probably-Approximately-Correct (PAC) Learning. In terms of logic we provide a unifying framework for Muggleton and Buntine's Inverse Resolution (IR) and Plotkin's Relative Least General Generalisation (RLGG) by rederiving RLGG in terms of IR. This leads to a discussion of the feasibility of extending the RLGG framework to allow for the invention of new predicates, previously discussed only within the context of IR.},
issn={1882-7055},
doi={10.1007/BF03037089},
url={https://doi.org/10.1007/BF03037089}
}

@techreport{noy2001ontology,
  title={Ontology development 101{: A} guide to creating your first ontology},
  author={Noy, Natalya F and McGuinness, Deborah L},
  year={2001},
  institution={Stanford Knowledge Systems Laboratory KSL-01-05 and Stanford Medical Informatics SMI-2001-0880, Stanford, CA},
}


@article{overview_cbr,
author = {Aamodt, Agnar and Plaza, Enric},
title = {Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches},
year = {1994},
issue_date = {March 1994},
publisher = {IOS Press},
address = {NLD},
volume = {7},
number = {1},
issn = {0921-7126},
journal = {AI Commun.},
doi={10.3233/AIC-1994-7104},
month = mar,
pages = {39–59},
numpages = {21}
}


@book{poole_2017_ai_foundations,
author = {Poole, David L. and Mackworth, Alan K.},
title = {Artificial Intelligence: Foundations of Computational Agents},
year = {2017},
isbn = {110719539X},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {Artificial intelligence, including machine learning, has emerged as a transformational science and engineering discipline. Artificial Intelligence: Foundations of Computational Agents presents AI using a coherent framework to study the design of intelligent computational agents. By showing how the basic approaches fit into a multidimensional design space, readers learn the fundamentals without losing sight of the bigger picture. The new edition also features expanded coverage on machine learning material, as well as on the social and ethical consequences of AI and ML. The book balances theory and experiment, showing how to link them together, and develops the science of AI together with its engineering applications. Although structured as an undergraduate and graduate textbook, the book's straightforward, self-contained style will also appeal to an audience of professionals, researchers, and independent learners. The second edition is well-supported by strong pedagogical features and online resources to enhance student comprehension.}
}

@article{friedman_1997_bayesian,
author = {Friedman, Nir and Geiger, Dan and Goldszmidt, Moises},
title = {Bayesian Network Classifiers},
year = {1997},
issue_date = {Nov./Dec. 1997},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {2–3},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1007465528199},
doi = {10.1023/A:1007465528199},
abstract = {Recent work in supervised learning has shown that a surprisingly
simple Bayesian classifier with strong assumptions of independence among
features, called naive Bayes, is competitive with
state-of-the-art classifiers such as C4.5. This fact raises the question of
whether a classifier with less restrictive assumptions can perform even
better. In this paper we evaluate approaches for inducing classifiers from
data, based on the theory of learning Bayesian networks. These networks are factored representations of
probability distributions that generalize the naive Bayesian classifier and
explicitly represent statements about independence. Among these approaches
we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time
maintains the computational simplicity (no search involved) and robustness
that characterize naive Bayes. We experimentally tested these approaches,
using problems from the University of California at Irvine repository, and 
compared them to C4.5, naive Bayes, and wrapper methods for feature
selection.},
journal = {Mach. Learn.},
month = {nov},
pages = {131–163},
numpages = {33},
keywords = {classification, Bayesian networks}
}

@incollection{GALVAN2003573,
title = {Parallel Evolutionary Computation for Solving Complex CFD Optimization Problems : A Review and Some Nozzle Applications},
editor = {K. Matsuno and A. Ecer and N. Satofuka and J. Periaux and P. Fox},
booktitle = {Parallel Computational Fluid Dynamics 2002},
publisher = {North-Holland},
address = {Amsterdam},
pages = {573-604},
year = {2003},
isbn = {978-0-444-50680-1},
doi = {https://doi.org/10.1016/B978-044450680-1/50072-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780444506801500723},
author = {B. Galvan and Greiner D. and Périaux J. and M. Sefrioui and G. Winter},
keywords = {Evolutionary Algorithms, Nozzle flows, Aerodynamic Shape Design Optimisation, Hierarchical Parallel Evolutionary Algorithms, Multi objective, Game Theory, Pareto Front and Nash Equilbrium},
abstract = {This paper attempts to present a summarized survey in the field of Parallel Evolutionary Algorithms (PEAs), trying to highlight the most relevent aspects in the design and implementation of each class of PEAs. A review of the most advanced research activities on this field is presented. New tools for new challenges of Industry and Society, which are definitely multi criteria oriented and CFD dominant in the applications, are investigated and a series of simple nozzle shape optimization problems with their methodologies and associated results – including Hierarchy and Game Theory - are discussed. Data resulting from evolutionary optimization, which have been collected in the database of a European Thematic Network named INGEnet are presented as a road map to Multidisciplinary Design Optimisation.}
}

@article{bengio_2012_dl_review,
  author    = {Yoshua Bengio and
               Aaron C. Courville and
               Pascal Vincent},
  title     = {Unsupervised Feature Learning and Deep Learning: {A} Review and New
               Perspectives},
  journal   = {CoRR},
  volume    = {abs/1206.5538},
  year      = {2012},
  url       = {http://arxiv.org/abs/1206.5538},
  eprinttype = {arXiv},
  eprint    = {1206.5538},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1206-5538.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{Rosenblatt58theperceptron:,
    author = {F. Rosenblatt},
    title = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
    journal = {Psychological Review},
    year = {1958},
    pages = {65--386}
}

@INBOOK{rumelhart_1987_backpropagation,  author={Rumelhart, David E. and McClelland, James L.},  booktitle={Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations},   title={Learning Internal Representations by Error Propagation},   year={1987},  volume={},  number={},  pages={318-362},  doi={}}

@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@article{chowdhury_2003_nlp,
author = {Chowdhury, Gobinda G.},
title = {Natural language processing},
journal = {Annual Review of Information Science and Technology},
volume = {37},
number = {1},
pages = {51-89},
doi = {https://doi.org/10.1002/aris.1440370103},
url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/aris.1440370103},
eprint = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/aris.1440370103},
year = {2003}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}


@inproceedings{wang-etal-2016-combination,
    title = "Combination of Convolutional and Recurrent Neural Network for Sentiment Analysis of Short Texts",
    author = "Wang, Xingyou  and
      Jiang, Weijie  and
      Luo, Zhiyong",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1229",
    pages = "2428--2437",
    abstract = "Sentiment analysis of short texts is challenging because of the limited contextual information they usually contain. In recent years, deep learning models such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been applied to text sentiment analysis with comparatively remarkable results. In this paper, we describe a jointed CNN and RNN architecture, taking advantage of the coarse-grained local features generated by CNN and long-distance dependencies learned via RNN for sentiment analysis of short texts. Experimental results show an obvious improvement upon the state-of-the-art on three benchmark corpora, MR, SST1 and SST2, with 82.28{\%}, 51.50{\%} and 89.95{\%} accuracy, respectively.",
}


@article{dai_survey_2020,
	title = {A {Survey} on {Knowledge} {Graph} {Embedding}: {Approaches}, {Applications} and {Benchmarks}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {A {Survey} on {Knowledge} {Graph} {Embedding}},
	url = {https://www.mdpi.com/2079-9292/9/5/750},
	doi = {10.3390/electronics9050750},
	abstract = {A knowledge graph (KG), also known as a knowledge base, is a particular kind of network structure in which the node indicates entity and the edge represent relation. However, with the explosion of network volume, the problem of data sparsity that causes large-scale KG systems to calculate and manage difficultly has become more significant. For alleviating the issue, knowledge graph embedding is proposed to embed entities and relations in a KG to a low-, dense and continuous feature space, and endow the yield model with abilities of knowledge inference and fusion. In recent years, many researchers have poured much attention in this approach, and we will systematically introduce the existing state-of-the-art approaches and a variety of applications that benefit from these methods in this paper. In addition, we discuss future prospects for the development of techniques and application trends. Specifically, we first introduce the embedding models that only leverage the information of observed triplets in the KG. We illustrate the overall framework and specific idea and compare the advantages and disadvantages of such approaches. Next, we introduce the advanced models that utilize additional semantic information to improve the performance of the original methods. We divide the additional information into two categories, including textual descriptions and relation paths. The extension approaches in each category are described, following the same classification criteria as those defined for the triplet fact-based models. We then describe two experiments for comparing the performance of listed methods and mention some broader domain tasks such as question answering, recommender systems, and so forth. Finally, we collect several hurdles that need to be overcome and provide a few future research directions for knowledge graph embedding.},
	language = {en},
	number = {5},
	urldate = {2021-03-10},
	journal = {Electronics},
	author = {Dai, Yuanfei and Wang, Shiping and Xiong, Neal N. and Guo, Wenzhong},
	month = may,
	year = {2020},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {knowledge graph embedding, deep learning, knowledge representation, statistical relational learning},
	pages = {750},
	file = {Full Text PDF:/home/eamador/Zotero/storage/CKKYDLJT/Dai et al. - 2020 - A Survey on Knowledge Graph Embedding Approaches,.pdf:application/pdf},
}

%--------------HYBRID MODELS

@article{harmelen_boxology_2019,
	title = {A {Boxology} of {Design} {Patterns} {forHybrid} {Learningand} {Reasoning} {Systems}},
	volume = {18},
	issn = {1540-9589},
	url = {http://www.riverpublishers.com/journal_read_html_article.php?j=JWE/18/1/3},
	doi = {10.13052/jwe1540-9589.18133},
	abstract = {We propose a set of compositional design patterns to describe a large variety of systems that combine statistical techniques from machine learning with symbolic techniques from knowledge representation. As in other areas of computer science (knowledge engineering, software engineering, ontology engineering, process mining and others), such design patterns help to systematize the literature, clarify which combinations of techniques serve which purposes, and encourage re-use of software components. We have validated our set of compositional design patterns against a large body of recent literature.},
	language = {en},
	number = {1},
	urldate = {2021-06-25},
	journal = {Journal of Web Engineering},
	author = {Harmelen, Frank van and {Department of Computer Science, Vrije Universiteit Amsterdam, Netherlands} and Teije, Annette ten and {Department of Computer Science, Vrije Universiteit Amsterdam, Netherlands}},
	year = {2019},
	note = {Number: 1},
	pages = {97--124},
	file = {Harmelen et al. - 2019 - A Boxology of Design Patterns forHybrid Learningan.pdf:/home/eamador/Zotero/storage/STUEPIRF/Harmelen et al. - 2019 - A Boxology of Design Patterns forHybrid Learningan.pdf:application/pdf},
}

@article{marcus_deep_2018,
	title = {Deep {Learning}: {A} {Critical} {Appraisal}},
	shorttitle = {Deep {Learning}},
	url = {http://arxiv.org/abs/1801.00631},
	abstract = {Although deep learning has historical roots going back decades, neither the term "deep learning" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.},
	urldate = {2021-12-15},
	journal = {arXiv:1801.00631 [cs, stat]},
	author = {Marcus, Gary},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.00631},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, I.2.6, 97R40, I.2.0},
	file = {arXiv Fulltext PDF:/home/eamador/Zotero/storage/A3KCBL3M/Marcus - 2018 - Deep Learning A Critical Appraisal.pdf:application/pdf;arXiv.org Snapshot:/home/eamador/Zotero/storage/WNR3H9GS/1801.html:text/html},
}

@article{van_bekkum_modular_2021,
	title = {Modular design patterns for hybrid learning and reasoning systems: a taxonomy, patterns and use cases},
	volume = {51},
	issn = {0924-669X},
	shorttitle = {Modular design patterns for hybrid learning and reasoning systems},
	doi = {10.1007/s10489-021-02394-3},
	abstract = {The unification of statistical (data-driven) and symbolic (knowledge-driven) methods is widely recognized as one of the key challenges of modern AI. Recent years have seen a large number of publications on such hybrid neuro-symbolic AI systems. That rapidly growing literature is highly diverse, mostly empirical, and is lacking a unifying view of the large variety of these hybrid systems. In this paper, we analyze a large body of recent literature and we propose a set of modular design patterns for such hybrid, neuro-symbolic systems. We are able to describe the architecture of a very large number of hybrid systems by composing only a small set of elementary patterns as building blocks. The main contributions of this paper are: 1) a taxonomically organised vocabulary to describe both processes and data structures used in hybrid systems; 2) a set of 15+ design patterns for hybrid AI systems organized in a set of elementary patterns and a set of compositional patterns; 3) an application of these design patterns in two realistic use-cases for hybrid AI systems. Our patterns reveal similarities between systems that were not recognized until now. Finally, our design patterns extend and refine Kautz’s earlier attempt at categorizing neuro-symbolic architectures. © 2021, The Author(s).},
	language = {English},
	number = {9},
	journal = {Applied Intelligence},
	author = {van Bekkum, M. and de Boer, M. and van Harmelen, F. and Meyer-Vitali, A. and Teije, A.},
	year = {2021},
	note = {Number: 9},
	keywords = {Design patterns, Neuro-symbolic systems},
	pages = {6528--6546},
}

@article{calegari_integration_nodate,
	title = {On the integration of symbolic and sub-symbolic techniques for {XAI}: {A} survey},
	abstract = {The more intelligent systems based on sub-symbolic techniques pervade our everyday lives, the less human can understand them. This is why symbolic approaches are getting more and more attention in the general effort to make AI interpretable, explainable, and trustable. Understanding the current state of the art of AI techniques integrating symbolic and sub-symbolic approaches is then of paramount importance, nowadays—in particular in the XAI perspective. This is why this paper provides an overview of the main symbolic/sub-symbolic integration techniques, focussing in particular on those targeting explainable AI systems.},
	language = {en},
	author = {Calegari, Roberta and Ciatto, Giovanni and Omicini, Andrea},
	pages = {26},
	file = {Calegari et al. - On the integration of symbolic and sub-symbolic te.pdf:/home/eamador/Zotero/storage/23FE66JV/Calegari et al. - On the integration of symbolic and sub-symbolic te.pdf:application/pdf},
}

@article{hilario_overview_nodate,
	title = {An {Overview} of {Strategies} for {Neurosymbolic} {Integration}},
	abstract = {At the crossroads of symbolic and neural processing, researchers have been actively investigating the synergies that might be obtained from combining the strengths of these two paradigms. Neurosymbolic integration comes in two avors: unifed and hybrid. Uni ed approaches strive to attain full symbol-processing functionalities using neural techniques alone while hybrid approaches blend symbolic reasoning and representational models with neural networks. This papers attempts to clarify and compare the objectives, mechanisms, variants and underlying assumptions of these major integration approaches.},
	language = {en},
	author = {Hilario, Melanie},
	pages = {6},
	file = {Hilario - An Overview of Strategies for Neurosymbolic Integr.pdf:/home/eamador/Zotero/storage/VX43NTCD/Hilario - An Overview of Strategies for Neurosymbolic Integr.pdf:application/pdf},
}

@article{garcez_neural-symbolic_2019,
	title = {Neural-{Symbolic} {Computing}: {An} {Effective} {Methodology} for {Principled} {Integration} of {Machine} {Learning} and {Reasoning}},
	shorttitle = {Neural-{Symbolic} {Computing}},
	url = {http://arxiv.org/abs/1905.06088},
	abstract = {Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.},
	urldate = {2021-12-27},
	journal = {arXiv:1905.06088 [cs]},
	author = {Garcez, Artur D'Avila and Gori, Marco and Lamb, Luis C. and Serafini, Luciano and Spranger, Michael and Tran, Son N.},
	month = may,
	year = {2019},
	note = {arXiv: 1905.06088},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/eamador/Zotero/storage/2KFMQCUB/Garcez et al. - 2019 - Neural-Symbolic Computing An Effective Methodolog.pdf:application/pdf;arXiv.org Snapshot:/home/eamador/Zotero/storage/FZ3RSENL/1905.html:text/html},
}

@article{mcgarry_hybrid_1999,
	title = {Hybrid {Neural} {Systems}: {From} {Simple} {Coupling} to {Fully} {Integrated} {Neural} {Networks}},
	abstract = {This paper describes techniques for integrating neural networks and symbolic components into powerful hybrid systems. Neural networks have unique processing characteristics that enable tasks to be performed that would be di cult or intractable for a symbolic rule-based system. However, a stand-alone neural network requires an interpretation either by a human or a rulebased system. This motivates the integration of neural/symbolic techniques within a hybrid system. A number of integration possibilities exist: some systems consist of neural network components performing symbolic tasks while other systems are composed of several neural networks and symbolic components, each component acting as a self-contained module communicating with the others. Other hybrid systems are able to transform subsymbolic representations into symbolic ones and vice-versa. This paper provides an overview and evaluation of the state of the art of several hybrid neural systems for rule-based processing.},
	language = {en},
	year = {1999},
	author = {McGarry, Kenneth and Wermter, Stefan and MacIntyre, John},
	pages = {32},
	file = {McGarry et al. - Hybrid Neural Systems From Simple Coupling to Ful.pdf:/home/eamador/Zotero/storage/9FMS69I9/McGarry et al. - Hybrid Neural Systems From Simple Coupling to Ful.pdf:application/pdf},
}

@ARTICLE{wang_kge_survey_2017,  author={Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},  journal={IEEE Transactions on Knowledge and Data Engineering},   title={Knowledge Graph Embedding: A Survey of Approaches and Applications},   year={2017},  volume={29},  number={12},  pages={2724-2743},  doi={10.1109/TKDE.2017.2754499}}

@article{garcez_neurosymbolic_2020,
	title = {Neurosymbolic {AI}: {The} 3rd {Wave}},
	shorttitle = {Neurosymbolic {AI}},
	url = {http://arxiv.org/abs/2012.05876},
	abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.},
	urldate = {2022-01-20},
	journal = {arXiv:2012.05876 [cs]},
	author = {Garcez, Artur D'Avila and Lamb, Luis C.},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.05876},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.4, I.2.6},
	file = {arXiv Fulltext PDF:/home/eamador/Zotero/storage/P9AYBH5H/Garcez and Lamb - 2020 - Neurosymbolic AI The 3rd Wave.pdf:application/pdf;arXiv.org Snapshot:/home/eamador/Zotero/storage/C3TVANUC/2012.html:text/html},
}

@article{nickel_review_ml_kg_2016,
   title={A Review of Relational Machine Learning for Knowledge Graphs},
   volume={104},
   ISSN={1558-2256},
   url={http://dx.doi.org/10.1109/JPROC.2015.2483592},
   DOI={10.1109/jproc.2015.2483592},
   number={1},
   journal={Proceedings of the IEEE},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Nickel, Maximilian and Murphy, Kevin and Tresp, Volker and Gabrilovich, Evgeniy},
   year={2016},
   month={Jan},
   pages={11–33} }


@inproceedings{leake_bringing_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {On {Bringing} {Case}-{Based} {Reasoning} {Methodology} to {Deep} {Learning}},
	isbn = {978-3-030-58342-2},
	doi = {10.1007/978-3-030-58342-2_22},
	abstract = {The case-based reasoning community is successfully pursuing multiple approaches for applying deep learning methods to advance case-based reasoning. This “Challenges and Promises” paper argues for a complementary endeavor: pursuing ways that the case-based reasoning methodology can advance deep learning. Starting from challenges in deep learning and proposed neural-symbolic integrations based on specific technologies, it proposes studying how CBR ideas can inform choices of components for a new reasoning pipeline.},
	language = {en},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}},
	publisher = {Springer International Publishing},
	author = {Leake, David and Crandall, David},
	editor = {Watson, Ian and Weber, Rosina},
	year = {2020},
	keywords = {Deep learning, Automated machine learning, Case-based reasoning methodology, Challenge problems, Integrations, Pipelines},
	pages = {343--348},
	file = {Springer Full Text PDF:/home/eamador/Zotero/storage/SX3U68DR/Leake and Crandall - 2020 - On Bringing Case-Based Reasoning Methodology to De.pdf:application/pdf},
}

@inproceedings{daniele_knowledge_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Knowledge {Enhanced} {Neural} {Networks}},
	isbn = {978-3-030-29908-8},
	doi = {10.1007/978-3-030-29908-8_43},
	abstract = {We propose Knowledge Enhanced Neural Networks (KENN), an architecture for injecting prior knowledge, codified by a set of logical clauses, into a neural network.In KENN clauses are directly incorporated in the structure of the neural network as a new layer that includes a set of additional learnable parameters, called clause weights. As a consequence, KENN can learn the level of satisfiability to impose in the final classification. When training data contradicts a constraint, KENN learns to ignore it, making the system robust to the presence of wrong knowledge. Moreover, the method returns learned clause weights, which gives us informations about the influence of each constraint in the final predictions, increasing the interpretability of the model. We evaluated KENN on two standard datasets for multi-label classification, showing that the injection of clauses automatically extracted from the training data sensibly improves the performances. Furthermore, we apply KENN to solve the problem of finding relationship between detected objects in images by adopting manually curated clauses. The evaluation shows that KENN outperforms the state of the art methods on this task.},
	language = {en},
	booktitle = {{PRICAI} 2019: {Trends} in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Daniele, Alessandro and Serafini, Luciano},
	editor = {Nayak, Abhaya C. and Sharma, Alok},
	year = {2019},
	keywords = {Fuzzy logic, Neural networks, Neural-symbolic integration, Visual Relationship Detection},
	pages = {542--554},
	file = {Springer Full Text PDF:/home/eamador/Zotero/storage/KRNFFFFC/Daniele and Serafini - 2019 - Knowledge Enhanced Neural Networks.pdf:application/pdf},
}

@article{hitzler_neural-symbolic_nodate,
	title = {Neural-{Symbolic} {Integration} and the {Semantic} {Web}},
	abstract = {Symbolic Systems in Artiﬁcial Intelligence which are based on formal logic and deductive reasoning are fundamentally diﬀerent from Artiﬁcial Intelligence systems based on artiﬁcial neural networks, such as deep learning approaches. The diﬀerence is not only in their inner workings and general approach, but also with respect to capabilities. Neural-symbolic Integration, as a ﬁeld of study, aims to bridge between the two paradigms. In this paper, we will discuss neural-symbolic integration in its relation to the Semantic Web ﬁeld, with a focus on promises and possible beneﬁts for both, and report on some current research on the topic.},
	language = {en},
	author = {Hitzler, Pascal and Bianchi, Federico and Ebrahimi, Monireh and Sarker, Kamruzzaman},
	pages = {10},
}
@unpublished {besold_neural-symbolic_2017,
	title = {Neural-Symbolic Learning and Reasoning: A Survey and Interpretation},
	year = {2017},
	author = {Tarek R. Besold and Artur S. d{\textquoteright}Avila Garcez and Sebastian Bader and Howard Bowman and Pedro Domingos and Pascal Hitzler and Kai-Uwe K{\"u}hnberger and Lu{\'\i}s C. Lamb and Daniel Lowd and Priscila Machado Vieira Lima and Leo de Penning and Gadi Pinkas and Hoifung Poon and Gerson Zaverucha}
}

@article{valiant_three_2003,
	title = {Three problems in computer science},
	volume = {50},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/602382.602410},
	doi = {10.1145/602382.602410},
	number = {1},
	urldate = {2022-01-17},
	journal = {Journal of the ACM},
	author = {Valiant, Leslie G.},
	year = {2003},
	pages = {96--99},
	file = {Full Text PDF:/home/eamador/Zotero/storage/HN548ZPL/Valiant - 2003 - Three problems in computer science.pdf:application/pdf},
}


@article{rossi_knowledge_2021,
	title = {Knowledge {Graph} {Embedding} for {Link} {Prediction}: {A} {Comparative} {Analysis}},
	volume = {15},
	issn = {1556-4681},
	shorttitle = {Knowledge {Graph} {Embedding} for {Link} {Prediction}},
	url = {https://doi.org/10.1145/3424672},
	doi = {10.1145/3424672},
	abstract = {Knowledge Graphs (KGs) have found many applications in industrial and in academic settings, which in turn, have motivated considerable research efforts towards large-scale information extraction from a variety of sources. Despite such efforts, it is well known that even the largest KGs suffer from incompleteness; Link Prediction (LP) techniques address this issue by identifying missing facts among entities already in the KG. Among the recent LP techniques, those based on KG embeddings have achieved very promising performance in some benchmarks. Despite the fast-growing literature on the subject, insufficient attention has been paid to the effect of the design choices in those methods. Moreover, the standard practice in this area is to report accuracy by aggregating over a large number of test facts in which some entities are vastly more represented than others; this allows LP methods to exhibit good results by just attending to structural properties that include such entities, while ignoring the remaining majority of the KG. This analysis provides a comprehensive comparison of embedding-based LP methods, extending the dimensions of analysis beyond what is commonly available in the literature. We experimentally compare the effectiveness and efficiency of 18 state-of-the-art methods, consider a rule-based baseline, and report detailed analysis over the most popular benchmarks in the literature.},
	number = {2},
	urldate = {2022-05-19},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Rossi, Andrea and Barbosa, Denilson and Firmani, Donatella and Matinata, Antonio and Merialdo, Paolo},
	year = {2021},
	keywords = {link prediction, Knowledge graphs, comparative analysis, knowledge graph embeddings},
	pages = {14:1--14:49},
	file = {Versión enviada:/home/eamador/Zotero/storage/PKHFXR9W/Rossi et al. - 2021 - Knowledge Graph Embedding for Link Prediction A C.pdf:application/pdf},
}


@article{DBLP:journals/ijimai/Amador-Dominguez21,
  author    = {Elvira Amador{-}Dom{\'{\i}}nguez and
               Emilio Serrano and
               Daniel Manrique and
               Javier Bajo},
  title     = {A Case-Based Reasoning Model Powered by Deep Learning for Radiology
               Report Recommendation},
  journal   = {Int. J. Interact. Multim. Artif. Intell.},
  volume    = {7},
  number    = {2},
  pages     = {15},
  year      = {2021},
  url       = {https://doi.org/10.9781/ijimai.2021.08.011},
  doi       = {10.9781/ijimai.2021.08.011},
  timestamp = {Fri, 04 Feb 2022 16:57:52 +0100},
  biburl    = {https://dblp.org/rec/journals/ijimai/Amador-Dominguez21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{amie+,
author={Gal{\'a}rraga, Luis
and Teflioudi, Christina
and Hose, Katja
and Suchanek, Fabian M.},
title={Fast rule mining in ontological knowledge bases with AMIE+},
journal={The VLDB Journal},
year={2015},
month={Dec},
day={01},
volume={24},
number={6},
pages={707-730},
abstract={Recent advances in information extraction have led to huge knowledge bases (KBs), which capture knowledge in a machine-readable format. Inductive logic programming (ILP) can be used to mine logical rules from these KBs, such as ``If two persons are married, then they (usually) live in the same city.'' While ILP is a mature field, mining logical rules from KBs is difficult, because KBs make an open-world assumption. This means that absent information cannot be taken as counterexamples. Our approach AMIE (Gal{\'a}rraga et al. in WWW, 2013) has shown how rules can be mined effectively from KBs even in the absence of counterexamples. In this paper, we show how this approach can be optimized to mine even larger KBs with more than 12M statements. Extensive experiments show how our new approach, AMIE{\$}{\$}+{\$}{\$}, extends to areas of mining that were previously beyond reach.},
issn={0949-877X},
doi={10.1007/s00778-015-0394-1},
url={https://doi.org/10.1007/s00778-015-0394-1}
}



@InProceedings{Miani,
author="Miani, Rafael Garcia Leonel
and de S. Pedro, Saulo D.
and Hruschla, Estevam R.",
editor="Bazzan, Ana L.C.
and Pichara, Karim",
title="Association Rules to Help Populating a Never-Ending Growing Knowledge Base",
booktitle="Advances in Artificial Intelligence -- IBERAMIA 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="169--181",
abstract="Large and continuous growing knowledge bases (KBs) have been widely studied in recent years. A major challenge in this field is how to develop techniques to help populating such KBs and improve their coverage. In this context, this work proposes an ``association rules''-base approach. We applied an association rule mining algorithm to discover new relations between the instances and categories, to populate a KB. Considering that automatically constructed KBs are often incomplete, we modified traditional support criteria, creating the MSC measure, to deal with missing values. Experiments showed that an association rule mining algorithm, with and without the modified support calculation, brings relevant rules and can play an interesting role in the process of increasing a large growing knowledge base.",
isbn="978-3-319-12027-0"
}

@inproceedings{transe,
  title={Translating embeddings for modeling multi-relational data},
  author={Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
  booktitle={Advances in Neural Information Processing Systems 26},
  pages={2787--2795},
  year={2013}
}

@inproceedings{transr,
  title={Learning entity and relation embeddings for knowledge graph completion},
  author={Lin, Yankai and Liu, Zhiyuan and Sun, Maosong and Liu, Yang and Zhu, Xuan},
  booktitle={Proceedings of the 29th AAAI Conference on Artificial Intelligence},
  year={2015}
}

@paper{transa,
	author = {Yantao Jia and Yuanzhuo Wang and Hailun Lin and Xiaolong Jin and Xueqi Cheng},
	title = {Locally Adaptive Translation for Knowledge Graph Embedding},
	conference = {AAAI Conference on Artificial Intelligence},
	year = {2016},
	keywords = {locally adaptive translation; knowledge graph embedding; optimal margin},
	abstract = {Knowledge graph embedding aims to represent entities and relations in a large-scale knowledge graph as elements in a continuous vector space. Existing methods, e.g., TransE and TransH, learn embedding representation by defining a global margin-based loss function over the data. However, the optimal loss function is determined during experiments whose parameters are examined among a closed set of candidates. Moreover, embeddings over two knowledge graphs with different entities and relations share the same set of candidate loss functions, ignoring the locality of both graphs. This leads to the limited performance of embedding related applications. In this paper, we propose a locally adaptive translation method for knowledge graph embedding, called TransA, to find the optimal loss function by adaptively determining its margin over different knowledge graphs. Experiments on two benchmark data sets demonstrate the superiority of the proposed method, as compared to the-state-of-the-art ones.},

	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12018}
}

@article{hake, title={Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/5701}, DOI={10.1609/aaai.v34i03.5701}, abstractNote={&lt;p&gt;Knowledge graph embedding, which aims to represent entities and relations as low dimensional vectors (or matrices, tensors, etc.), has been shown to be a powerful technique for predicting missing links in knowledge graphs. Existing knowledge graph embedding models mainly focus on modeling relation patterns such as symmetry/antisymmetry, inversion, and composition. However, many existing approaches fail to model &lt;em&gt;semantic hierarchies&lt;/em&gt;, which are common in real-world applications. To address this challenge, we propose a novel knowledge graph embedding model—namely, Hierarchy-Aware Knowledge Graph Embedding (HAKE)—which maps entities into the polar coordinate system. HAKE is inspired by the fact that concentric circles in the polar coordinate system can naturally reflect the hierarchy. Specifically, the radial coordinate aims to model entities at different levels of the hierarchy, and entities with smaller radii are expected to be at higher levels; the angular coordinate aims to distinguish entities at the same level of the hierarchy, and these entities are expected to have roughly the same radii but different angles. Experiments demonstrate that HAKE can effectively model the semantic hierarchies in knowledge graphs, and significantly outperforms existing state-of-the-art methods on benchmark datasets for the link prediction task.&lt;/p&gt;}, number={03}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhang, Zhanqiu and Cai, Jianyu and Zhang, Yongdong and Wang, Jie}, year={2020}, month={Apr.}, pages={3065-3072} }

@inproceedings{
rotate,
title={RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space},
author={Zhiqing Sun and Zhi-Hong Deng and Jian-Yun Nie and Jian Tang},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HkgEQnRqYQ},
}

@inproceedings{rescal,
  title={A Three-Way Model for Collective Learning on Multi-Relational Data.},
  author={Nickel, Maximilian and Tresp, Volker and Kriegel, Hans-Peter},
  booktitle={Proceedings of the 28th International Conference on Machine Learning},
  pages={809--816},
  year={2011}
} %volume={11},


@inproceedings{distmult,
  author = {Yang, Bishan and Yih, Scott Wen-tau and He, Xiaodong and Gao, Jianfeng and Deng, Li},
    title = {Embedding Entities and Relations for Learning and Inference in Knowledge Bases},
    booktitle = {Proceedings of the International Conference on Learning Representations 2015},
    year = {2015},
    month = {May},
    
}


@inproceedings{complex,
  title={Complex embeddings for simple link prediction},
  author={Trouillon, Th{\'e}o and Welbl, Johannes and Riedel, Sebastian and Gaussier, {\'E}ric and Bouchard, Guillaume},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  pages={2071--2080},
  year={2016}
}

 @InProceedings{analogy, title = {Analogical Inference for Multi-relational Embeddings}, author = {Hanxiao Liu and Yuexin Wu and Yiming Yang}, pages = {2168--2178}, year = {2017}, editor = {Doina Precup and Yee Whye Teh}, volume = {70}, booktitle = {Proceedings of Machine Learning Research} } 
 
 @inproceedings{tucker,
    title = "{T}uck{ER}: Tensor Factorization for Knowledge Graph Completion",
    author = "Balazevic, Ivana  and
      Allen, Carl  and
      Hospedales, Timothy",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1522",
    doi = "10.18653/v1/D19-1522",
    pages = "5185--5194",
    abstract = "Knowledge graphs are structured representations of real world facts. However, they typically contain only a small subset of all possible facts. Link prediction is a task of inferring missing facts based on existing ones. We propose TuckER, a relatively straightforward but powerful linear model based on Tucker decomposition of the binary tensor representation of knowledge graph triples. TuckER outperforms previous state-of-the-art models across standard link prediction datasets, acting as a strong baseline for more elaborate models. We show that TuckER is a fully expressive model, derive sufficient bounds on its embedding dimensionalities and demonstrate that several previously introduced linear models can be viewed as special cases of TuckER.",
}
@inproceedings{ruge,
  author={Shu Guo and Quan Wang and Lihong Wang and Bin Wang and Li Guo},
  title={Knowledge Graph Embedding With Iterative Guidance From Soft Rules},
  year={2018},
  cdate={1514764800000},
  pages={4816-4823},
  url={https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16369},
  booktitle={AAAI},
  crossref={conf/aaai/2018}
}

@inproceedings{rulerec,
	address = {San Francisco, CA, USA},
	series = {{WWW} '19},
	title = {Jointly {Learning} {Explainable} {Rules} for {Recommendation} with {Knowledge} {Graph}},
	isbn = {978-1-4503-6674-8},
	url = {https://doi.org/10.1145/3308558.3313607},
	doi = {10.1145/3308558.3313607},
	abstract = {Explainability and effectiveness are two key aspects for building recommender systems. Prior efforts mostly focus on incorporating side information to achieve better recommendation performance. However, these methods have some weaknesses: (1) prediction of neural network-based embedding methods are hard to explain and debug; (2) symbolic, graph-based approaches (e.g., meta path-based models) require manual efforts and domain knowledge to define patterns and rules, and ignore the item association types (e.g. substitutable and complementary). In this paper, we propose a novel joint learning framework to integrate induction of explainable rules from knowledge graph with construction of a rule-guided neural recommendation model. The framework encourages two modules to complement each other in generating effective and explainable recommendation: 1) inductive rules, mined from item-centric knowledge graphs, summarize common multi-hop relational patterns for inferring different item associations and provide human-readable explanation for model prediction; 2) recommendation module can be augmented by induced rules and thus have better generalization ability dealing with the cold-start issue. Extensive experiments1 show that our proposed method has achieved significant improvements in item recommendation over baselines on real-world datasets. Our model demonstrates robust performance over “noisy” item knowledge graphs, generated by linking item names to related entities.},
	urldate = {2020-06-02},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Weizhi and Zhang, Min and Cao, Yue and Jin, Woojeong and Wang, Chenyang and Liu, Yiqun and Ma, Shaoping and Ren, Xiang},
	month = may,
	year = {2019},
	pages = {1210--1221},
}

@inproceedings{slre,
author = {Guo, Shu and Li, Lin and Hui, Zhen and Meng, Lingshuai and Ma, Bingnan and Liu, Wei and Wang, Lihong and Zhai, Haibin and Zhang, Hong},
title = {Knowledge Graph Embedding Preserving Soft Logical Regularity},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412055},
doi = {10.1145/3340531.3412055},
abstract = {Embedding knowledge graphs (KGs) into continuous vector spaces is currently an active research area. Soft rules, despite their uncertainty, are highly beneficial to KG embedding. However, they have not been studied enough in recent methods. A major challenge here is how to devise a principled framework, which efficiently and effectively integrates such soft logical information into embedding models. This paper proposes a highly scalable and effective method for preserving soft logical regularities by imposing soft rule constraints on relation representations. Specifically, we first represent relations as bilinear forms and map entity representations into a non-negative and bounded space. Then we derive a rule-based regularization that merely enforces relation representations to satisfy constraints introduced by soft rules. The proposed method has the following advantages: 1) it regularizes relations directly with the complexity of rule learning independent of entity set size, improving scalability; 2) it imposes prior logical information upon the structure of the embedding space, and would be beneficial to knowledge reasoning. Evaluation in link prediction on Freebase and DBpedia shows the effectiveness of our approach over many competitive baselines. Code and datasets are available at https://github.com/StudyGroup-lab/SLRE.},
booktitle = {Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
pages = {425–434},
numpages = {10},
keywords = {knowledge graph, logic rule, representation learning, embedding},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@article{sole,
	title = {Enhanced {Knowledge} {Graph} {Embedding} by {Jointly} {Learning} {Soft} {Rules} and {Facts}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1999-4893/12/12/265},
	doi = {10.3390/a12120265},
	abstract = {Combining first order logic rules with a Knowledge Graph (KG) embedding model has recently gained increasing attention, as rules introduce rich background information. Among such studies, models equipped with soft rules, which are extracted with certain confidences, achieve state-of-the-art performance. However, the existing methods either cannot support the transitivity and composition rules or take soft rules as regularization terms to constrain derived facts, which is incapable of encoding the logical background knowledge about facts contained in soft rules. In addition, previous works performed one time logical inference over rules to generate valid groundings for modeling rules, ignoring forward chaining inference, which can further generate more valid groundings to better model rules. To these ends, this paper proposes Soft Logical rules enhanced Embedding (SoLE), a novel KG embedding model equipped with a joint training algorithm over soft rules and KG facts to inject the logical background knowledge of rules into embeddings, as well as forward chaining inference over rules. Evaluations on Freebase and DBpedia show that SoLE not only achieves improvements of 11.6\%/5.9\% in Mean Reciprocal Rank (MRR) and 18.4\%/15.9\% in HITS@1 compared to the model on which SoLE is based, but also significantly and consistently outperforms the state-of-the-art baselines in the link prediction task.},
	language = {en},
	number = {12},
	urldate = {2021-04-12},
	journal = {Algorithms},
	author = {Zhang, Jindou and Li, Jing},
	month = dec,
	year = {2019},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {knowledge graph, knowledge graph embedding, link prediction, logical rule},
	pages = {265},
}
@inproceedings{ptranse,
    title = "Knowledge Graph and Text Jointly Embedding",
    author = "Wang, Zhen  and
      Zhang, Jianwen  and
      Feng, Jianlin  and
      Chen, Zheng",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1167",
    doi = "10.3115/v1/D14-1167",
    pages = "1591--1601",
}

@inproceedings{tare,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Embedding {Knowledge} {Graphs} {Based} on {Transitivity} and {Asymmetry} of {Rules}},
	isbn = {978-3-319-93037-4},
	doi = {10.1007/978-3-319-93037-4_12},
	abstract = {Representation learning of knowledge graphs encodes entities and relation types into a continuous low-dimensional vector space, learns embeddings of entities and relation types. Most existing methods only concentrate on knowledge triples, ignoring logic rules which contain rich background knowledge. Although there has been some work aiming at leveraging both knowledge triples and logic rules, they ignore the transitivity and asymmetry of logic rules. In this paper, we propose a novel approach to learn knowledge representations with entities and ordered relations in knowledges and logic rules. The key idea is to integrate knowledge triples and logic rules, and approximately order the relation types in logic rules to utilize the transitivity and asymmetry of logic rules. All entries of the embeddings of relation types are constrained to be non-negative. We translate the general constrained optimization problem into an unconstrained optimization problem to solve the non-negative matrix factorization. Experimental results show that our model significantly outperforms other baselines on knowledge graph completion task. It indicates that our model is capable of capturing the transitivity and asymmetry information, which is significant when learning embeddings of knowledge graphs.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer International Publishing},
	author = {Wang, Mengya and Rong, Erhu and Zhuo, Hankui and Zhu, Huiling},
	editor = {Phung, Dinh and Tseng, Vincent S. and Webb, Geoffrey I. and Ho, Bao and Ganji, Mohadeseh and Rashidi, Lida},
	year = {2018},
	keywords = {Knowledge graph, Asymmetry, Logic rules, Non-negative matrix factorization, Transitivity},
	pages = {141--153},
}

@inproceedings{itere,
author = {Zhang, Wen and Paudel, Bibek and Wang, Liang and Chen, Jiaoyan and Zhu, Hai and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
title = {Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313612},
doi = {10.1145/3308558.3313612},
abstract = {Reasoning is essential for the development of large knowledge graphs, especially for completion, which aims to infer new triples based on existing ones. Both rules and embeddings can be used for knowledge graph reasoning and they have their own advantages and difficulties. Rule-based reasoning is accurate and explainable but rule learning with searching over the graph always suffers from efficiency due to huge search space. Embedding-based reasoning is more scalable and efficient as the reasoning is conducted via computation between embeddings, but it has difficulty learning good representations for sparse entities because a good embedding relies heavily on data richness. Based on this observation, in this paper we explore how embedding and rule learning can be combined together and complement each other's difficulties with their advantages. We propose a novel framework IterE iteratively learning embeddings and rules, in which rules are learned from embeddings with proper pruning strategy and embeddings are learned from existing triples and new triples inferred by rules. Evaluations on embedding qualities of IterE show that rules help improve the quality of sparse entity embeddings and their link prediction results. We also evaluate the efficiency of rule learning and quality of rules from IterE compared with AMIE+, showing that IterE is capable of generating high quality rules more efficiently. Experiments show that iteratively learning embeddings and rules benefit each other during learning and prediction.},
booktitle = {The World Wide Web Conference},
pages = {2366–2377},
numpages = {12},
keywords = {rule learning, reasoning, knowledge graph, embedding},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@inproceedings{ruLES,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Rule {Learning} from {Knowledge} {Graphs} {Guided} by {Embedding} {Models}},
	isbn = {978-3-030-00671-6},
	doi = {10.1007/978-3-030-00671-6\_5},
	abstract = {Rules over a Knowledge Graph (KG) capture interpretable patterns in data and various methods for rule learning have been proposed. Since KGs are inherently incomplete, rules can be used to deduce missing facts. Statistical measures for learned rules such as confidence reflect rule quality well when the KG is reasonably complete; however, these measures might be misleading otherwise. So it is difficult to learn high-quality rules from the KG alone, and scalability dictates that only a small set of candidate rules could be generated. Therefore, the ranking and pruning of candidate rules are major problems. To address this issue, we propose a rule learning method that utilizes probabilistic representations of missing facts. In particular, we iteratively extend rules induced from a KG by relying on feedback from a precomputed embedding model over the KG and external information sources including text corpora. Experiments on real-world KGs demonstrate the effectiveness of our novel approach both with respect to the quality of the learned rules and fact predictions that they produce.},
	language = {en},
	booktitle = {The {Semantic} {Web} – {ISWC} 2018},
	publisher = {Springer International Publishing},
	author = {Ho, Vinh Thinh and Stepanova, Daria and Gad-Elrab, Mohamed H. and Kharlamov, Evgeny and Weikum, Gerhard},
	editor = {Vrandečić, Denny and Bontcheva, Kalina and Suárez-Figueroa, Mari Carmen and Presutti, Valentina and Celino, Irene and Sabou, Marta and Kaffee, Lucie-Aimée and Simperl, Elena},
	year = {2018},
	keywords = {Candidate Rules, Embedding Model, Horn Part, Knowledge Graph (KG), Rule Learning System},
	pages = {72--90},
}

@inproceedings{kale,
    title = "Jointly Embedding Knowledge Graphs and Logical Rules",
    author = "Guo, Shu  and
      Wang, Quan  and
      Wang, Lihong  and
      Wang, Bin  and
      Guo, Li",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1019",
    doi = "10.18653/v1/D16-1019",
    pages = "192--202",
}

@incollection{rbox,
	address = {Cham},
	title = {Enhancing {Knowledge} {Graph} {Embedding} from a {Logical} {Perspective}},
	volume = {10675},
	isbn = {978-3-319-70681-8 978-3-319-70682-5},
	url = {http://link.springer.com/10.1007/978-3-319-70682-5_15},
	abstract = {Knowledge graph embedding aims to represent entities and relations in a knowledge graph as low-dimensional real-value vectors. Most existing studies exploit only structural information to learn these vectors. This paper studies how logical information expressed as RBox axioms in OWL 2 is used for embedding. The involvement of RBox axioms could prevent existing methods from learning predictive vectors. For example, the symmetric, reﬂexive or transitive relations can be declared by RBox axioms, but popular translation-based methods are unable to learn distinguishable vectors for multiple these relations in the ideal case. To overcome these limitations introduced by the involvement of RBox axioms, this paper proposes to enhance existing translationbased methods by logical pre-completion and bi-directional projection of entities. Experimental results demonstrate that these enhancements improve the predictive performance in link prediction and triple classiﬁcation.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {Semantic {Technology}},
	publisher = {Springer International Publishing},
	author = {Du, Jianfeng and Qi, Kunxun and Wan, Hai and Peng, Bo and Lu, Shengbin and Shen, Yuming},
	editor = {Wang, Zhe and Turhan, Anni-Yasmin and Wang, Kewen and Zhang, Xiaowang},
	year = {2017},
	doi = {10.1007/978-3-319-70682-5_15},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {232--247},
}
@inproceedings{yoonetal,
	address = {San Diego, California},
	title = {A {Translation}-{Based} {Knowledge} {Graph} {Embedding} {Preserving} {Logical} {Property} of {Relations}},
	url = {https://www.aclweb.org/anthology/N16-1105},
	doi = {10.18653/v1/N16-1105},
	urldate = {2021-04-15},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Yoon, Hee-Geun and Song, Hyun-Je and Park, Seong-Bae and Park, Se-Young},
	month = jun,
	year = {2016},
	pages = {907--916},
}

@article{rlvlr,
	title = {An {Embedding}-based {Approach} to {Rule} {Learning} in {Knowledge} {Graphs}},
	abstract = {It is natural and effective to use rules for representing explicit knowledge in knowledge graphs. However, it is challenging to learn rules automatically from very large knowledge graphs such as Freebase and YAGO. This paper presents a new approach, RLvLR (Rule Learning via Learning Representations), to learning rules from large knowledge graphs by using the technique of embedding in representation learning together with a new sampling method. Based on RLvLR, a new method RLvLR-Stream is developed for learning rules from streams of knowledge graphs. Both RLvLR and RLvLR-Stream have been implemented and experiments conducted to validate the proposed methods regarding the tasks of rule learning and link prediction. Experimental results show that our systems are able to handle the task of rule learning from large knowledge graphs with high accuracy and outperform some state-of-the-art systems. Speciﬁcally, for massive knowledge graphs with hundreds of predicates and over 10M facts, RLvLR is much faster and can learn much more quality rules than major systems for rule learning in knowledge graphs such as AMIE+. In the setting of knowledge graph streams, RLvLR-Stream signiﬁcantly improved RLvLR for both rule learning and link prediction.},
	language = {en},
	author = {Omran, Pouya Ghiasnezhad and Wang, Kewen and Wang, Zhe},
	pages = {13},
}

@inproceedings{hyperkg,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Hyperbolic {Knowledge} {Graph} {Embeddings} for {Knowledge} {Base} {Completion}},
	isbn = {978-3-030-49461-2},
	doi = {10.1007/978-3-030-49461-2_12},
	abstract = {Learning embeddings of entities and relations existing in knowledge bases allows the discovery of hidden patterns in them. In this work, we examine the contribution of geometrical space to the task of knowledge base completion. We focus on the family of translational models, whose performance has been lagging. We extend these models to the hyperbolic space so as to better reflect the topological properties of knowledge bases. We investigate the type of regularities that our model, dubbed HyperKG, can capture and show that it is a prominent candidate for effectively representing a subset of Datalog rules. We empirically show, using a variety of link prediction datasets, that hyperbolic space allows to narrow down significantly the performance gap between translational and bilinear models and effectively represent certain types of rules.},
	language = {en},
	booktitle = {The {Semantic} {Web}},
	publisher = {Springer International Publishing},
	author = {Kolyvakis, Prodromos and Kalousis, Alexandros and Kiritsis, Dimitris},
	editor = {Harth, Andreas and Kirrane, Sabrina and Ngonga Ngomo, Axel-Cyrille and Paulheim, Heiko and Rula, Anisa and Gentile, Anna Lisa and Haase, Peter and Cochez, Michael},
	year = {2020},
	keywords = {Hyperbolic embeddings, Knowledge base completion, Knowledge graph embeddings},
	pages = {199--214},
}

@article{rpje,
	title = {Rule-{Guided} {Compositional} {Representation} {Learning} on {Knowledge} {Graphs}},
	volume = {34},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/5687},
	doi = {10.1609/aaai.v34i03.5687},
	abstract = {Representation learning on a knowledge graph (KG) is to embed entities and relations of a KG into low-dimensional continuous vector spaces. Early KG embedding methods only pay attention to structured information encoded in triples, which would cause limited performance due to the structure sparseness of KGs. Some recent attempts consider paths information to expand the structure of KGs but lack explainability in the process of obtaining the path representations. In this paper, we propose a novel Rule and Path-based Joint Embedding (RPJE) scheme, which takes full advantage of the explainability and accuracy of logic rules, the generalization of KG embedding as well as the supplementary semantic structure of paths. Specifically, logic rules of different lengths (the number of relations in rule body) in the form of Horn clauses are first mined from the KG and elaborately encoded for representation learning. Then, the rules of length 2 are applied to compose paths accurately while the rules of length 1 are explicitly employed to create semantic associations among relations and constrain relation embeddings. Moreover, the confidence level of each rule is also considered in optimization to guarantee the availability of applying the rule to representation learning. Extensive experimental results illustrate that RPJE outperforms other state-of-the-art baselines on KG completion task, which also demonstrate the superiority of utilizing logic rules as well as paths for improving the accuracy and explainability of representation learning.},
	language = {en},
	number = {03},
	urldate = {2020-10-14},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Niu, Guanglin and Zhang, Yongfei and Li, Bo and Cui, Peng and Liu, Si and Li, Jingyang and Zhang, Xiaowei},
	month = apr,
	year = {2020},
	note = {Number: 03},
	pages = {2950--2958},
}
@inproceedings{anyburl,
  title     = {Anytime Bottom-Up Rule Learning for Knowledge Graph Completion},
  author    = {Meilicke, Christian and Chekol, Melisachew Wudage and Ruffinelli, Daniel and Stuckenschmidt, Heiner},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {3137--3143},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/435},
  url       = {https://doi.org/10.24963/ijcai.2019/435},
}

@article{ukge,
	title = {Embedding {Uncertain} {Knowledge} {Graphs}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4210},
	doi = {10.1609/aaai.v33i01.33013363},
	language = {en},
	number = {01},
	urldate = {2021-04-16},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Chen, Xuelu and Chen, Muhao and Shi, Weijia and Sun, Yizhou and Zaniolo, Carlo},
	month = jul,
	year = {2019},
	note = {Number: 01},
	pages = {3363--3370},
}

@inproceedings{drum,
 author = {Sadeghian, Ali and Armandpour, Mohammadreza and Ding, Patrick and Wang, Daisy Zhe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {DRUM: End-To-End Differentiable Rule Mining On Knowledge Graphs},
 url = {https://proceedings.neurips.cc/paper/2019/file/0c72cb7ee1512f800abe27823a792d03-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{crosse,
author = {Zhang, Wen and Paudel, Bibek and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
title = {Interaction Embeddings for Prediction and Explanation in Knowledge Graphs},
year = {2019},
isbn = {9781450359405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3289600.3291014},
doi = {10.1145/3289600.3291014},
abstract = {Knowledge graph embedding aims to learn distributed representations for entities and relations, and is proven to be effective in many applications. Crossover interactions -- bi-directional effects between entities and relations --- help select related information when predicting a new triple, but haven't been formally discussed before. In this paper, we propose CrossE, a novel knowledge graph embedding which explicitly simulates crossover interactions. It not only learns one general embedding for each entity and relation as most previous methods do, but also generates multiple triple specific embeddings for both of them, named interaction embeddings. We evaluate embeddings on typical link prediction tasks and find that CrossE achieves state-of-the-art results on complex and more challenging datasets. Furthermore, we evaluate embeddings from a new perspective -- giving explanations for predicted triples, which is important for real applications. In this work, an explanation for a triple is regarded as a reliable closed-path between the head and the tail entity. Compared to other baselines, we show experimentally that CrossE, benefiting from interaction embeddings, is more capable of generating reliable explanations to support its predictions.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
pages = {96–104},
numpages = {9},
keywords = {link prediction, explanation, knowledge graph embedding, crossover interactions},
location = {Melbourne VIC, Australia},
series = {WSDM '19}
}

@inproceedings{rtranse,
    title = "Composing Relationships with Translations",
    author = "Garc{\'\i}a-Dur{\'a}n, Alberto  and
      Bordes, Antoine  and
      Usunier, Nicolas",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1034",
    doi = "10.18653/v1/D15-1034",
    pages = "286--290",
}


@article{gnn,
  author    = {Zonghan Wu and
               Shirui Pan and
               Fengwen Chen and
               Guodong Long and
               Chengqi Zhang and
               Philip S. Yu},
  title     = {A Comprehensive Survey on Graph Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1901.00596},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.00596},
  archivePrefix = {arXiv},
  eprint    = {1901.00596},
  timestamp = {Thu, 31 Jan 2019 13:52:49 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-00596.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{hole,
	author = {Maximilian Nickel and Lorenzo Rosasco and Tomaso Poggio},
	title = {Holographic Embeddings of Knowledge Graphs},
	conference = {AAAI Conference on Artificial Intelligence},
	year = {2016},
	keywords = {Knowledge Graph; Compositional Embeddings; Holographic Embeddings},
	abstract = {Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional  vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.},


}

@inproceedings{dihedral,
    title = "Relation Embedding with Dihedral Group in Knowledge Graph",
    author = "Xu, Canran  and
      Li, Ruijiang",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1026",
    doi = "10.18653/v1/P19-1026",
    pages = "263--272",
    abstract = "Link prediction is critical for the application of incomplete knowledge graph (KG) in the downstream tasks. As a family of effective approaches for link predictions, embedding methods try to learn low-rank representations for both entities and relations such that the bilinear form defined therein is a well-behaved scoring function. Despite of their successful performances, existing bilinear forms overlook the modeling of relation compositions, resulting in lacks of interpretability for reasoning on KG. To fulfill this gap, we propose a new model called DihEdral, named after dihedral symmetry group. This new model learns knowledge graph embeddings that can capture relation compositions by nature. Furthermore, our approach models the relation embeddings parametrized by discrete values, thereby decrease the solution space drastically. Our experiments show that DihEdral is able to capture all desired properties such as (skew-) symmetry, inversion and (non-) Abelian composition, and outperforms existing bilinear form based approach and is comparable to or better than deep learning models such as ConvE.",
}

@article{bianchietal,
  author    = {Federico Bianchi and
               Gaetano Rossiello and
               Luca Costabello and
               Matteo Palmonari and
               Pasquale Minervini},
  title     = {Knowledge Graph Embeddings and Explainable {AI}},
  journal   = {CoRR},
  volume    = {abs/2004.14843},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.14843},
  archivePrefix = {arXiv},
  eprint    = {2004.14843},
  timestamp = {Sun, 03 May 2020 17:39:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-14843.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{gnnexplainer,
  author    = {Rex Ying and
               Dylan Bourgeois and
               Jiaxuan You and
               Marinka Zitnik and
               Jure Leskovec},
  title     = {{GNN} Explainer: {A} Tool for Post-hoc Explanation of Graph Neural
               Networks},
  journal   = {CoRR},
  volume    = {abs/1903.03894},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.03894},
  archivePrefix = {arXiv},
  eprint    = {1903.03894},
  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-03894.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{criage,
title={Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications},
author={Pezeshkpour, Pouya and Tian, Yifan and Singh, Sameer},
journal={arXiv preprint arXiv:1905.00563},
year={2019}
}

@inproceedings{yago,
  abstract = {We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques.},
  acmid = {1242667},
  added-at = {2016-11-28T08:43:21.000+0100},
  address = {New York, NY, USA},
  author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
  biburl = {https://www.bibsonomy.org/bibtex/2a4ca39faa9a4c71f37c073d626db963f/thoni},
  booktitle = {Proceedings of the 16th International Conference on World Wide Web},
  doi = {10.1145/1242572.1242667},
  interhash = {1d2c2b23ce2a6754d12c4364e19c574c},
  intrahash = {a4ca39faa9a4c71f37c073d626db963f},
  isbn = {978-1-59593-654-7},
  keywords = {ontology proposal tau yago},
  location = {Banff, Alberta, Canada},
  numpages = {10},
  pages = {697--706},
  publisher = {ACM},
  series = {WWW '07},
  timestamp = {2017-12-12T10:34:31.000+0100},
  title = {Yago: A Core of Semantic Knowledge},
  url = {http://doi.acm.org/10.1145/1242572.1242667},
  year = 2007
}

@inproceedings{freebase,
author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
title = {Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge},
year = {2008},
isbn = {9781605581026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1376616.1376746},
doi = {10.1145/1376616.1376746},
abstract = {Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.},
booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
pages = {1247–1250},
numpages = {4},
keywords = {tuple store, semantic network, collaborative systems},
location = {Vancouver, Canada},
series = {SIGMOD '08}
}

@book{wordnet,
  abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.},
  added-at = {2017-11-01T11:46:20.000+0100},
  address = {Cambridge, MA},
  biburl = {https://www.bibsonomy.org/bibtex/28472b4f9d7f2bfc4a97ffd4a023facc6/flint63},
  editor = {Fellbaum, Christiane},
  file = {eBook:1900-99/Fellbaum1998.pdf:PDF;MIT Press Product Page:http\://mitpress.mit.edu/books/wordnet:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/026206197X/:URL},
  groups = {public},
  interhash = {42daa1681607dd1d3f3234c605d84ec3},
  intrahash = {8472b4f9d7f2bfc4a97ffd4a023facc6},
  isbn = {978-0-262-06197-1},
  keywords = {01821 101 mitpress book shelf ai language processing ontology lexicon},
  publisher = {MIT Press},
  series = {Language, Speech, and Communication},
  timestamp = {2018-04-16T11:51:58.000+0200},
  title = {WordNet: An Electronic Lexical Database},
  username = {flint63},
  year = 1998
}

@inproceedings{raina_2009_gpu,
author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
title = {Large-Scale Deep Unsupervised Learning Using Graphics Processors},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553486},
doi = {10.1145/1553374.1553486},
abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton &amp; Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples.In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {873–880},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{glorot_2014_relu,
  added-at = {2014-04-01T20:16:10.000+0200},
  author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  biburl = {https://www.bibsonomy.org/bibtex/256f5ffd25378f109c8cc14394bcfdabb/prlz77},
  booktitle = {AISTATS},
  crossref = {conf/aistats/2011},
  editor = {Gordon, Geoffrey J. and Dunson, David B. and Dudík, Miroslav},
  ee = {http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf},
  interhash = {fbf04ef5079b11118f3f3184b1068d88},
  intrahash = {56f5ffd25378f109c8cc14394bcfdabb},
  keywords = {Bengio Deep Networks Neural Rectifier Relu Sparse},
  pages = {315-323},
  publisher = {JMLR.org},
  series = {JMLR Proceedings},
  timestamp = {2014-04-01T20:16:10.000+0200},
  title = {Deep Sparse Rectifier Neural Networks.},
  url = {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp15.html#GlorotBB11},
  volume = 15,
  year = 2011
}



@misc{embedding_visualization,
url={https://graphvite.io/pretrained\_models}}


@article{pykeen,
    author = {Ali, Mehdi and Berrendorf, Max and Hoyt, Charles Tapley and Vermue, Laurent and Sharifzadeh, Sahand and Tresp, Volker and Lehmann, Jens},
    journal = {Journal of Machine Learning Research},
    number = {82},
    pages = {1--6},
    title = {{PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings}},
    url = {http://jmlr.org/papers/v22/20-825.html},
    volume = {22},
    year = {2021}
}