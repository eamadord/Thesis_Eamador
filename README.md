# Methods for Knowledge-Based Systems and Deep Learning Integration

Keywords: neurosymbolic AI, explainable AI, deep learning, knowledge-based systems, integration methods


## Abstract
Neurosymbolic artifcial intelligence comprises a set of approaches for the integration of artifcial intelligence models (symbolic and subsymbolic), such that the benefts of both models are combined under a unifed approach. For this purpose, multiple neurosymbolic design techniques have been proposed throughout the years. However, these approaches do not address contextual and practical aspects, and do not provide clear guidelines on how or when neurosymbolic integration is required. This thesis aims to provide a general design method for neurosymbolic systems, focusing on the integration of knowledge-based systems (symbolic) and deep learning models (subsymbolic). The proposed design method extends the previously considered aspects of neurosymbolic integration (limitations and benefts) by including practical and contextual aspects (restrictions and considerations). For each potential interaction between knowledge-based systems and deep learning, a specifc integration design method is formulated outlining its individual parameters. Instantiations on the different integration design methods are provided to assess the viability and applicability of the proposal. The contributions presented in this thesis can be summarized as follows. First, a general design method for the integration of knowledge-based systems and deep learning models is proposed. From this general design method, a specifc method for each potential interaction between knowledge-based systems and deep learning models is formulated. Each integration design method is instantiated on different application scenarios, generating the following research resources: a semanticbased initialization method for knowledge graph embedding models, a case-based reasoning model powered by deep learning for the generation of medical reports, a multi-agent system for the extraction of behavioral user patterns from opaque personalization systems, and an explainability framework for knowledge graph embedding predictions. The versatility and applicability of the proposed general design method is validated through its instantiation across several application scenarios, providing feasible solutions for several open research challenges, thus contributing to advancing the state-of-the-art in those areas. 
